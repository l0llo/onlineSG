{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Example\n",
    "of the last added functionalities in onlineSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')  # uncomment to add the path to the onlineSG folder \n",
    "# You have to change the path if you move this file.\n",
    "# Alternatevely add the onlineSG folder to your PYTHONPATH\n",
    "# e.g. On Linux add this line on .bashrc:\n",
    "# export PYTHONPATH=\"<absolute-path-to-onlineSG>:PYTHONPATH\"\n",
    "# then you can use onlineSG library from everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import source.game as game\n",
    "import source.player as player\n",
    "import source.environment as environment\n",
    "import source.errors as errors\n",
    "import source.parsers as parsers\n",
    "import source.players.attackers as attackers\n",
    "import source.players.base_defenders as base_defenders\n",
    "import source.players.defenders as defenders\n",
    "import source.runner as runner\n",
    "import source.players.detection as detection \n",
    "import source.util as util\n",
    "\n",
    "from source.util import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'source.util' from '/home/lorenzo/Scrivania/Polimi/Thesis/code/onlineSG/source/util.py'>"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you change something in the files, don't forget to reload\n",
    "reload(player)\n",
    "reload(base_defenders)\n",
    "reload(attackers)\n",
    "reload(defenders)\n",
    "reload(errors)\n",
    "reload(runner)\n",
    "reload(parsers)\n",
    "reload(game)\n",
    "#reload(environment)\n",
    "reload(detection)\n",
    "reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import source.players.fabulous as fabulous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'source.players.fabulous' from '/home/lorenzo/Scrivania/Polimi/Thesis/code/onlineSG/source/players/fabulous.py'>"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(fabulous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2238775040138658 231\n"
     ]
    }
   ],
   "source": [
    "t+=1\n",
    "p = 0.5 / t**2\n",
    "b = (sqrt(-log(p) / (t)))\n",
    "print(b, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = game.zs_game([0.4, 0.5, 0.3, 0.1, 0.7, 0.8], 1000)\n",
    "d = fabulous.FABULOUS(g, 0, 1)\n",
    "a = attackers.StochasticAttacker(g, 1, 1)\n",
    "p1 = attackers.StochasticAttacker(g, 1, 1)\n",
    "p2 = attackers.StochasticAttacker(g, 1, 1)\n",
    "p3 = attackers.UnknownStochasticAttacker(g, 1, 1)\n",
    "g.set_players([d], [a], [a, p1, p2, p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = runner.Experiment(deepcopy(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lt_loss 0.180151176757 is in [-0.5157335921350472141, 1.1157335921350470809]\n",
      "with b 0.8157335921350471 and loss 0.3\n",
      "lt_loss 0.180151176757 is in [-0.35191353338089642611, 1.2185802000475629558]\n",
      "with b 0.7852468667142297 and loss 0.4333333333333333\n",
      "lt_loss 0.180151176757 is in [-0.39465948221180691124, 1.0946594822118069779]\n",
      "with b 0.7446594822118069 and loss 0.35\n",
      "lt_loss 0.180151176757 is in [-0.32762910107965648177, 1.0876291010796563796]\n",
      "with b 0.7076291010796565 and loss 0.38\n",
      "lt_loss 0.180151176757 is in [-0.27540929765714111666, 1.0754092976571409945]\n",
      "with b 0.6754092976571411 and loss 0.39999999999999997\n",
      "lt_loss 0.180151176757 is in [-0.26173998033182632739, 1.0331685517603976798]\n",
      "with b 0.647454266046112 and loss 0.3857142857142857\n",
      "lt_loss 0.180151176757 is in [-0.27302682214618123613, 0.97302682214618119172]\n",
      "with b 0.6230268221461812 and loss 0.35\n",
      "lt_loss 0.180151176757 is in [-0.27926312945576492464, 0.9237075739002093]\n",
      "with b 0.6014853516779871 and loss 0.3222222222222222\n",
      "lt_loss 0.180151176757 is in [-0.28231633281153495352, 0.8823163328115348758]\n",
      "with b 0.5823163328115349 and loss 0.3\n",
      "lt_loss 0.180151176757 is in [-0.22875261432693688723, 0.90147988705420956101]\n",
      "with b 0.5651162506905733 and loss 0.33636363636363636\n",
      "lt_loss 0.180151176757 is in [-0.21623427755779606185, 0.882900944224462636]\n",
      "with b 0.5495676108911294 and loss 0.3333333333333333\n",
      "lt_loss 0.180151176757 is in [-0.17388009314628460888, 0.89695701622320778146]\n",
      "with b 0.5354185546847462 and loss 0.3615384615384616\n",
      "lt_loss 0.180151176757 is in [-0.17961005211206526599, 0.86532433782635098662]\n",
      "with b 0.5224671949692081 and loss 0.34285714285714286\n",
      "lt_loss 0.180151176757 is in [-0.18388326252532360972, 0.83721659585865693121]\n",
      "with b 0.5105499291919903 and loss 0.32666666666666666\n",
      "lt_loss 0.180151176757 is in [-0.14953276669461873505, 0.84953276669461863513]\n",
      "with b 0.4995327666946187 and loss 0.35\n",
      "lt_loss 0.180151176757 is in [-0.15989310092135572416, 0.81871663033312036539]\n",
      "with b 0.4893048656272381 and loss 0.32941176470588235\n",
      "lt_loss 0.180151176757 is in [-0.1519958983599898894, 0.80755145391554528089]\n",
      "with b 0.4797736761377676 and loss 0.3277777777777777\n",
      "lt_loss 0.180151176757 is in [-0.13401914868323439034, 0.8077033592095500536]\n",
      "with b 0.4708612539463922 and loss 0.33684210526315783\n",
      "lt_loss 0.180151176757 is in [-0.11750143273872537542, 0.80750143273872532212]\n",
      "with b 0.46250143273872535 and loss 0.345\n",
      "lt_loss 0.180151176757 is in [-0.09273287066096497222, 0.81654239447048881928]\n",
      "with b 0.45463763256572687 and loss 0.3619047619047619\n",
      "lt_loss 0.180151176757 is in [-0.079039325806102067595, 0.81540296216973839893]\n",
      "with b 0.44722114398792023 and loss 0.36818181818181817\n",
      "lt_loss 0.180151176757 is in [-0.074992380427448102065, 0.80542716303614381168]\n",
      "with b 0.44020977173179593 and loss 0.3652173913043478\n",
      "lt_loss 0.180151176757 is in [-0.079400086094837896145, 0.787733419428171322]\n",
      "with b 0.4335667527615046 and loss 0.3541666666666667\n",
      "lt_loss 0.180151176757 is in [-0.075259885848866558966, 0.77925988584886651811]\n",
      "with b 0.42725988584886654 and loss 0.352\n",
      "lt_loss 0.180151176757 is in [-0.07126082566440505861, 0.7712608256644050142]\n",
      "with b 0.42126082566440504 and loss 0.35\n",
      "lt_loss 0.180151176757 is in [-0.078507468938039726147, 0.75258154301211377391]\n",
      "with b 0.41554450597507675 and loss 0.337037037037037\n",
      "lt_loss 0.180151176757 is in [-0.074374379288375924713, 0.74580295071694746589]\n",
      "with b 0.41008866500266167 and loss 0.33571428571428574\n",
      "lt_loss 0.180151176757 is in [-0.056597590188397051136, 0.75314931432632814534]\n",
      "with b 0.4048734522573626 and loss 0.34827586206896555\n",
      "lt_loss 0.180151176757 is in [-0.053214434165648416553, 0.74654776749898177357]\n",
      "with b 0.3998811008323151 and loss 0.3466666666666667\n",
      "lt_loss 0.180151176757 is in [-0.049934362338381943491, 0.74025694298354327572]\n",
      "with b 0.3950956526609626 and loss 0.34516129032258064\n",
      "lt_loss 0.180151176757 is in [-0.046752726908773301062, 0.73425272690877330106]\n",
      "with b 0.3905027269087733 and loss 0.34375\n",
      "lt_loss 0.180151176757 is in [-0.052755990380652650895, 0.71942265704731922504]\n",
      "with b 0.38608932371398597 and loss 0.3333333333333333\n",
      "lt_loss 0.180151176757 is in [-0.055373068832816174645, 0.70831424530340436618]\n",
      "with b 0.3818436570681103 and loss 0.3264705882352941\n",
      "lt_loss 0.180151176757 is in [-0.040612154708732695063, 0.71489786899444685009]\n",
      "with b 0.3777550118515898 and loss 0.3371428571428571\n",
      "lt_loss 0.180151176757 is in [-0.046035843220641192719, 0.70159139877619680625]\n",
      "with b 0.37381362099841897 and loss 0.3277777777777778\n",
      "lt_loss 0.180151176757 is in [-0.042983532491502773887, 0.69703758654555680874]\n",
      "with b 0.3700105595185298 and loss 0.327027027027027\n",
      "lt_loss 0.180151176757 is in [-0.040021863231696097607, 0.69265344217906454904]\n",
      "with b 0.3663376527053803 and loss 0.3263157894736842\n",
      "lt_loss 0.180151176757 is in [-0.037146370692656416335, 0.68842842197470766052]\n",
      "with b 0.36278739633368207 and loss 0.32564102564102565\n",
      "lt_loss 0.180151176757 is in [-0.034352887035299983776, 0.68435288703529995047]\n",
      "with b 0.3593528870353 and loss 0.325\n",
      "lt_loss 0.180151176757 is in [-0.031637517447981766683, 0.6804180052528598921]\n",
      "with b 0.3560277613504208 and loss 0.32439024390243903\n",
      "lt_loss 0.180151176757 is in [-0.028996618392201134462, 0.67661566601124867315]\n",
      "with b 0.3528061422017249 and loss 0.32380952380952377\n",
      "lt_loss 0.180151176757 is in [-0.026426777790102051746, 0.67293840569707874533]\n",
      "with b 0.3496825917435904 and loss 0.32325581395348835\n",
      "lt_loss 0.180151176757 is in [-0.023924796978392448565, 0.66937934243293795156]\n",
      "with b 0.3466520697056652 and loss 0.32272727272727275\n",
      "lt_loss 0.180151176757 is in [-0.028154340932242394313, 0.659265452043353406]\n",
      "with b 0.34370989648779793 and loss 0.31555555555555553\n",
      "lt_loss 0.180151176757 is in [-0.025634329072723005538, 0.65606911168141857083]\n",
      "with b 0.3408517203770708 and loss 0.3152173913043478\n",
      "lt_loss 0.180151176757 is in [-0.018924552181856957311, 0.6572224245222825223]\n",
      "with b 0.33807348835206974 and loss 0.3191489361702128\n",
      "lt_loss 0.180151176757 is in [-0.020788086684845497043, 0.64995475335151220442]\n",
      "with b 0.3353714200181788 and loss 0.3145833333333333\n",
      "lt_loss 0.180151176757 is in [-0.010293004691627749558, 0.65519096387530117997]\n",
      "with b 0.33274198428346446 and loss 0.3224489795918367\n",
      "lt_loss 0.180151176757 is in [-0.0041818784399408892583, 0.65618187843994080222]\n",
      "with b 0.33018187843994085 and loss 0.32599999999999996\n",
      "lt_loss 0.180151176757 is in [-0.002197813283100757964, 0.65317820543996352178]\n",
      "with b 0.32768800936153214 and loss 0.3254901960784314\n",
      "lt_loss 0.180151176757 is in [-0.00025747656937974428004, 0.650257476569379822]\n",
      "with b 0.32525747656937976 and loss 0.325\n",
      "lt_loss 0.180151176757 is in [0.0016407449382916383662, 0.64741585883529317869]\n",
      "with b 0.3228875569485008 and loss 0.32452830188679244\n",
      "lt_loss 0.180151176757 is in [0.0034983831458849090623, 0.64464976500226323086]\n",
      "with b 0.32057569092818916 and loss 0.32407407407407407\n",
      "lt_loss 0.180151176757 is in [0.0016805300372272902187, 0.63831946996277255657]\n",
      "with b 0.31831946996277266 and loss 0.31999999999999995\n",
      "lt_loss 0.180151176757 is in [0.0035262319727830671034, 0.63575948231293111235]\n",
      "with b 0.31611662517007405 and loss 0.3196428571428571\n",
      "lt_loss 0.180151176757 is in [0.0018244566814891172157, 0.62975449068693190036]\n",
      "with b 0.3139650170027214 and loss 0.3157894736842105\n",
      "lt_loss 0.180151176757 is in [0.012275305191712104769, 0.63600055687725332021]\n",
      "with b 0.31186262584277064 and loss 0.32413793103448274\n",
      "lt_loss 0.180151176757 is in [0.020700931152947354974, 0.64031601799959503296]\n",
      "with b 0.30980754342332384 and loss 0.3305084745762712\n",
      "lt_loss 0.180151176757 is in [0.01886870167440490853, 0.63446463165892841296]\n",
      "with b 0.30779796499226175 and loss 0.32666666666666666\n",
      "lt_loss 0.180151176757 is in [0.02039732605358973716, 0.63206169033985282191]\n",
      "with b 0.30583218214313157 and loss 0.3262295081967213\n",
      "lt_loss 0.180151176757 is in [0.025123681817664444971, 0.63294083431136771711]\n",
      "with b 0.30390857624685164 and loss 0.3290322580645161\n",
      "lt_loss 0.180151176757 is in [0.023371212971413923842, 0.62742243782223683368]\n",
      "with b 0.3020256124254115 and loss 0.3253968253968254\n",
      "lt_loss 0.180151176757 is in [0.024818165984693718595, 0.62518183401530635912]\n",
      "with b 0.3001818340153063 and loss 0.325\n",
      "lt_loss 0.180151176757 is in [0.026239527141194540771, 0.62299124208957468163]\n",
      "with b 0.29837585747419004 and loss 0.3246153846153846\n",
      "lt_loss 0.180151176757 is in [0.030666359583459590343, 0.62387909496199500659]\n",
      "with b 0.2966063676892677 and loss 0.32727272727272727\n",
      "lt_loss 0.180151176757 is in [0.031993557991417453934, 0.62173778529216461308]\n",
      "with b 0.2948721136503736 and loss 0.32686567164179103\n",
      "lt_loss 0.180151176757 is in [0.030357507310124487443, 0.61670131621928736543]\n",
      "with b 0.2931719044545814 and loss 0.3235294117647059\n",
      "lt_loss 0.180151176757 is in [0.03748090163374717676, 0.62049011285900645962]\n",
      "with b 0.29150460561262964 and loss 0.3289855072463768\n",
      "lt_loss 0.180151176757 is in [0.034416578655228569072, 0.61415484991619995192]\n",
      "with b 0.2898691356304857 and loss 0.3242857142857143\n",
      "lt_loss 0.180151176757 is in [0.032862297721317046406, 0.60939122340544349399]\n",
      "with b 0.2882644628420632 and loss 0.32112676056338024\n",
      "lt_loss 0.180151176757 is in [0.031365953084062536682, 0.60474515802704864598]\n",
      "with b 0.28668960247149305 and loss 0.3180555555555556\n",
      "lt_loss 0.180151176757 is in [0.029924879245213253931, 0.6002121070561565741]\n",
      "with b 0.28514361390547166 and loss 0.3150684931506849\n",
      "lt_loss 0.180151176757 is in [0.028536564004068343259, 0.59578776032025604348]\n",
      "with b 0.28362559815809385 and loss 0.3121621621621622\n",
      "lt_loss 0.180151176757 is in [0.029865304487736055172, 0.59413469551226394394]\n",
      "with b 0.28213469551226394 and loss 0.312\n",
      "lt_loss 0.180151176757 is in [0.031172021939880112384, 0.59251218858643550647]\n",
      "with b 0.2806700833232777 and loss 0.3118421052631578\n",
      "lt_loss 0.180151176757 is in [0.038950844210306589943, 0.5974127921533297636]\n",
      "with b 0.2792309739715116 and loss 0.3181818181818182\n",
      "lt_loss 0.180151176757 is in [0.036285951150204664994, 0.59191917705492347324]\n",
      "with b 0.2778166129523594 and loss 0.31410256410256404\n",
      "lt_loss 0.180151176757 is in [0.03496612797065823397, 0.58781868215592403271]\n",
      "with b 0.2764262770926329 and loss 0.31139240506329113\n",
      "lt_loss 0.180151176757 is in [0.038690727116387380047, 0.58880927288361251115]\n",
      "with b 0.2750592728836126 and loss 0.31375\n",
      "lt_loss 0.180151176757 is in [0.0373961761893060185, 0.58482604603291621359]\n",
      "with b 0.2737149349218051 and loss 0.3111111111111111\n",
      "lt_loss 0.180151176757 is in [0.044680546282459543406, 0.58946579518095498784]\n",
      "with b 0.2723926244492477 and loss 0.31707317073170727\n",
      "lt_loss 0.180151176757 is in [0.048185380447826664518, 0.59036883641964310598]\n",
      "with b 0.27109172798590825 and loss 0.3192771084337349\n",
      "lt_loss 0.180151176757 is in [0.045664534428825620527, 0.58528784652355536622]\n",
      "with b 0.26981165604736485 and loss 0.31547619047619047\n",
      "lt_loss 0.180151176757 is in [0.051448158058471138432, 0.58855184194152887489]\n",
      "with b 0.26855184194152887 and loss 0.32\n",
      "lt_loss 0.180151176757 is in [0.050130119826421126739, 0.58475360110381136014]\n",
      "with b 0.2673117406386951 and loss 0.31744186046511624\n",
      "lt_loss 0.180151176757 is in [0.051150551600667670815, 0.58333220702002197555]\n",
      "with b 0.2660908277096771 and loss 0.3172413793103448\n",
      "lt_loss 0.180151176757 is in [0.052156856218242064749, 0.5819340528726670847]\n",
      "with b 0.2648885983272125 and loss 0.3170454545454546\n",
      "lt_loss 0.180151176757 is in [0.058767343786143289019, 0.58617647643857573314]\n",
      "with b 0.26370456632621625 and loss 0.32247191011235954\n",
      "lt_loss 0.180151176757 is in [0.057461736681190145326, 0.58253826331880975697]\n",
      "with b 0.2625382633188098 and loss 0.31999999999999995\n",
      "lt_loss 0.180151176757 is in [0.058390981919840323489, 0.58116945764059924073]\n",
      "with b 0.26138923786037943 and loss 0.31978021978021975\n",
      "lt_loss 0.180151176757 is in [0.06148207577157299708, 0.58199618509799222466]\n",
      "with b 0.26025705466320964 and loss 0.32173913043478264\n",
      "lt_loss 0.180151176757 is in [0.062364082489582084445, 0.58064667019858995367]\n",
      "with b 0.25914129385450396 and loss 0.32150537634408605\n",
      "lt_loss 0.180151176757 is in [0.067490364617763864974, 0.58357346516947017356]\n",
      "with b 0.2580415502758531 and loss 0.325531914893617\n",
      "lt_loss 0.180151176757 is in [0.068305725073307121953, 0.58222059071616649728]\n",
      "with b 0.2569574328214297 and loss 0.3252631578947368\n",
      "lt_loss 0.180151176757 is in [0.073278102854270388278, 0.58505523047906293765]\n",
      "with b 0.2558885638123963 and loss 0.32916666666666666\n",
      "lt_loss 0.180151176757 is in [0.07815511231645022594, 0.58782426912684870857]\n",
      "with b 0.25483457840519924 and loss 0.33298969072164947\n",
      "lt_loss 0.180151176757 is in [0.07681712086636710568, 0.58440736892955125192]\n",
      "with b 0.25379512403159205 and loss 0.33061224489795915\n",
      "lt_loss 0.180151176757 is in [0.077533170434640752422, 0.58307289017141972209]\n",
      "with b 0.2527698598683895 and loss 0.33030303030303027\n",
      "lt_loss 0.180151176757 is in [0.078241543664902379884, 0.58175845633509748467]\n",
      "with b 0.2517584563350976 and loss 0.32999999999999996\n",
      "lt_loss 0.180151176757 is in [0.078942375679331489025, 0.58046356491472783645]\n",
      "with b 0.2507605946176982 and loss 0.32970297029702966\n",
      "lt_loss 0.180151176757 is in [0.077675014175169282415, 0.57722694660914442011]\n",
      "with b 0.24977596621698758 and loss 0.32745098039215687\n",
      "lt_loss 0.180151176757 is in [0.076438445926620718351, 0.57404699096658307056]\n",
      "with b 0.2488042725199812 and loss 0.3252427184466019\n",
      "lt_loss 0.180151176757 is in [0.077154775606999848048, 0.57284522439300000762]\n",
      "with b 0.2478452243930001 and loss 0.32499999999999996\n",
      "lt_loss 0.180151176757 is in [0.077863362966754862127, 0.57166044655705461341]\n",
      "with b 0.2468985417951499 and loss 0.32476190476190475\n",
      "lt_loss 0.180151176757 is in [0.078564348475801237814, 0.57049225529778357924]\n",
      "with b 0.2459639534109912 and loss 0.32452830188679244\n",
      "lt_loss 0.180151176757 is in [0.082996186876289568257, 0.57307857947885043615]\n",
      "with b 0.24504119630128046 and loss 0.32803738317757003\n",
      "lt_loss 0.180151176757 is in [0.083647762207040871063, 0.57190779334851460369]\n",
      "with b 0.24413001557073685 and loss 0.3277777777777777\n",
      "lt_loss 0.180151176757 is in [0.081540478149975947897, 0.56800080625369386844]\n",
      "with b 0.24323016405185893 and loss 0.3247706422018349\n",
      "lt_loss 0.180151176757 is in [0.08038587072339312134, 0.56506867473115240941]\n",
      "with b 0.24234140200387963 and loss 0.32272727272727275\n",
      "lt_loss 0.180151176757 is in [0.081059025696516073811, 0.56398601934852887752]\n",
      "with b 0.24146349682600643 and loss 0.3225225225225225\n",
      "lt_loss 0.180151176757 is in [0.08172520578727762719, 0.56291765135557947364]\n",
      "with b 0.2405962227841509 and loss 0.32232142857142854\n",
      "lt_loss 0.180151176757 is in [0.082384533054910003003, 0.56186325455570940157]\n",
      "with b 0.2397393607503997 and loss 0.3221238938053097\n",
      "lt_loss 0.180151176757 is in [0.083037126606874012147, 0.56082252251593289749]\n",
      "with b 0.23889269795452944 and loss 0.32192982456140345\n",
      "lt_loss 0.180151176757 is in [0.087161363557437726568, 0.56327341905125782873]\n",
      "with b 0.23805602774691006 and loss 0.3252173913043478\n",
      "lt_loss 0.180151176757 is in [0.089494988558851990001, 0.56395328730321692134]\n",
      "with b 0.23722914937218245 and loss 0.32672413793103444\n",
      "lt_loss 0.180151176757 is in [0.090083858742591921276, 0.562907594248861054]\n",
      "with b 0.23641186775313458 and loss 0.3264957264957265\n",
      "lt_loss 0.180151176757 is in [0.090667193156442449364, 0.56187517972491352047]\n",
      "with b 0.23560399328423554 and loss 0.326271186440678\n",
      "lt_loss 0.180151176757 is in [0.089564406264840273897, 0.55917508953347905276]\n",
      "with b 0.2348053416343194 and loss 0.3243697478991597\n",
      "lt_loss 0.180151176757 is in [0.09015093310872501764, 0.55818240022460829941]\n",
      "with b 0.23401573355794164 and loss 0.32416666666666666\n",
      "lt_loss 0.180151176757 is in [0.090731947433799947644, 0.55720193686372054831]\n",
      "with b 0.23323499471496031 and loss 0.32396694214876026\n",
      "lt_loss 0.180151176757 is in [0.08966819204306489266, 0.55459410303890233074]\n",
      "with b 0.2324629554979187 and loss 0.3221311475409836\n",
      "lt_loss 0.180151176757 is in [0.087812744255117369807, 0.55121164598878502616]\n",
      "with b 0.23169945086683386 and loss 0.3195121951219512\n",
      "lt_loss 0.180151176757 is in [0.088410518518661662668, 0.55029915890069325268]\n",
      "with b 0.2309443201910158 and loss 0.31935483870967746\n",
      "lt_loss 0.180151176757 is in [0.087402592902434073086, 0.54779740709756596928]\n",
      "with b 0.23019740709756592 and loss 0.3176\n",
      "lt_loss 0.180151176757 is in [0.088001758134094998365, 0.54691887678653983151]\n",
      "with b 0.22945855932622244 and loss 0.31746031746031744\n",
      "lt_loss 0.180151176757 is in [0.087020402905823246442, 0.54447566008630277068]\n",
      "with b 0.22872762859023976 and loss 0.315748031496063\n",
      "lt_loss 0.180151176757 is in [0.087620529556993398401, 0.54362947044300669042]\n",
      "with b 0.22800447044300665 and loss 0.31562500000000004\n",
      "lt_loss 0.180151176757 is in [0.085889350423519028599, 0.54046723872376767339]\n",
      "with b 0.22728894415012435 and loss 0.3131782945736434\n",
      "lt_loss 0.180151176757 is in [0.088034472048703266145, 0.54119629718206585522]\n",
      "with b 0.2265809125666813 and loss 0.3146153846153846\n",
      "lt_loss 0.180151176757 is in [0.088623574774416347122, 0.54038405881336992742]\n",
      "with b 0.22588024201947676 and loss 0.3145038167938931\n",
      "lt_loss 0.180151176757 is in [0.086934409927255096306, 0.53730801431516905797]\n",
      "with b 0.22518680219395698 and loss 0.3121212121212121\n",
      "lt_loss 0.180151176757 is in [0.089033368560823084037, 0.53803430061210910651]\n",
      "with b 0.22450046602564303 and loss 0.3135338345864661\n",
      "lt_loss 0.180151176757 is in [0.0911042635384886057, 0.53874648273016823019]\n",
      "with b 0.22382110959583978 and loss 0.3149253731343284\n",
      "lt_loss 0.180151176757 is in [0.089443980561165703502, 0.53574120462401952913]\n",
      "with b 0.22314861203142689 and loss 0.3125925925925926\n",
      "lt_loss 0.180151176757 is in [0.092958321062044324545, 0.53792403187913206963]\n",
      "with b 0.2224828554085439 and loss 0.3154411764705882\n",
      "lt_loss 0.180151176757 is in [0.093504742493292852812, 0.53715219181327644726]\n",
      "with b 0.2218237246599918 and loss 0.31532846715328466\n",
      "lt_loss 0.180151176757 is in [0.094046283818167153434, 0.53638849879052852287]\n",
      "with b 0.22117110748618068 and loss 0.31521739130434784\n",
      "lt_loss 0.180151176757 is in [0.092424746018304942963, 0.53347453455723459204]\n",
      "with b 0.22052489426946484 and loss 0.3129496402877698\n",
      "lt_loss 0.180151176757 is in [0.092972164865429501868, 0.53274212084885619323]\n",
      "with b 0.21988497799171333 and loss 0.31285714285714283\n",
      "lt_loss 0.180151176757 is in [0.093514703291837170118, 0.53201721160177972703]\n",
      "with b 0.2192512541549713 and loss 0.31276595744680846\n",
      "lt_loss 0.180151176757 is in [0.094052435632951958411, 0.53129967704310443466]\n",
      "with b 0.21862362070507624 and loss 0.3126760563380282\n",
      "lt_loss 0.180151176757 is in [0.094585434629313097643, 0.53058939054551201853]\n",
      "with b 0.21800197795809947 and loss 0.31258741258741257\n",
      "lt_loss 0.180151176757 is in [0.095113771470510755091, 0.5298862285294891894]\n",
      "with b 0.21738622852948924 and loss 0.3125\n",
      "lt_loss 0.180151176757 is in [0.098396136527304278729, 0.53194869105890252303]\n",
      "with b 0.21677627726579912 and loss 0.3151724137931034\n",
      "lt_loss 0.180151176757 is in [0.098896461971794691337, 0.5312405243295751367]\n",
      "with b 0.21617203117889022 and loss 0.3150684931506849\n",
      "lt_loss 0.180151176757 is in [0.099392587012056221596, 0.53053938577705939128]\n",
      "with b 0.21557339938250158 and loss 0.3149659863945578\n",
      "lt_loss 0.180151176757 is in [0.1025872745364791172, 0.53254786059865599768]\n",
      "with b 0.21498029303108843 and loss 0.31756756756756754\n",
      "lt_loss 0.180151176757 is in [0.10171475728950268858, 0.53050000781116835036]\n",
      "with b 0.21439262526083286 and loss 0.31610738255033555\n",
      "lt_loss 0.180151176757 is in [0.1021896888672644832, 0.52981031113273546751]\n",
      "with b 0.21381031113273552 and loss 0.316\n",
      "lt_loss 0.180151176757 is in [0.10266077215739691231, 0.52912730731280177565]\n",
      "with b 0.21323326757770242 and loss 0.31589403973509933\n",
      "lt_loss 0.180151176757 is in [0.10575963928803491787, 0.53108246597512298592]\n",
      "with b 0.21266141334354402 and loss 0.31842105263157894\n",
      "lt_loss 0.180151176757 is in [0.10620598465096312002, 0.53039532253857935018]\n",
      "with b 0.2120946689438081 and loss 0.3183006535947712\n",
      "lt_loss 0.180151176757 is in [0.10664886157344638518, 0.52971477479019002388]\n",
      "with b 0.2115329566083718 and loss 0.3181818181818182\n",
      "lt_loss 0.180151176757 is in [0.1057979933126655947, 0.5277503937841085957]\n",
      "with b 0.2109762002357215 and loss 0.3167741935483871\n",
      "lt_loss 0.180151176757 is in [0.10624234131981416529, 0.52709099201351916619]\n",
      "with b 0.2104243253468525 and loss 0.31666666666666665\n",
      "lt_loss 0.180151176757 is in [0.10668325051341620568, 0.52643776859486401953]\n",
      "with b 0.2098772590407239 and loss 0.3165605095541401\n",
      "lt_loss 0.180151176757 is in [0.10712076625132524454, 0.52579062615373794998]\n",
      "with b 0.20933492995120637 and loss 0.3164556962025316\n",
      "lt_loss 0.180151176757 is in [0.10755493305239746671, 0.52514946946332574651]\n",
      "with b 0.20879726820546415 and loss 0.3163522012578616\n",
      "lt_loss 0.180151176757 is in [0.10673579461628462939, 0.52326420538371554159]\n",
      "with b 0.20826420538371543 and loss 0.31500000000000006\n",
      "lt_loss 0.180151176757 is in [0.10592892179297599964, 0.52140027075360795283]\n",
      "with b 0.20773567448031596 and loss 0.31366459627329196\n",
      "lt_loss 0.180151176757 is in [0.10636863704746407633, 0.52079185677969630497]\n",
      "with b 0.20721160986611614 and loss 0.3135802469135802\n",
      "lt_loss 0.180151176757 is in [0.10680498526329607056, 0.52018887976737870904]\n",
      "with b 0.20669194725204132 and loss 0.3134969325153374\n",
      "lt_loss 0.180151176757 is in [0.10845752268761449377, 0.5208107699953123948]\n",
      "with b 0.20617662365384892 and loss 0.3146341463414634\n",
      "lt_loss 0.180151176757 is in [0.10887987718743699639, 0.52021103190347217637]\n",
      "with b 0.20566557735801758 and loss 0.3145454545454546\n",
      "lt_loss 0.180151176757 is in [0.10929908343657593339, 0.51961657921402648608]\n",
      "with b 0.20515874788872526 and loss 0.3144578313253012\n",
      "lt_loss 0.180151176757 is in [0.10791877432352603439, 0.51723092627527633702]\n",
      "with b 0.20465607597587515 and loss 0.3125748502994012\n",
      "lt_loss 0.180151176757 is in [0.11072344885682133819, 0.51903845590508335128]\n",
      "with b 0.20415750352413103 and loss 0.3148809523809524\n",
      "lt_loss 0.180151176757 is in [0.11112992582536085351, 0.5184558729912072117]\n",
      "with b 0.20366297358292318 and loss 0.31479289940828403\n",
      "lt_loss 0.180151176757 is in [0.11388639321202168042, 0.52023125384680179994]\n",
      "with b 0.20317243031739005 and loss 0.3170588235294117\n",
      "lt_loss 0.180151176757 is in [0.11427324534726451821, 0.51964488330770630675]\n",
      "with b 0.20268581898022087 and loss 0.3169590643274854\n",
      "lt_loss 0.180151176757 is in [0.11582016992958726886, 0.5202263416983197164]\n",
      "with b 0.2022030858843662 and loss 0.31802325581395346\n",
      "lt_loss 0.180151176757 is in [0.1161948967679238276, 0.51964325352109352885]\n",
      "with b 0.20172417837658485 and loss 0.3179190751445087\n",
      "lt_loss 0.180151176757 is in [0.11944061036061670578, 0.5219386999842108299]\n",
      "with b 0.20124904481179706 and loss 0.32068965517241377\n",
      "lt_loss 0.180151176757 is in [0.11979379404321349734, 0.52134906309964357263]\n",
      "with b 0.20077763452821507 and loss 0.32057142857142856\n",
      "lt_loss 0.180151176757 is in [0.12014464763132257086, 0.52076444327776827414]\n",
      "with b 0.20030989782322287 and loss 0.32045454545454544\n",
      "lt_loss 0.180151176757 is in [0.1187982818666311613, 0.51848985372658917825]\n",
      "with b 0.19984578592997904 and loss 0.3186440677966102\n",
      "lt_loss 0.180151176757 is in [0.12027767035359823722, 0.51904817234303091134]\n",
      "with b 0.19938525099471635 and loss 0.3196629213483146\n",
      "lt_loss 0.180151176757 is in [0.12341812266036888968, 0.52127461476979874977]\n",
      "with b 0.19892824605471493 and loss 0.3223463687150838\n",
      "lt_loss 0.180151176757 is in [0.12208083053863169609, 0.51903028057247935223]\n",
      "with b 0.19847472501692384 and loss 0.32055555555555554\n",
      "lt_loss 0.180151176757 is in [0.12131237393737601127, 0.51736165921179533278]\n",
      "with b 0.19802464263720967 and loss 0.3193370165745857\n",
      "lt_loss 0.180151176757 is in [0.12165281473055891692, 0.51680872373097952455]\n",
      "with b 0.1975779545002103 and loss 0.3192307692307692\n",
      "lt_loss 0.180151176757 is in [0.12417685841006378955, 0.51844609240960837226]\n",
      "with b 0.19713461699977228 and loss 0.32131147540983607\n",
      "lt_loss 0.180151176757 is in [0.12450106485395989742, 0.51789023949386625567]\n",
      "with b 0.19669458731995315 and loss 0.32119565217391305\n",
      "lt_loss 0.180151176757 is in [0.12590433874559420202, 0.51841998557873014697]\n",
      "with b 0.19625782341656794 and loss 0.32216216216216215\n",
      "lt_loss 0.180151176757 is in [0.12514345793622091985, 0.5167920259347468237]\n",
      "with b 0.19582428399926297 and loss 0.3209677419354839\n",
      "lt_loss 0.180151176757 is in [0.12439216774258660125, 0.51518002477078228551]\n",
      "with b 0.19539392851409787 and loss 0.31978609625668447\n",
      "lt_loss 0.180151176757 is in [0.12311838925635884556, 0.51305182350959843696]\n",
      "with b 0.1949667171266198 and loss 0.31808510638297866\n",
      "lt_loss 0.180151176757 is in [0.12344680728400511671, 0.51253202869483083237]\n",
      "with b 0.19454261070541287 and loss 0.317989417989418\n",
      "lt_loss 0.180151176757 is in [0.12272053445705072283, 0.51096367606926507143]\n",
      "with b 0.19412157080610715 and loss 0.31684210526315787\n",
      "lt_loss 0.180151176757 is in [0.12566816809285880074, 0.51307528740452346128]\n",
      "with b 0.1937035596558323 and loss 0.3193717277486911\n",
      "lt_loss 0.180151176757 is in [0.12441979319523216452, 0.51099687347143452065]\n",
      "with b 0.1932885401381012 and loss 0.31770833333333337\n",
      "lt_loss 0.180151176757 is in [0.12474010453277167843, 0.51049305608898998265]\n",
      "with b 0.19287647577810912 and loss 0.3176165803108808\n",
      "lt_loss 0.180151176757 is in [0.12351205071486337506, 0.50844671217173453837]\n",
      "with b 0.19246733072843558 and loss 0.31597938144329896\n",
      "lt_loss 0.180151176757 is in [0.12486200716794149113, 0.50898414667821223478]\n",
      "with b 0.19206106975513537 and loss 0.31692307692307686\n",
      "lt_loss 0.180151176757 is in [0.12517907646967074697, 0.50849439291808440355]\n",
      "with b 0.19165765822420683 and loss 0.3168367346938776\n",
      "lt_loss 0.180151176757 is in [0.12549420694710872182, 0.50800833112395737956]\n",
      "with b 0.1912570620884243 and loss 0.316751269035533\n",
      "lt_loss 0.180151176757 is in [0.126817519802243317, 0.50853601555129213097]\n",
      "with b 0.1908592478745244 and loss 0.3176767676767677\n",
      "lt_loss 0.180151176757 is in [0.12963631984182888424, 0.51056468518329689577]\n",
      "with b 0.190464182670734 and loss 0.3201005025125629\n",
      "lt_loss 0.180151176757 is in [0.12892816588537048261, 0.50907183411462963996]\n",
      "with b 0.19007183411462958 and loss 0.31900000000000006\n",
      "lt_loss 0.180151176757 is in [0.12922330225549860661, 0.50858764301813319531]\n",
      "with b 0.1896821703813173 and loss 0.3189054726368159\n",
      "lt_loss 0.180151176757 is in [0.12951672101619476907, 0.50810704136004303244]\n",
      "with b 0.1892951601719241 and loss 0.3188118811881189\n",
      "lt_loss 0.180151176757 is in [0.12980843912027006937, 0.50762998452505003755]\n",
      "with b 0.18891077270238998 and loss 0.31871921182266005\n",
      "lt_loss 0.180151176757 is in [0.13009847328783996634, 0.50715642867294430385]\n",
      "with b 0.18852897769255217 and loss 0.31862745098039214\n",
      "lt_loss 0.180151176757 is in [0.1303868400103416203, 0.50668633072136581852]\n",
      "with b 0.1881497453555121 and loss 0.3185365853658537\n",
      "lt_loss 0.180151176757 is in [0.13261530312728636583, 0.50816139590183984076]\n",
      "with b 0.18777304638727677 and loss 0.32038834951456313\n",
      "lt_loss 0.180151176757 is in [0.13289100311579751801, 0.50768870702913004855]\n",
      "with b 0.18739885195666625 and loss 0.32028985507246377\n",
      "lt_loss 0.180151176757 is in [0.13220363553529065892, 0.50625790292624772704]\n",
      "with b 0.18702713369547855 and loss 0.3192307692307692\n",
      "lt_loss 0.180151176757 is in [0.13439476789004234369, 0.50771049526785239081]\n",
      "with b 0.18665786368890502 and loss 0.32105263157894737\n",
      "lt_loss 0.180151176757 is in [0.13656612839095466638, 0.50914815732333118525]\n",
      "with b 0.18629101446618823 and loss 0.3228571428571429\n",
      "lt_loss 0.180151176757 is in [0.13871799077151825141, 0.51057110875454803089]\n",
      "with b 0.1859265589915149 and loss 0.32464454976303314\n",
      "lt_loss 0.180151176757 is in [0.13802043500523974995, 0.50914937631551493435]\n",
      "with b 0.1855644706551376 and loss 0.32358490566037734\n",
      "lt_loss 0.180151176757 is in [0.14014738941133847439, 0.51055683594077416743]\n",
      "with b 0.18520472326471782 and loss 0.3253521126760563\n",
      "lt_loss 0.180151176757 is in [0.14038635382292918852, 0.51008093589669700751]\n",
      "with b 0.1848472910368839 and loss 0.3252336448598131\n",
      "lt_loss 0.180151176757 is in [0.14248459559704829136, 0.51146889277504470339]\n",
      "with b 0.1844921485889982 and loss 0.3269767441860465\n",
      "lt_loss 0.180151176757 is in [0.14132369203183661743, 0.50960223389408931816]\n",
      "with b 0.18413927093112634 and loss 0.32546296296296295\n",
      "lt_loss 0.180151176757 is in [0.14063532967543698748, 0.50821259659184403468]\n",
      "with b 0.18378863345820354 and loss 0.3244239631336405\n",
      "lt_loss 0.180151176757 is in [0.1427065770484336471, 0.5095870009332177375]\n",
      "with b 0.18344021194239207 and loss 0.3261467889908257\n",
      "lt_loss 0.180151176757 is in [0.14293341473464984959, 0.50912137978589810938]\n",
      "with b 0.18309398252562412 and loss 0.32602739726027397\n",
      "lt_loss 0.180151176757 is in [0.14315916919676607844, 0.50865901262141577366]\n",
      "with b 0.18274992171232485 and loss 0.3259090909090909\n",
      "lt_loss 0.180151176757 is in [0.14247887146574353401, 0.50729488419036505853]\n",
      "with b 0.18240800636231078 and loss 0.3248868778280543\n",
      "lt_loss 0.180151176757 is in [0.14270656109091667263, 0.50684298845863273719]\n",
      "with b 0.18206821368385806 and loss 0.32477477477477473\n",
      "lt_loss 0.180151176757 is in [0.14472687787620261424, 0.50818792033007542663]\n",
      "with b 0.18173052122693642 and loss 0.32645739910313903\n",
      "lt_loss 0.180151176757 is in [0.14494437883768263031, 0.50773419259088881095]\n",
      "with b 0.1813949068766031 and loss 0.3263392857142857\n",
      "lt_loss 0.180151176757 is in [0.14516087337566846438, 0.5072835710687759736]\n",
      "with b 0.18106134884655378 and loss 0.32622222222222225\n",
      "lt_loss 0.180151176757 is in [0.14537636901744077633, 0.50683602036309016725]\n",
      "with b 0.1807298256728247 and loss 0.32610619469026547\n",
      "lt_loss 0.180151176757 is in [0.14470981595094767336, 0.50551044836623293399]\n",
      "with b 0.18040031620764263 and loss 0.3251101321585903\n",
      "lt_loss 0.180151176757 is in [0.14580439336903794345, 0.50594999259587425389]\n",
      "with b 0.18007279961341816 and loss 0.3258771929824561\n",
      "lt_loss 0.180151176757 is in [0.14470689311473694527, 0.50420140382849443217]\n",
      "with b 0.17974725535687874 and loss 0.3244541484716157\n",
      "lt_loss 0.180151176757 is in [0.14405459766622796813, 0.50290192407290246202]\n",
      "with b 0.17942366320333725 and loss 0.3234782608695652\n",
      "lt_loss 0.180151176757 is in [0.14340881929972987274, 0.50161282572191523421]\n",
      "with b 0.17910200321109265 and loss 0.3225108225108225\n",
      "lt_loss 0.180151176757 is in [0.14276946841197188376, 0.50033397986389016587]\n",
      "with b 0.17878225572595915 and loss 0.32155172413793104\n",
      "lt_loss 0.180151176757 is in [0.1417072724438224185, 0.49863607519566255366]\n",
      "with b 0.17846440137592007 and loss 0.3201716738197425\n",
      "lt_loss 0.180151176757 is in [0.14065499773751530266, 0.49695183986932234266]\n",
      "with b 0.17814842106590353 and loss 0.31880341880341884\n",
      "lt_loss 0.180151176757 is in [0.14088910828264300523, 0.4965577002279953911]\n",
      "with b 0.1778342959726762 and loss 0.3187234042553192\n",
      "lt_loss 0.180151176757 is in [0.14281697551099498122, 0.49786099059069993666]\n",
      "with b 0.17752200753985248 and loss 0.32033898305084746\n",
      "lt_loss 0.180151176757 is in [0.14219774522740652456, 0.49662082017343728291]\n",
      "with b 0.17721153747301538 and loss 0.3194092827004219\n",
      "lt_loss 0.180151176757 is in [0.14158452722303624394, 0.49539026269293007232]\n",
      "with b 0.17690286773494693 and loss 0.31848739495798317\n",
      "lt_loss 0.180151176757 is in [0.14181406130003970656, 0.49500602238196855787]\n",
      "with b 0.17659598054096443 and loss 0.31841004184100413\n",
      "lt_loss 0.180151176757 is in [0.14370914164563966531, 0.49629085835436037577]\n",
      "with b 0.17629085835436034 and loss 0.32\n",
      "lt_loss 0.180151176757 is in [0.14309965304751773307, 0.49507462081140352073]\n",
      "with b 0.17598748388194288 and loss 0.3190871369294606\n",
      "lt_loss 0.180151176757 is in [0.14208275497164768453, 0.49345443511099695844]\n",
      "with b 0.17568584006967464 and loss 0.3177685950413223\n",
      "lt_loss 0.180151176757 is in [0.14230956315262219269, 0.49308138334943540926]\n",
      "with b 0.17538591009840662 and loss 0.3176954732510288\n",
      "lt_loss 0.180151176757 is in [0.14130576524324503507, 0.49148112000265664623]\n",
      "with b 0.1750876773797058 and loss 0.3163934426229508\n",
      "lt_loss 0.180151176757 is in [0.14153540506047215808, 0.49111765616401759083]\n",
      "with b 0.1747911255517727 and loss 0.31632653061224486\n",
      "lt_loss 0.180151176757 is in [0.14176392412617797034, 0.49075640107707407811]\n",
      "with b 0.17449623847544807 and loss 0.31626016260162604\n",
      "lt_loss 0.180151176757 is in [0.14280104835269108454, 0.49120704881330073954]\n",
      "with b 0.17420300023030483 and loss 0.3170040485829959\n",
      "lt_loss 0.180151176757 is in [0.14302408876014321981, 0.49084687898179230059]\n",
      "with b 0.17391139511082454 and loss 0.31693548387096776\n",
      "lt_loss 0.180151176757 is in [0.14244284940545709484, 0.48968566465076784899]\n",
      "with b 0.17362140762265538 and loss 0.31606425702811247\n",
      "lt_loss 0.180151176757 is in [0.14266697752105006458, 0.48933302247894994164]\n",
      "with b 0.17333302247894994 and loss 0.316\n",
      "lt_loss 0.180151176757 is in [0.14169481125979321856, 0.48778726045335418782]\n",
      "with b 0.17304622459678048 and loss 0.3147410358565737\n",
      "lt_loss 0.180151176757 is in [0.14073106439843321991, 0.48625306258569378492]\n",
      "with b 0.17276099909363027 and loss 0.3134920634920635\n",
      "lt_loss 0.180151176757 is in [0.14254243156189144726, 0.4874970941298081839]\n",
      "with b 0.17247733128395837 and loss 0.3150197628458498\n",
      "lt_loss 0.180151176757 is in [0.14197802167061968071, 0.48636843502229365477]\n",
      "with b 0.172195206675837 and loss 0.31417322834645667\n",
      "lt_loss 0.180151176757 is in [0.14141872236567479271, 0.48524794430099182918]\n",
      "with b 0.1719146109676585 and loss 0.3133333333333333\n",
      "lt_loss 0.180151176757 is in [0.14320821995508864477, 0.48647928004491142184]\n",
      "with b 0.1716355300449114 and loss 0.31484375000000003\n",
      "lt_loss 0.180151176757 is in [0.14420625235760764493, 0.48692215231165303368]\n",
      "with b 0.1713579499770227 and loss 0.31556420233463034\n",
      "lt_loss 0.180151176757 is in [0.14519721275317587494, 0.48736092678170783721]\n",
      "with b 0.17108185701426598 and loss 0.31627906976744186\n",
      "lt_loss 0.180151176757 is in [0.14540897863148358193, 0.48702345380094891336]\n",
      "with b 0.17080723758473268 and loss 0.31621621621621626\n",
      "lt_loss 0.180151176757 is in [0.14715822940094230864, 0.4882263859836731279]\n",
      "with b 0.1705340782913654 and loss 0.3176923076923077\n",
      "lt_loss 0.180151176757 is in [0.14889472221355326553, 0.48941945403165743045]\n",
      "with b 0.17026236590905208 and loss 0.31915708812260535\n",
      "lt_loss 0.180151176757 is in [0.14909188208386986441, 0.48907605684742788688]\n",
      "with b 0.169992087381779 and loss 0.3190839694656489\n",
      "lt_loss 0.180151176757 is in [0.150048633298029227, 0.48949509293771220619]\n",
      "with b 0.16972322981984148 and loss 0.3197718631178707\n",
      "lt_loss 0.180151176757 is in [0.15099876495743450033, 0.48991032595165640018]\n",
      "with b 0.16945578049711094 and loss 0.32045454545454544\n",
      "lt_loss 0.180151176757 is in [0.15118763164220913597, 0.48956708533892290269]\n",
      "with b 0.1691897268483569 and loss 0.32037735849056603\n",
      "lt_loss 0.180151176757 is in [0.15062381571382840728, 0.48847392864707372961]\n",
      "with b 0.16892505646662268 and loss 0.3195488721804511\n",
      "lt_loss 0.180151176757 is in [0.15156296200047045253, 0.48888647620177672071]\n",
      "with b 0.16866175710065315 and loss 0.3202247191011236\n",
      "lt_loss 0.180151176757 is in [0.15174943707896915157, 0.4885490703837174209]\n",
      "with b 0.16839981665237413 and loss 0.3201492537313433\n",
      "lt_loss 0.180151176757 is in [0.1519351262679579373, 0.48821357261680053963]\n",
      "with b 0.1681392231744213 and loss 0.3200743494423792\n",
      "lt_loss 0.180151176757 is in [0.15212003513228194995, 0.48787996486771806337]\n",
      "with b 0.16787996486771806 and loss 0.32\n",
      "lt_loss 0.180151176757 is in [0.15230416918289158001, 0.48754822934109365296]\n",
      "with b 0.16762203007910104 and loss 0.3199261992619926\n",
      "lt_loss 0.180151176757 is in [0.15322282799512554341, 0.48795364259310969324]\n",
      "with b 0.16736540729899207 and loss 0.3205882352941176\n",
      "lt_loss 0.180151176757 is in [0.15267013462110415323, 0.48689030493933538324]\n",
      "with b 0.1671100851591156 and loss 0.31978021978021975\n",
      "lt_loss 0.180151176757 is in [0.15285197676681980261, 0.48656408162734077205]\n",
      "with b 0.1668560524302605 and loss 0.3197080291970803\n",
      "lt_loss 0.180151176757 is in [0.15230579288900558677, 0.48551238892917625289]\n",
      "with b 0.16660329802008533 and loss 0.3189090909090909\n",
      "lt_loss 0.180151176757 is in [0.15248876873917899255, 0.48519239068111091884]\n",
      "with b 0.16635181097096596 and loss 0.31884057971014496\n",
      "lt_loss 0.180151176757 is in [0.15194896105836097622, 0.48415212197412993422]\n",
      "with b 0.16610158045788448 and loss 0.31805054151624546\n",
      "lt_loss 0.180151176757 is in [0.15213301572443257981, 0.48383820729715010245]\n",
      "with b 0.16585259578635878 and loss 0.31798561151079136\n",
      "lt_loss 0.180151176757 is in [0.15159945468485722109, 0.48280914746568026619]\n",
      "with b 0.16560484639041154 and loss 0.31720430107526876\n",
      "lt_loss 0.180151176757 is in [0.15178453531227908968, 0.48250117897343514084]\n",
      "with b 0.16535832183057803 and loss 0.3171428571428571\n",
      "lt_loss 0.180151176757 is in [0.15196883874185634911, 0.48219486232575931028]\n",
      "with b 0.16511301179195148 and loss 0.31708185053380783\n",
      "lt_loss 0.180151176757 is in [0.15144315065532290565, 0.48118096281985434093]\n",
      "with b 0.1648689060822657 and loss 0.3163120567375886\n",
      "lt_loss 0.180151176757 is in [0.15056835165973916912, 0.47982034091976621948]\n",
      "with b 0.1646259946300135 and loss 0.3151943462897527\n",
      "lt_loss 0.180151176757 is in [0.14970023955965272577, 0.47846877452485425675]\n",
      "with b 0.16438426748260077 and loss 0.3140845070422535\n",
      "lt_loss 0.180151176757 is in [0.14883874133581612154, 0.47712617094488551928]\n",
      "with b 0.16414371480453468 and loss 0.3129824561403508\n",
      "lt_loss 0.180151176757 is in [0.14903273606141675955, 0.47684138981270907109]\n",
      "with b 0.16390432687564616 and loss 0.3129370629370629\n",
      "lt_loss 0.180151176757 is in [0.14922589197337279843, 0.47655808015206269079]\n",
      "with b 0.16366609408934493 and loss 0.31289198606271773\n",
      "lt_loss 0.180151176757 is in [0.15080710416020398634, 0.47766511806201822354]\n",
      "with b 0.16342900695090712 and loss 0.3142361111111111\n",
      "lt_loss 0.180151176757 is in [0.15237787818026099496, 0.47876399033184974252]\n",
      "with b 0.16319305607579437 and loss 0.31557093425605537\n",
      "lt_loss 0.180151176757 is in [0.15393831953613390517, 0.479854783912141869]\n",
      "with b 0.16295823218800398 and loss 0.3168965517241379\n",
      "lt_loss 0.180151176757 is in [0.15548853230079492937, 0.48093758453769297478]\n",
      "with b 0.16272452611844904 and loss 0.31821305841924397\n",
      "lt_loss 0.180151176757 is in [0.15565875612813853679, 0.48064261373487526807]\n",
      "with b 0.16249192880336835 and loss 0.3181506849315069\n",
      "lt_loss 0.180151176757 is in [0.15514571206194463504, 0.47966657462747519514]\n",
      "with b 0.16226043128276527 and loss 0.3174061433447099\n",
      "lt_loss 0.180151176757 is in [0.15531691407663544835, 0.47937696347438490951]\n",
      "with b 0.16203002469887473 and loss 0.3173469387755102\n",
      "lt_loss 0.180151176757 is in [0.15548743529856209888, 0.47908883588787853913]\n",
      "with b 0.16180070029465823 and loss 0.31728813559322033\n",
      "lt_loss 0.180151176757 is in [0.15700863166875544952, 0.48015353049340669944]\n",
      "with b 0.16157244941232562 and loss 0.3185810810810811\n",
      "lt_loss 0.180151176757 is in [0.15852005637343613564, 0.48121058335720356958]\n",
      "with b 0.16134526349188372 and loss 0.31986531986531985\n",
      "lt_loss 0.180151176757 is in [0.15867952364840998136, 0.48091779178783156112]\n",
      "with b 0.1611191340697108 and loss 0.31979865771812077\n",
      "lt_loss 0.180151176757 is in [0.15883838869441560537, 0.48062649424872816439]\n",
      "with b 0.16089405277715627 and loss 0.31973244147157187\n",
      "lt_loss 0.180151176757 is in [0.15832998866083411449, 0.47967001133916575828]\n",
      "with b 0.16067001133916584 and loss 0.31899999999999995\n",
      "lt_loss 0.180151176757 is in [0.15915432733072398808, 0.48004833047658490575]\n",
      "with b 0.16044700157293046 and loss 0.31960132890365445\n",
      "lt_loss 0.180151176757 is in [0.15931140845450023069, 0.47976143922761893545]\n",
      "with b 0.16022501538655934 and loss 0.31953642384105957\n",
      "lt_loss 0.180151176757 is in [0.15880783641034232345, 0.47881592596589528377]\n",
      "with b 0.1600040447777765 and loss 0.3188118811881188\n",
      "lt_loss 0.180151176757 is in [0.15830802343051791903, 0.47787618709579776644]\n",
      "with b 0.15978408183263992 and loss 0.31809210526315784\n",
      "lt_loss 0.180151176757 is in [0.15846766816096272135, 0.47759790560952919414]\n",
      "with b 0.15956511872428322 and loss 0.31803278688524594\n",
      "lt_loss 0.180151176757 is in [0.16026069542557552783, 0.47895499084893422559]\n",
      "with b 0.15934714771167935 and loss 0.3196078431372549\n",
      "lt_loss 0.180151176757 is in [0.15976234700489688745, 0.47802266928174808047]\n",
      "with b 0.1591301611384256 and loss 0.3188925081433225\n",
      "lt_loss 0.180151176757 is in [0.15991701739961897144, 0.47774532026271865348]\n",
      "with b 0.15891415143154983 and loss 0.3188311688311688\n",
      "lt_loss 0.180151176757 is in [0.16136561381875672017, 0.47876383601943106605]\n",
      "with b 0.15869911110033716 and loss 0.3200647249190939\n",
      "lt_loss 0.180151176757 is in [0.16280528984546824289, 0.47977535531582204964]\n",
      "with b 0.15848503273517692 and loss 0.32129032258064516\n",
      "lt_loss 0.180151176757 is in [0.16359304276205927087, 0.48013686077491829485]\n",
      "with b 0.1582719090064295 and loss 0.3218649517684888\n",
      "lt_loss 0.180151176757 is in [0.16501719041361068152, 0.48113665574023539717]\n",
      "with b 0.15805973266331236 and loss 0.32307692307692304\n",
      "lt_loss 0.180151176757 is in [0.16643265362693931975, 0.48212964669254948502]\n",
      "with b 0.15784849653280508 and loss 0.3242811501597444\n",
      "lt_loss 0.180151176757 is in [0.16656562813747771701, 0.48184201517462416087]\n",
      "with b 0.15763819351857322 and loss 0.32420382165605094\n",
      "lt_loss 0.180151176757 is in [0.16669816752707383722, 0.48155580072689435633]\n",
      "with b 0.15742881659991026 and loss 0.3241269841269841\n",
      "lt_loss 0.180151176757 is in [0.16683027408069514563, 0.48127099174208964882]\n",
      "with b 0.15722035883069727 and loss 0.3240506329113924\n",
      "lt_loss 0.180151176757 is in [0.16759286489505814677, 0.48161849157181885195]\n",
      "with b 0.15701281333838035 and loss 0.3246056782334385\n",
      "lt_loss 0.180151176757 is in [0.16709319774621717025, 0.4807055443921475768]\n",
      "with b 0.1568061733229652 and loss 0.3238993710691824\n",
      "lt_loss 0.180151176757 is in [0.1665970601069812207, 0.47979792421903749711]\n",
      "with b 0.15660043205602814 and loss 0.32319749216300936\n",
      "lt_loss 0.180151176757 is in [0.16672941712025571293, 0.47952058287974441697]\n",
      "with b 0.15639558287974434 and loss 0.32312500000000005\n",
      "lt_loss 0.180151176757 is in [0.16686134029562621484, 0.47924457870748898847]\n",
      "with b 0.1561916192059314 and loss 0.3230529595015576\n",
      "lt_loss 0.180151176757 is in [0.16699283194451805534, 0.47896990097473668424]\n",
      "with b 0.15598853451510933 and loss 0.3229813664596274\n",
      "lt_loss 0.180151176757 is in [0.16712389436269026177, 0.47869653907384224212]\n",
      "with b 0.155786322355576 and loss 0.32291021671826625\n",
      "lt_loss 0.180151176757 is in [0.16848909773157647041, 0.47965905041657153074]\n",
      "with b 0.15558497634249754 and loss 0.324074074074074\n",
      "lt_loss 0.180151176757 is in [0.16800012522760143785, 0.4787691055416293251]\n",
      "with b 0.15538449015701394 and loss 0.3233846153846154\n",
      "lt_loss 0.180151176757 is in [0.16812802589022343702, 0.47849774098094211006]\n",
      "with b 0.15518485754535935 and loss 0.3233128834355828\n",
      "lt_loss 0.180151176757 is in [0.16947875948628501885, 0.47945090412227764354]\n",
      "with b 0.1549860723179963 and loss 0.3244648318042813\n",
      "lt_loss 0.180151176757 is in [0.17021187165123538576, 0.47978812834876460869]\n",
      "with b 0.15478812834876463 and loss 0.325\n",
      "lt_loss 0.180151176757 is in [0.16942113848066747694, 0.47860317762875498326]\n",
      "with b 0.15459101957404375 and loss 0.32401215805471123\n",
      "lt_loss 0.180151176757 is in [0.16954465394746526252, 0.47833413393132268032]\n",
      "with b 0.1543947399919287 and loss 0.32393939393939397\n",
      "lt_loss 0.180151176757 is in [0.1690635562177346396, 0.47746212354057349092]\n",
      "with b 0.1541992836614194 and loss 0.32326283987915405\n",
      "lt_loss 0.180151176757 is in [0.16828451192488314003, 0.47629380132812892956]\n",
      "with b 0.1540046447016229 and loss 0.32228915662650603\n",
      "lt_loss 0.180151176757 is in [0.16901200553185424802, 0.47663364011379139029]\n",
      "with b 0.15381081729096857 and loss 0.3228228228228228\n",
      "lt_loss 0.180151176757 is in [0.16973549774673793444, 0.47697108907960938939]\n",
      "with b 0.1536177956664357 and loss 0.32335329341317365\n",
      "lt_loss 0.180151176757 is in [0.16985800796675867841, 0.47670915621234577486]\n",
      "with b 0.15342557412279353 and loss 0.3232835820895522\n",
      "lt_loss 0.180151176757 is in [0.17117061489290882892, 0.47763890891661497928]\n",
      "with b 0.1532341470118531 and loss 0.3244047619047619\n",
      "lt_loss 0.180151176757 is in [0.17188230728200759589, 0.47796932476547016044]\n",
      "with b 0.15304350874173128 and loss 0.3249258160237389\n",
      "lt_loss 0.180151176757 is in [0.17199841722979075653, 0.47770572478204359479]\n",
      "with b 0.15285365377612642 and loss 0.3248520710059172\n",
      "lt_loss 0.180151176757 is in [0.17329412543129185664, 0.47862327869850163076]\n",
      "with b 0.1526645766336049 and loss 0.32595870206489674\n",
      "lt_loss 0.180151176757 is in [0.17340608105427685048, 0.47835862482807606222]\n",
      "with b 0.1524762718868996 and loss 0.32588235294117646\n",
      "lt_loss 0.180151176757 is in [0.17469073797854350882, 0.47926820630298139214]\n",
      "with b 0.15228873416221894 and loss 0.32697947214076245\n",
      "lt_loss 0.180151176757 is in [0.17421383133511761376, 0.47841774761225075441]\n",
      "with b 0.15210195813856656 and loss 0.32631578947368417\n",
      "lt_loss 0.180151176757 is in [0.17548930926633887761, 0.47932118636048326454]\n",
      "with b 0.1519159385470722 and loss 0.32740524781341107\n",
      "lt_loss 0.180151176757 is in [0.17472281820176088774, 0.47818415854242518614]\n",
      "with b 0.15173067017033215 and loss 0.32645348837209304\n",
      "lt_loss 0.180151176757 is in [0.17541037389736960361, 0.47850266958089127112]\n",
      "with b 0.15154614784176082 and loss 0.3269565217391304\n",
      "lt_loss 0.180151176757 is in [0.17551624627181156013, 0.47824097916171443012]\n",
      "with b 0.15136236644495143 and loss 0.326878612716763\n",
      "lt_loss 0.180151176757 is in [0.17504546294862433076, 0.47740410477471872941]\n",
      "with b 0.1511793209130472 and loss 0.32622478386167153\n",
      "lt_loss 0.180151176757 is in [0.17515241905923456534, 0.47714643151547803113]\n",
      "with b 0.15099700622812173 and loss 0.3261494252873563\n",
      "lt_loss 0.180151176757 is in [0.17468601524418697624, 0.47631685008532592684]\n",
      "with b 0.15081541742056948 and loss 0.32550143266475645\n",
      "lt_loss 0.180151176757 is in [0.1747940218600668727, 0.47606312099707603913]\n",
      "with b 0.15063454956850458 and loss 0.32542857142857146\n",
      "lt_loss 0.180151176757 is in [0.17604132869855659838, 0.47695012429289640465]\n",
      "with b 0.1504543977971699 and loss 0.3264957264957265\n",
      "lt_loss 0.180151176757 is in [0.17614549726710038158, 0.47669541182380870126]\n",
      "with b 0.15027495727835416 and loss 0.32642045454545454\n",
      "lt_loss 0.180151176757 is in [0.176249385835337391, 0.47644183229497422127]\n",
      "with b 0.15009622322981842 and loss 0.3263456090651558\n",
      "lt_loss 0.180151176757 is in [0.17748293902877171346, 0.47731932085823386425]\n",
      "with b 0.14991819091473108 and loss 0.3274011299435028\n",
      "lt_loss 0.180151176757 is in [0.17870984858424088237, 0.47819155986646333378]\n",
      "with b 0.14974085564111123 and loss 0.3284507042253521\n",
      "lt_loss 0.180151176757 is in [0.17880657375557346134, 0.47793499927813448691]\n",
      "with b 0.1495642127612805 and loss 0.328370786516854\n",
      "lt_loss 0.180151176757 is in [0.17890305885528734464, 0.47767957419793394269]\n",
      "with b 0.1493882576713233 and loss 0.32829131652661064\n",
      "lt_loss 0.180151176757 is in [0.17899930469223879204, 0.47742527631334774618]\n",
      "with b 0.14921298581055448 and loss 0.32821229050279327\n",
      "lt_loss 0.180151176757 is in [0.17909531207438025846, 0.477172097396371786]\n",
      "with b 0.14903839266099575 and loss 0.328133704735376\n",
      "lt_loss 0.180151176757 is in [0.17919108180869627867, 0.47692002930241483849]\n",
      "with b 0.14886447374685927 and loss 0.32805555555555554\n",
      "lt_loss 0.180151176757 is in [0.17928661470114110044, 0.47666906396921898681]\n",
      "with b 0.14869122463403894 and loss 0.32797783933518004\n",
      "lt_loss 0.180151176757 is in [0.17938191155657823295, 0.47641919341579752611]\n",
      "with b 0.14851864092960965 and loss 0.3279005524861879\n",
      "lt_loss 0.24173596897 is in [0.091047221112606158133, 0.38774065767527265969]\n",
      "with b 0.14834671828133325 and loss 0.2393939393939394\n",
      "lt_loss 0.180151176757 is in [0.18012125091953101741, 0.47647215567387557478]\n",
      "with b 0.14817545237717228 and loss 0.3282967032967033\n",
      "lt_loss 0.24173596897 is in [0.092543106260668861474, 0.38855278415029009809]\n",
      "with b 0.14800483894481062 and loss 0.24054794520547948\n",
      "lt_loss 0.24173596897 is in [0.093421956849911835796, 0.38909170435227391494]\n",
      "with b 0.14783487375118104 and loss 0.24125683060109288\n",
      "lt_loss 0.24173596897 is in [0.092933902438872062479, 0.38826500764287180667]\n",
      "with b 0.14766555260199987 and loss 0.24059945504087193\n",
      "lt_loss 0.24173596897 is in [0.092448780832604715574, 0.38744252351522129318]\n",
      "with b 0.1474968713413083 and loss 0.239945652173913\n",
      "lt_loss 0.24173596897 is in [0.092237569812936515135, 0.38689522151497679481]\n",
      "with b 0.14732882585102014 and loss 0.23956639566395665\n",
      "lt_loss 0.24173596897 is in [0.092027777138712657523, 0.3863506012396656919]\n",
      "with b 0.14716141205047653 and loss 0.2391891891891892\n",
      "lt_loss 0.180151176757 is in [0.17995955200156740772, 0.47394880379358073075]\n",
      "with b 0.14699462589600668 and loss 0.3269541778975741\n",
      "lt_loss 0.180151176757 is in [0.18005325704961241962, 0.47371018381060270297]\n",
      "with b 0.14682846338049513 and loss 0.32688172043010755\n",
      "lt_loss 0.24173596897 is in [0.093551556678841130132, 0.38687739774475132792]\n",
      "with b 0.1466629205329551 and loss 0.24021447721179623\n",
      "lt_loss 0.24173596897 is in [0.093074199095261017645, 0.38607018593147690577]\n",
      "with b 0.14649799341810796 and loss 0.23957219251336898\n",
      "lt_loss 0.24173596897 is in [0.092599655197364544312, 0.38526701146930208974]\n",
      "with b 0.1463336781359688 and loss 0.23893333333333333\n",
      "lt_loss 0.24173596897 is in [0.093989603646647296165, 0.38632954528952290207]\n",
      "with b 0.1461699708214378 and loss 0.24015957446808509\n",
      "lt_loss 0.24173596897 is in [0.093515678775200838935, 0.3855294140629954569]\n",
      "with b 0.1460068676438973 and loss 0.23952254641909815\n",
      "lt_loss 0.24173596897 is in [0.094102725140275150784, 0.38579145475390475006]\n",
      "with b 0.14584436480681479 and loss 0.23994708994708994\n",
      "lt_loss 0.24173596897 is in [0.093631525621514166691, 0.38499644271621669134]\n",
      "with b 0.14568245854735126 and loss 0.23931398416886543\n",
      "lt_loss 0.24173596897 is in [0.094215696969287915374, 0.38525798724123838657]\n",
      "with b 0.14552114513597525 and loss 0.23973684210526316\n",
      "lt_loss 0.24173596897 is in [0.093747190672474167705, 0.38446803242463867267]\n",
      "with b 0.14536042087608225 and loss 0.23910761154855642\n",
      "lt_loss 0.24173596897 is in [0.093281393289050829054, 0.38368195749628947189]\n",
      "with b 0.14520028210361932 and loss 0.23848167539267015\n",
      "lt_loss 0.24173596897 is in [0.094645958886391878817, 0.38472740925982218396]\n",
      "with b 0.14504072518671515 and loss 0.23968668407310703\n",
      "lt_loss 0.24173596897 is in [0.096003670141351554745, 0.38576716319198178784]\n",
      "with b 0.14488174652531513 and loss 0.24088541666666669\n",
      "lt_loss 0.24173596897 is in [0.095796137968659045292, 0.38524282307030199846]\n",
      "with b 0.14472334255082148 and loss 0.24051948051948052\n",
      "lt_loss 0.24173596897 is in [0.097144334833847045818, 0.38627535428532389084]\n",
      "with b 0.14456550972573842 and loss 0.24170984455958547\n",
      "lt_loss 0.24173596897 is in [0.097969016438589906492, 0.38678550552523432993]\n",
      "with b 0.1444082445433222 and loss 0.24237726098191212\n",
      "lt_loss 0.24173596897 is in [0.097501033792351532448, 0.38600412084682372837]\n",
      "with b 0.1442515435272361 and loss 0.24175257731958763\n",
      "lt_loss 0.24173596897 is in [0.098835188028430165375, 0.3870259944908500116]\n",
      "with b 0.14409540323120992 and loss 0.2429305912596401\n",
      "lt_loss 0.24173596897 is in [0.10016274386385987105, 0.38804238434126836488]\n",
      "with b 0.14393982023870425 and loss 0.24410256410256412\n",
      "lt_loss 0.24173596897 is in [0.10071648760979906578, 0.38828606993495795585]\n",
      "with b 0.14378479116257945 and loss 0.2445012787723785\n",
      "lt_loss 0.24173596897 is in [0.1002472383756392027, 0.38750786366517714354]\n",
      "with b 0.14363031264476897 and loss 0.24387755102040817\n",
      "lt_loss 0.24173596897 is in [0.099780616099513580464, 0.38673337881142788586]\n",
      "with b 0.14347638135595717 and loss 0.24325699745547075\n",
      "lt_loss 0.24173596897 is in [0.10109324965956076325, 0.38773923765008388997]\n",
      "with b 0.14332299399526158 and loss 0.24441624365482234\n",
      "lt_loss 0.24173596897 is in [0.10239947296324511394, 0.38873976754308392501]\n",
      "with b 0.14317014728991942 and loss 0.24556962025316453\n",
      "lt_loss 0.24173596897 is in [0.10218418220704195143, 0.38821985819699839082]\n",
      "with b 0.14301783799497822 and loss 0.24520202020202017\n",
      "lt_loss 0.24173596897 is in [0.10348154415990587496, 0.3892136699458874638]\n",
      "with b 0.1428660628929908 and loss 0.24634760705289668\n",
      "lt_loss 0.24173596897 is in [0.10301382442236603487, 0.38844346200979473771]\n",
      "with b 0.14271481879371437 and loss 0.2457286432160804\n",
      "lt_loss 0.24173596897 is in [0.1025486794210738184, 0.38767688448870057938]\n",
      "with b 0.14256410253381338 and loss 0.2451127819548872\n",
      "lt_loss 0.24173596897 is in [0.10333608902343335845, 0.38816391097656666176]\n",
      "with b 0.14241391097656667 and loss 0.24575000000000002\n",
      "lt_loss 0.24173596897 is in [0.1028729160956536326, 0.38740139811881019183]\n",
      "with b 0.14226424101157828 and loss 0.2451371571072319\n",
      "lt_loss 0.24173596897 is in [0.10241227362958724156, 0.38664245273857189567]\n",
      "with b 0.14211508955449234 and loss 0.24452736318407958\n",
      "lt_loss 0.24173596897 is in [0.10195414198678731665, 0.38588704908021015383]\n",
      "with b 0.14196645354671142 and loss 0.24392059553349874\n",
      "lt_loss 0.24173596897 is in [0.10273612549042554498, 0.38637278540066355426]\n",
      "with b 0.141818329955119 and loss 0.24455445544554455\n",
      "lt_loss 0.24173596897 is in [0.10400829657387369864, 0.38734972811748435984]\n",
      "with b 0.14167071577180532 and loss 0.24567901234567902\n",
      "lt_loss 0.24173596897 is in [0.10379658903053812224, 0.38684380505813176221]\n",
      "with b 0.14152360801379682 and loss 0.24532019704433494\n",
      "lt_loss 0.24173596897 is in [0.10456894222315646359, 0.38732294966873537234]\n",
      "with b 0.14137700372278947 and loss 0.24594594594594593\n",
      "lt_loss 0.24173596897 is in [0.10411223729001681249, 0.38657403721978711442]\n",
      "with b 0.14123089996488516 and loss 0.24534313725490198\n",
      "lt_loss 0.24173596897 is in [0.10365798245328669558, 0.385828570113950442]\n",
      "with b 0.14108529383033186 and loss 0.24474327628361855\n",
      "lt_loss 0.24173596897 is in [0.10320615903014765391, 0.38508652389668163174]\n",
      "with b 0.14094018243326698 and loss 0.24414634146341463\n",
      "lt_loss 0.24173596897 is in [0.10275674852405888848, 0.3843478743469872505]\n",
      "with b 0.1407955629114642 and loss 0.24355231143552308\n",
      "lt_loss 0.24173596897 is in [0.10230973262246020883, 0.38361259747462717051]\n",
      "with b 0.14065143242608347 and loss 0.24296116504854368\n",
      "lt_loss 0.24173596897 is in [0.10210722394511317912, 0.38312280026796191601]\n",
      "with b 0.14050778816142437 and loss 0.24261501210653755\n",
      "lt_loss 0.24173596897 is in [0.10166435818256383539, 0.38239361283192896401]\n",
      "with b 0.14036462732468255 and loss 0.24202898550724639\n",
      "lt_loss 0.24173596897 is in [0.10218769140850744725, 0.38263158569992627989]\n",
      "with b 0.1402219471457094 and loss 0.24240963855421685\n",
      "lt_loss 0.24173596897 is in [0.10198756281553308933, 0.38214705256908232389]\n",
      "with b 0.14007974487677463 and loss 0.24206730769230772\n",
      "lt_loss 0.24173596897 is in [0.10346725798704431432, 0.38334329357170865427]\n",
      "with b 0.13993801779233217 and loss 0.24340527577937648\n",
      "lt_loss 0.24173596897 is in [0.10302620331838813206, 0.38261972969596597105]\n",
      "with b 0.13979676318878892 and loss 0.24282296650717705\n",
      "lt_loss 0.24173596897 is in [0.10354211230784779452, 0.38285406907640040508]\n",
      "with b 0.13965597838427632 and loss 0.2431980906921241\n",
      "lt_loss 0.24173596897 is in [0.10310338690062251232, 0.38213470833747276156]\n",
      "with b 0.1395156607184251 and loss 0.24261904761904762\n",
      "lt_loss 0.24173596897 is in [0.10290447748348680035, 0.3816560925877721111]\n",
      "with b 0.13937580755214266 and loss 0.24228028503562946\n",
      "lt_loss 0.24173596897 is in [0.10270671169469181017, 0.38117954422947875059]\n",
      "with b 0.13923641626739347 and loss 0.24194312796208528\n",
      "lt_loss 0.24173596897 is in [0.10227367412545293468, 0.38046864265941704453]\n",
      "with b 0.13909748426698204 and loss 0.24137115839243498\n",
      "lt_loss 0.24173596897 is in [0.10184287781811407481, 0.3797608957667915619]\n",
      "with b 0.13895900897433874 and loss 0.24080188679245282\n",
      "lt_loss 0.24173596897 is in [0.10235548275492686865, 0.37999745842154375453]\n",
      "with b 0.13882098783330846 and loss 0.24117647058823533\n",
      "lt_loss 0.24173596897 is in [0.10192691033055609195, 0.37929374694643913646]\n",
      "with b 0.13868341830794154 and loss 0.24061032863849763\n",
      "lt_loss 0.24173596897 is in [0.10313988478750152344, 0.38023248055207697904]\n",
      "with b 0.13854629788228773 and loss 0.24168618266978925\n",
      "lt_loss 0.24173596897 is in [0.10434738528560197346, 0.38116663340598677667]\n",
      "with b 0.13840962406019242 and loss 0.2427570093457944\n",
      "lt_loss 0.24173596897 is in [0.10415084805914667787, 0.3806976367893381008]\n",
      "with b 0.13827339436509573 and loss 0.2424242424242424\n",
      "lt_loss 0.24173596897 is in [0.10372285877644543683, 0.37999807145611269599]\n",
      "with b 0.13813760633983363 and loss 0.24186046511627907\n",
      "lt_loss 0.24173596897 is in [0.10492117632826786222, 0.38092569142115201286]\n",
      "with b 0.13800225754644208 and loss 0.24292343387470994\n",
      "lt_loss 0.24173596897 is in [0.10611413591551838165, 0.38184882704744460558]\n",
      "with b 0.1378673455659631 and loss 0.2439814814814815\n",
      "lt_loss 0.24173596897 is in [0.10568514585855928734, 0.38115088185506662555]\n",
      "with b 0.13773286799825366 and loss 0.24341801385681294\n",
      "lt_loss 0.24173596897 is in [0.10687122362115278329, 0.38206886854474586546]\n",
      "with b 0.13759882246179653 and loss 0.2444700460829493\n",
      "lt_loss 0.24173596897 is in [0.10644283938349768937, 0.3813732525705252896]\n",
      "with b 0.1374652065935138 and loss 0.2439080459770115\n",
      "lt_loss 0.24173596897 is in [0.10601660580462857197, 0.380680641901793404]\n",
      "with b 0.13733201804858242 and loss 0.243348623853211\n",
      "lt_loss 0.24173596897 is in [0.10582134046542279737, 0.38021984946592729537]\n",
      "with b 0.13719925450025225 and loss 0.24302059496567505\n",
      "lt_loss 0.24173596897 is in [0.10562715028727451272, 0.37976097756660676108]\n",
      "with b 0.13706691363966614 and loss 0.24269406392694065\n",
      "lt_loss 0.24173596897 is in [0.10543402732545684164, 0.37930401367682109459]\n",
      "with b 0.1369349931756821 and loss 0.24236902050113895\n",
      "lt_loss 0.24173596897 is in [0.10524196371075636436, 0.37884894538015279064]\n",
      "with b 0.1368034908346982 and loss 0.24204545454545456\n",
      "lt_loss 0.24173596897 is in [0.10641149586627859924, 0.37975630458723608207]\n",
      "with b 0.13667240436047876 and loss 0.24308390022675735\n",
      "lt_loss 0.24173596897 is in [0.10599220513760040929, 0.37907566816556692579]\n",
      "with b 0.13654173151398327 and loss 0.24253393665158368\n",
      "lt_loss 0.24173596897 is in [0.10557498590874403455, 0.37839792605513855595]\n",
      "with b 0.13641147007319726 and loss 0.2419864559819413\n",
      "lt_loss 0.24173596897 is in [0.10515982360847653254, 0.37772305927440635864]\n",
      "with b 0.1362816178329649 and loss 0.24144144144144145\n",
      "lt_loss 0.24173596897 is in [0.10497142290079383709, 0.37727576811044216676]\n",
      "with b 0.13615217260482415 and loss 0.241123595505618\n",
      "lt_loss 0.24173596897 is in [0.10455982742441233269, 0.37660609185809884591]\n",
      "with b 0.13602313221684326 and loss 0.2405829596412556\n",
      "lt_loss 0.24173596897 is in [0.10437396186237915541, 0.37616295088929874169]\n",
      "with b 0.13589449451345978 and loss 0.24026845637583893\n",
      "lt_loss 0.24173596897 is in [0.10485874264467878736, 0.37639125735532119599]\n",
      "with b 0.1357662573553212 and loss 0.24062499999999998\n",
      "lt_loss 0.24173596897 is in [0.10600968828510412556, 0.37728652552335906201]\n",
      "with b 0.13563841861912748 and loss 0.2416481069042316\n",
      "lt_loss 0.24173596897 is in [0.10560013491363556826, 0.37662208730858665051]\n",
      "with b 0.13551097619747554 and loss 0.2411111111111111\n",
      "lt_loss 0.24173596897 is in [0.10519256867535189959, 0.37596042467276347132]\n",
      "with b 0.13538392799870577 and loss 0.24057649667405767\n",
      "lt_loss 0.24173596897 is in [0.10478697584086080208, 0.37530151973436043367]\n",
      "with b 0.13525727194674983 and loss 0.24004424778761063\n",
      "lt_loss 0.24173596897 is in [0.10438334280489106054, 0.3746453547668529005]\n",
      "with b 0.1351310059809809 and loss 0.23951434878587197\n",
      "lt_loss 0.24173596897 is in [0.10420192040208456352, 0.37421217651421501138]\n",
      "with b 0.1350051280560652 and loss 0.23920704845814977\n",
      "lt_loss 0.24173596897 is in [0.10468080341862409655, 0.37444007570225501524]\n",
      "with b 0.13487963614181547 and loss 0.23956043956043957\n",
      "lt_loss 0.24173596897 is in [0.10428055949625206211, 0.3737896159423443887]\n",
      "with b 0.13475452822304618 and loss 0.23903508771929824\n",
      "lt_loss 0.24173596897 is in [0.10410105109225459286, 0.37336065569111520634]\n",
      "with b 0.1346298022994303 and loss 0.2387308533916849\n",
      "lt_loss 0.24173596897 is in [0.10370415060154150599, 0.37271506337225757122]\n",
      "with b 0.13450545638535805 and loss 0.23820960698689955\n",
      "lt_loss 0.24173596897 is in [0.10330914329848209232, 0.37207212031807557207]\n",
      "with b 0.13438148850979675 and loss 0.23769063180827885\n",
      "lt_loss 0.24173596897 is in [0.10291601632732533256, 0.37143180975963119295]\n",
      "with b 0.13425789671615293 and loss 0.23717391304347826\n",
      "lt_loss 0.24173596897 is in [0.10274167668623751526, 0.3710110348105086775]\n",
      "with b 0.13413467906213558 and loss 0.2368763557483731\n",
      "lt_loss 0.24173596897 is in [0.10408340447561678643, 0.37210707171485934985]\n",
      "with b 0.1340118336196213 and loss 0.23809523809523808\n",
      "lt_loss 0.24173596897 is in [0.10520351409567382794, 0.37298223104471495137]\n",
      "with b 0.13388935847452058 and loss 0.2390928725701944\n",
      "lt_loss 0.24173596897 is in [0.10567240344576753208, 0.37320690689905999804]\n",
      "with b 0.13376725172664625 and loss 0.23943965517241378\n",
      "lt_loss 0.24173596897 is in [0.10678459603729886784, 0.3740756190164645778]\n",
      "with b 0.13364551148958284 and loss 0.2404301075268817\n",
      "lt_loss 0.24173596897 is in [0.10810676539699581866, 0.37515503717811149453]\n",
      "with b 0.13352413589055784 and loss 0.24163090128755366\n",
      "lt_loss 0.24173596897 is in [0.10771036729371152862, 0.37451661343433989559]\n",
      "with b 0.13340312307031418 and loss 0.2411134903640257\n",
      "lt_loss 0.24173596897 is in [0.10881154591103270324, 0.37537648827700148546]\n",
      "with b 0.1332824711829844 and loss 0.2420940170940171\n",
      "lt_loss 0.24173596897 is in [0.10990818407738159324, 0.37623254086931356976]\n",
      "with b 0.13316217839596597 and loss 0.24307036247334757\n",
      "lt_loss 0.24173596897 is in [0.11036201242935045341, 0.37644649820894737768]\n",
      "with b 0.13304224288979846 and loss 0.24340425531914892\n",
      "lt_loss 0.24173596897 is in [0.11017712482773342475, 0.3760224505438164444]\n",
      "with b 0.13292266285804152 and loss 0.24309978768577495\n",
      "lt_loss 0.24173596897 is in [0.1112643601030146312, 0.3768712331173242891]\n",
      "with b 0.13280343650715484 and loss 0.24406779661016947\n",
      "lt_loss 0.24173596897 is in [0.11107865147427631314, 0.37644777558703446108]\n",
      "with b 0.13268456205637907 and loss 0.2437632135306554\n",
      "lt_loss 0.24173596897 is in [0.11215970065900629504, 0.37729177613424269566]\n",
      "with b 0.1325660377376182 and loss 0.24472573839662448\n",
      "lt_loss 0.24173596897 is in [0.11176266452046615396, 0.37665838811111274076]\n",
      "with b 0.1324478617953233 and loss 0.24421052631578946\n",
      "lt_loss 0.24173596897 is in [0.11136744650521901434, 0.37602751147797425224]\n",
      "with b 0.13233003248637762 and loss 0.24369747899159663\n",
      "lt_loss 0.24173596897 is in [0.11202225275859159503, 0.37644734891855724523]\n",
      "with b 0.1322125480799828 and loss 0.2442348008385744\n",
      "lt_loss 0.24173596897 is in [0.11183764753575897721, 0.37602846125085187534]\n",
      "with b 0.13209540685754645 and loss 0.24393305439330543\n",
      "lt_loss 0.24173596897 is in [0.11144519246989237349, 0.37540240669503455173]\n",
      "with b 0.1319786071125711 and loss 0.24342379958246346\n",
      "lt_loss 0.24173596897 is in [0.112096186182789187, 0.37582048048387750594]\n",
      "with b 0.13186214715054415 and loss 0.24395833333333333\n",
      "lt_loss 0.24173596897 is in [0.11316041961761555412, 0.3766524701952742582]\n",
      "with b 0.13174602528882937 and loss 0.24490644490644492\n",
      "lt_loss 0.24173596897 is in [0.11422038255007982421, 0.37748086226319815806]\n",
      "with b 0.13163023985655917 and loss 0.245850622406639\n",
      "lt_loss 0.24173596897 is in [0.11486202239967438499, 0.37789160078873140769]\n",
      "with b 0.13151478919452853 and loss 0.2463768115942029\n",
      "lt_loss 0.24173596897 is in [0.11591437793168710146, 0.37871372124186664099]\n",
      "with b 0.13139967165508978 and loss 0.24731404958677689\n",
      "lt_loss 0.24173596897 is in [0.11551923810929162761, 0.3780890093133887353]\n",
      "with b 0.13128488560204857 and loss 0.2468041237113402\n",
      "lt_loss 0.24173596897 is in [0.1153316282026075057, 0.3776724870237299081]\n",
      "with b 0.1311704294105612 and loss 0.2465020576131687\n",
      "lt_loss 0.24173596897 is in [0.11493959175678633566, 0.37705219469085227146]\n",
      "with b 0.13105630146703295 and loss 0.2459958932238193\n",
      "lt_loss 0.24173596897 is in [0.11454930310967120777, 0.3764343034477058425]\n",
      "with b 0.13094250016901732 and loss 0.24549180327868853\n",
      "lt_loss 0.24173596897 is in [0.11436525010351306086, 0.37602329795374661581]\n",
      "with b 0.13082902392511678 and loss 0.24519427402862984\n",
      "lt_loss 0.24173596897 is in [0.11540657782470759019, 0.37683832013447604581]\n",
      "with b 0.13071587115488423 and loss 0.24612244897959182\n",
      "lt_loss 0.24173596897 is in [0.11501814097400320236, 0.3762242215514550181]\n",
      "with b 0.1306030402887259 and loss 0.2456211812627291\n",
      "lt_loss 0.24173596897 is in [0.11625743771186999864, 0.37723849724747959833]\n",
      "with b 0.1304905297678048 and loss 0.2467479674796748\n",
      "lt_loss 0.24173596897 is in [0.1158691264590966663, 0.37662580254698851956]\n",
      "with b 0.1303783380439459 and loss 0.24624746450304258\n",
      "lt_loss 0.24173596897 is in [0.11568495342450690888, 0.37621788058359023621]\n",
      "with b 0.13026646357954166 and loss 0.24595141700404857\n",
      "lt_loss 0.24173596897 is in [0.11550166080910673205, 0.37581147050402458065]\n",
      "with b 0.13015490484745892 and loss 0.24565656565656566\n",
      "lt_loss 0.24173596897 is in [0.11652892031421430152, 0.3766162409761082408]\n",
      "with b 0.13004366033094697 and loss 0.24657258064516127\n",
      "lt_loss 0.24173596897 is in [0.1169485592028119969, 0.37681401624990429333]\n",
      "with b 0.12993272852354615 and loss 0.24688128772635815\n",
      "lt_loss 0.24173596897 is in [0.116563434239676883, 0.37620765009767254128]\n",
      "with b 0.12982210792899782 and loss 0.2463855421686747\n",
      "lt_loss 0.24173596897 is in [0.11638038730758237804, 0.37580398142989257515]\n",
      "with b 0.1297117970611551 and loss 0.24609218436873748\n",
      "lt_loss 0.24173596897 is in [0.1161982055561052718, 0.37540179444389470964]\n",
      "with b 0.12960179444389472 and loss 0.2458\n",
      "lt_loss 0.24173596897 is in [0.11581728262649537697, 0.3748014798485545529]\n",
      "with b 0.1294920986110296 and loss 0.24530938123752496\n",
      "lt_loss 0.24173596897 is in [0.11683243133600862418, 0.37559784754845348953]\n",
      "with b 0.12938270810622243 and loss 0.24621513944223106\n",
      "lt_loss 0.24173596897 is in [0.11645202464035989132, 0.37499926760616097976]\n",
      "with b 0.12927362148290053 and loss 0.24572564612326042\n",
      "lt_loss 0.24173596897 is in [0.11607325793392433977, 0.37440293254226608699]\n",
      "with b 0.1291648373041709 and loss 0.24523809523809523\n",
      "lt_loss 0.24173596897 is in [0.11728027952062949901, 0.37539298780610308448]\n",
      "with b 0.1290563541427368 and loss 0.2463366336633663\n",
      "lt_loss 0.24173596897 is in [0.1170992602492244572, 0.37499560141085458431]\n",
      "with b 0.12894817058081506 and loss 0.24604743083003952\n",
      "lt_loss 0.24173596897 is in [0.1181025155789006964, 0.37578308599900855924]\n",
      "with b 0.12884028521005395 and loss 0.24694280078895464\n",
      "lt_loss 0.24173596897 is in [0.11772399628193344623, 0.37518938954483826986]\n",
      "with b 0.1287326966314524 and loss 0.24645669291338584\n",
      "lt_loss 0.24173596897 is in [0.11734709163312898039, 0.37459789854368830131]\n",
      "with b 0.12862540345527965 and loss 0.24597249508840863\n",
      "lt_loss 0.24173596897 is in [0.11716787020880789494, 0.3742046788107999955]\n",
      "with b 0.12851840430099604 and loss 0.24568627450980393\n",
      "lt_loss 0.24173596897 is in [0.11679378165488035757, 0.37361717724922921535]\n",
      "with b 0.12841169779717443 and loss 0.2452054794520548\n",
      "lt_loss 0.24173596897 is in [0.11720252991857743607, 0.37381309508142257503]\n",
      "with b 0.12830528258142257 and loss 0.2455078125\n",
      "lt_loss 0.24173596897 is in [0.11683008246577558653, 0.37322839706638816226]\n",
      "with b 0.1281991573003063 and loss 0.24502923976608187\n",
      "lt_loss 0.24173596897 is in [0.1178210762778862386, 0.37400771749643280106]\n",
      "with b 0.12809332060927328 and loss 0.24591439688715952\n",
      "lt_loss 0.24173596897 is in [0.11744912203130555839, 0.37342466437646149036]\n",
      "with b 0.12798777117257795 and loss 0.2454368932038835\n",
      "lt_loss 0.24173596897 is in [0.11804772489493262078, 0.37381274022134636237]\n",
      "with b 0.12788250766320688 and loss 0.2459302325581395\n",
      "lt_loss 0.24173596897 is in [0.11787044028941914831, 0.37342549781502953898]\n",
      "with b 0.1277775287628052 and loss 0.24564796905222436\n",
      "lt_loss 0.24173596897 is in [0.11750091201214174497, 0.37284657833534862181]\n",
      "with b 0.12767283316160344 and loss 0.24517374517374518\n",
      "lt_loss 0.24173596897 is in [0.11713292918924603225, 0.37226976830593705436]\n",
      "with b 0.1275684195583455 and loss 0.24470134874759153\n",
      "lt_loss 0.24173596897 is in [0.11811263641670585733, 0.37304120973714027798]\n",
      "with b 0.1274642866602172 and loss 0.24557692307692305\n",
      "lt_loss 0.24173596897 is in [0.11793707161568917074, 0.37265793798123980629]\n",
      "with b 0.12736043318277532 and loss 0.2452975047984645\n",
      "lt_loss 0.24173596897 is in [0.11757072835701862235, 0.37208444405677443267]\n",
      "with b 0.12725685784987792 and loss 0.24482758620689654\n",
      "lt_loss 0.24173596897 is in [0.11797072358917679025, 0.37227784237640637599]\n",
      "with b 0.12715355939361478 and loss 0.24512428298279157\n",
      "lt_loss 0.24173596897 is in [0.11760595199537926536, 0.37170702510385739137]\n",
      "with b 0.12705053655423906 and loss 0.24465648854961833\n",
      "lt_loss 0.24173596897 is in [0.11743316430085307123, 0.3713287404610516873]\n",
      "with b 0.1269477880800993 and loss 0.24438095238095237\n",
      "lt_loss 0.24173596897 is in [0.11707103708231378358, 0.3707616625374581254]\n",
      "with b 0.12684531272757216 and loss 0.24391634980988594\n",
      "lt_loss 0.24173596897 is in [0.11671040117543654557, 0.37019661969742878593]\n",
      "with b 0.1267431092609961 and loss 0.24345351043643265\n",
      "lt_loss 0.24173596897 is in [0.11635124778981875693, 0.36963360069502976257]\n",
      "with b 0.1266411764526055 and loss 0.24299242424242426\n",
      "lt_loss 0.24173596897 is in [0.11693874778709981155, 0.37001777395203061527]\n",
      "with b 0.1265395130824654 and loss 0.2434782608695652\n",
      "lt_loss 0.24173596897 is in [0.11658074998612122375, 0.36945698586293534982]\n",
      "with b 0.12643811793840706 and loss 0.2430188679245283\n",
      "lt_loss 0.24173596897 is in [0.11622421545710551194, 0.36889819508903387568]\n",
      "with b 0.12633698981596417 and loss 0.24256120527306968\n",
      "lt_loss 0.24173596897 is in [0.11586913563958509132, 0.36834139067620430552]\n",
      "with b 0.12623612751830962 and loss 0.2421052631578947\n",
      "lt_loss 0.24173596897 is in [0.11551550203874144662, 0.36778656175112722782]\n",
      "with b 0.1261355298561929 and loss 0.24165103189493434\n",
      "lt_loss 0.24173596897 is in [0.11609963581279608702, 0.36817002710855223357]\n",
      "with b 0.12603519564787807 and loss 0.24213483146067416\n",
      "lt_loss 0.24173596897 is in [0.11574711927157149693, 0.36761736670973688135]\n",
      "with b 0.1259351237190827 and loss 0.2416822429906542\n",
      "lt_loss 0.24173596897 is in [0.11670200052991902551, 0.36837262633575268422]\n",
      "with b 0.12583531290291683 and loss 0.24253731343283585\n",
      "lt_loss 0.24173596897 is in [0.11783965695459025502, 0.36931118103423654642]\n",
      "with b 0.12573576203982315 and loss 0.2435754189944134\n",
      "lt_loss 0.24173596897 is in [0.1174862066024082996, 0.36875914655744301829]\n",
      "with b 0.12563646997751735 and loss 0.24312267657992565\n",
      "lt_loss 0.24173596897 is in [0.11713417852925631091, 0.36820904967111467432]\n",
      "with b 0.1255374355709292 and loss 0.2426716141001855\n",
      "lt_loss 0.24173596897 is in [0.11807986083637420083, 0.3689571762006628175]\n",
      "with b 0.1254386576821443 and loss 0.2435185185185185\n",
      "lt_loss 0.24173596897 is in [0.11902215687140973999, 0.36970242723210222646]\n",
      "with b 0.12534013518034623 and loss 0.24436229205175597\n",
      "lt_loss 0.24173596897 is in [0.11959208139772387058, 0.37007581528124294801]\n",
      "with b 0.12524186694175954 and loss 0.2448339483394834\n",
      "lt_loss 0.24173596897 is in [0.12052833967895221212, 0.37081604337813806049]\n",
      "with b 0.12514385184959292 and loss 0.24567219152854514\n",
      "lt_loss 0.24173596897 is in [0.12035832297072263097, 0.37045050055868911087]\n",
      "with b 0.12504608879398324 and loss 0.24540441176470587\n",
      "lt_loss 0.24173596897 is in [0.1200055517684268519, 0.36990270511230710637]\n",
      "with b 0.12494857667194013 and loss 0.24495412844036699\n",
      "lt_loss 0.24173596897 is in [0.11965418011820362632, 0.36935680889278538208]\n",
      "with b 0.12485131438729087 and loss 0.2445054945054945\n",
      "lt_loss 0.24173596897 is in [0.11948701541994068143, 0.36899561712119283152]\n",
      "with b 0.12475430085062607 and loss 0.24424131627056675\n",
      "lt_loss 0.24173596897 is in [0.11932056721053527215, 0.36863563716902669753]\n",
      "with b 0.12465753497924573 and loss 0.243978102189781\n",
      "lt_loss 0.24173596897 is in [0.11897268193495243171, 0.3680947133291641582]\n",
      "with b 0.12456101569710586 and loss 0.2435336976320583\n",
      "lt_loss 0.24173596897 is in [0.11935343988341610977, 0.36828292375294752192]\n",
      "with b 0.12446474193476571 and loss 0.24381818181818182\n",
      "lt_loss 0.24173596897 is in [0.11918845615469357557, 0.36792588141336440843]\n",
      "with b 0.12436871262933542 and loss 0.243557168784029\n",
      "lt_loss 0.24173596897 is in [0.11902417472485130046, 0.36757002817369943681]\n",
      "with b 0.12427292672442405 and loss 0.24329710144927535\n",
      "lt_loss 0.24173596897 is in [0.11867975968705429812, 0.36703452602723135589]\n",
      "with b 0.12417738317008853 and loss 0.24285714285714283\n",
      "lt_loss 0.24173596897 is in [0.11923921871620662971, 0.36740338056177174186]\n",
      "with b 0.12408208092278256 and loss 0.24332129963898919\n",
      "lt_loss 0.24173596897 is in [0.11889586393757643756, 0.36686990182818934869]\n",
      "with b 0.12398701894530646 and loss 0.2428828828828829\n",
      "lt_loss 0.24173596897 is in [0.11945312753424988661, 0.36723751994776454577]\n",
      "with b 0.12389219620675732 and loss 0.2433453237410072\n",
      "lt_loss 0.24173596897 is in [0.11911082637856180988, 0.36670604974352077887]\n",
      "with b 0.12379761168247948 and loss 0.2429084380610413\n",
      "lt_loss 0.24173596897 is in [0.11966591127322435961, 0.36707243998125588247]\n",
      "with b 0.12370326435401575 and loss 0.24336917562724011\n",
      "lt_loss 0.24173596897 is in [0.1193246571666118222, 0.36654296358472987505]\n",
      "with b 0.12360915320905903 and loss 0.24293381037567086\n",
      "lt_loss 0.24173596897 is in [0.118984722758595729, 0.36601527724140425768]\n",
      "with b 0.12351527724140426 and loss 0.2425\n",
      "lt_loss 0.24173596897 is in [0.11864610073448235428, 0.36548937163628414382]\n",
      "with b 0.12342163545090089 and loss 0.24206773618538324\n",
      "lt_loss 0.24173596897 is in [0.11830878383275061916, 0.36496523751956250203]\n",
      "with b 0.12332822684340594 and loss 0.24163701067615656\n",
      "lt_loss 0.24173596897 is in [0.11797276484457347445, 0.36444286570604816911]\n",
      "with b 0.12323505043073735 and loss 0.24120781527531082\n",
      "lt_loss 0.24173596897 is in [0.11763803661334390482, 0.36392224707459941424]\n",
      "with b 0.12314210523062774 and loss 0.24078014184397165\n",
      "lt_loss 0.24173596897 is in [0.11730459203420612324, 0.36340337256756377604]\n",
      "with b 0.12304939026667883 and loss 0.24035398230088495\n",
      "lt_loss 0.24173596897 is in [0.11714910249882176663, 0.36306291163545384437]\n",
      "with b 0.12295690456831604 and loss 0.2401060070671378\n",
      "lt_loss 0.24173596897 is in [0.11699425935482948846, 0.36272355369631686939]\n",
      "with b 0.12286464717074369 and loss 0.23985890652557318\n",
      "lt_loss 0.24173596897 is in [0.11666400260340928363, 0.36220923683321037956]\n",
      "with b 0.12277261711490056 and loss 0.23943661971830985\n",
      "lt_loss 0.24173596897 is in [0.11633500377578281926, 0.36169663067061436079]\n",
      "with b 0.12268081344741577 and loss 0.2390158172231986\n",
      "lt_loss 0.24173596897 is in [0.11618269460399605064, 0.36136116504512677539]\n",
      "with b 0.12258923522056536 and loss 0.2387719298245614\n",
      "lt_loss 0.24173596897 is in [0.11603101518027543471, 0.36102677816473333072]\n",
      "with b 0.12249788149222894 and loss 0.23852889667250438\n",
      "lt_loss 0.24173596897 is in [0.11570513678604114893, 0.36051863943773504451]\n",
      "with b 0.12240675132584695 and loss 0.2381118881118881\n",
      "lt_loss 0.24173596897 is in [0.11538049128815563993, 0.36001217886891234699]\n",
      "with b 0.12231584379037835 and loss 0.237696335078534\n",
      "lt_loss 0.24173596897 is in [0.11523128803277295218, 0.35968160395328979684]\n",
      "with b 0.12222515796025842 and loss 0.23745644599303137\n",
      "lt_loss 0.24173596897 is in [0.11490878534551215995, 0.35917817117622696799]\n",
      "with b 0.12213469291535739 and loss 0.23704347826086955\n",
      "lt_loss 0.24173596897 is in [0.11580277448128314943, 0.35989166996316135361]\n",
      "with b 0.12204444774093909 and loss 0.23784722222222224\n",
      "lt_loss 0.24173596897 is in [0.11565389736319446612, 0.3595627404184346676]\n",
      "with b 0.12195442152762011 and loss 0.23760831889081457\n",
      "lt_loss 0.24173596897 is in [0.11654369112694040744, 0.36027291786959936282]\n",
      "with b 0.12186461337132948 and loss 0.23840830449826989\n",
      "lt_loss 0.24173596897 is in [0.11622152339529810694, 0.35977156814183486322]\n",
      "with b 0.12177502237326839 and loss 0.2379965457685665\n",
      "lt_loss 0.24173596897 is in [0.11590055925668105163, 0.35927185453642240809]\n",
      "with b 0.12168564763987066 and loss 0.23758620689655172\n",
      "lt_loss 0.24173596897 is in [0.11558079226801123984, 0.35877376883353784276]\n",
      "with b 0.12159648828276329 and loss 0.23717728055077453\n",
      "lt_loss 0.24173596897 is in [0.11612132256065389735, 0.35913640939810903552]\n",
      "with b 0.12150754341872756 and loss 0.23762886597938146\n",
      "lt_loss 0.24173596897 is in [0.11580245712708071848, 0.35864008146640130592]\n",
      "with b 0.12141881216966029 and loss 0.237221269296741\n",
      "lt_loss 0.24173596897 is in [0.11548477483061497795, 0.35814536215568637534]\n",
      "with b 0.1213302936625357 and loss 0.23681506849315068\n",
      "lt_loss 0.24173596897 is in [0.11533920955182913604, 0.35782318361056403289]\n",
      "with b 0.12124198702936745 and loss 0.23658119658119658\n",
      "lt_loss 0.24173596897 is in [0.11519423145972322586, 0.35750201427406519405]\n",
      "with b 0.12115389140717099 and loss 0.23634812286689422\n",
      "lt_loss 0.24173596897 is in [0.11556091058677531169, 0.35769292246262840429]\n",
      "with b 0.12106600593792655 and loss 0.23662691652470186\n",
      "lt_loss 0.24173596897 is in [0.11541622805458734424, 0.35737288759167112895]\n",
      "with b 0.12097832976854189 and loss 0.23639455782312924\n",
      "lt_loss 0.24173596897 is in [0.11646058107312266816, 0.35824230517475502689]\n",
      "with b 0.12089086205081619 and loss 0.23735144312393885\n",
      "lt_loss 0.24173596897 is in [0.11614555060096938555, 0.35775275448377635845]\n",
      "with b 0.12080360194140348 and loss 0.23694915254237287\n",
      "lt_loss 0.24173596897 is in [0.11701610791260551314, 0.35844920511615929737]\n",
      "with b 0.1207165486017769 and loss 0.2377326565143824\n",
      "lt_loss 0.24173596897 is in [0.11754597447748250938, 0.35880537687386881984]\n",
      "with b 0.12062970119819315 and loss 0.23817567567567566\n",
      "lt_loss 0.24173596897 is in [0.11723097145247435291, 0.35831708925578870106]\n",
      "with b 0.12054305890165717 and loss 0.23777403035413153\n",
      "lt_loss 0.24173596897 is in [0.11691711648585012551, 0.3578303582616246814]\n",
      "with b 0.12045662088788728 and loss 0.2373737373737374\n",
      "lt_loss 0.24173596897 is in [0.11744473971313962313, 0.35818551238770068856]\n",
      "with b 0.12037038633728053 and loss 0.23781512605042016\n",
      "lt_loss 0.24173596897 is in [0.11729953818257118914, 0.3578682470523281145]\n",
      "with b 0.12028435443487845 and loss 0.23758389261744964\n",
      "lt_loss 0.24173596897 is in [0.11782492621593167181, 0.35822197495659757749]\n",
      "with b 0.12019852437033295 and loss 0.23802345058626462\n",
      "lt_loss 0.24173596897 is in [0.11868309128420076459, 0.35890888195994630205]\n",
      "with b 0.12011289533787278 and loss 0.23879598662207355\n",
      "lt_loss 0.24173596897 is in [0.11853680725337936708, 0.35859174032591945025]\n",
      "with b 0.12002746653627006 and loss 0.23856427378964942\n",
      "lt_loss 0.24173596897 is in [0.11839109616452617169, 0.35827557050214053902]\n",
      "with b 0.11994223716880717 and loss 0.23833333333333334\n",
      "lt_loss 0.24173596897 is in [0.11874512300767109396, 0.35845953589415918694]\n",
      "with b 0.11985720644324405 and loss 0.23860232945091514\n",
      "lt_loss 0.24173596897 is in [0.11843360649465957402, 0.35797835363823077293]\n",
      "with b 0.11977237357178559 and loss 0.23820598006644517\n",
      "lt_loss 0.24173596897 is in [0.1192840698574745284, 0.35865954539957356495]\n",
      "with b 0.11968773777104952 and loss 0.23897180762852405\n",
      "lt_loss 0.24173596897 is in [0.1196351123339920719, 0.35884170885806088158]\n",
      "with b 0.11960329826203442 and loss 0.2392384105960265\n",
      "lt_loss 0.24173596897 is in [0.11932392093652345599, 0.35836202947669970609]\n",
      "with b 0.11951905427008812 and loss 0.23884297520661157\n",
      "lt_loss 0.24173596897 is in [0.11917885636126232529, 0.35804886641101496547]\n",
      "with b 0.1194350050248763 and loss 0.23861386138613863\n",
      "lt_loss 0.24173596897 is in [0.11903435271081826141, 0.35773665223152112391]\n",
      "with b 0.11935114976035142 and loss 0.23838550247116969\n",
      "lt_loss 0.24173596897 is in [0.11872593333790960879, 0.35726090876735350221]\n",
      "with b 0.11926748771472194 and loss 0.23799342105263155\n",
      "lt_loss 0.24173596897 is in [0.11841860912737793565, 0.35678664538822141283]\n",
      "with b 0.11918401813042175 and loss 0.23760262725779968\n",
      "lt_loss 0.24173596897 is in [0.11827630892624795, 0.35647778943440772137]\n",
      "with b 0.11910074025407989 and loss 0.23737704918032784\n",
      "lt_loss 0.24173596897 is in [0.11911655288282196885, 0.35715185955580319721]\n",
      "with b 0.11901765333649061 and loss 0.23813420621931258\n",
      "lt_loss 0.24173596897 is in [0.11897374009944264306, 0.35684325336460964717]\n",
      "with b 0.11893475663258352 and loss 0.23790849673202616\n",
      "lt_loss 0.24173596897 is in [0.11866834211573468183, 0.35637244091852304795]\n",
      "with b 0.11885204940139418 and loss 0.23752039151712886\n",
      "lt_loss 0.24173596897 is in [0.11836401958256440037, 0.35590308139463422421]\n",
      "with b 0.11876953090603493 and loss 0.23713355048859933\n",
      "lt_loss 0.24173596897 is in [0.11806076706600898696, 0.35543516789334062]\n",
      "with b 0.11868720041366582 and loss 0.2367479674796748\n",
      "lt_loss 0.24173596897 is in [0.11857026747985886794, 0.35578038187079052967]\n",
      "with b 0.11860505719546584 and loss 0.2371753246753247\n",
      "lt_loss 0.24173596897 is in [0.11940234517841961936, 0.35644854623162902652]\n",
      "with b 0.11852310052660471 and loss 0.23792544570502433\n",
      "lt_loss 0.24173596897 is in [0.12023180947236170035, 0.35711446884479047803]\n",
      "with b 0.11844132968621437 and loss 0.23867313915857608\n",
      "lt_loss 0.24173596897 is in [0.11992781662422200006, 0.35664730453894433193]\n",
      "with b 0.11835974395736118 and loss 0.23828756058158318\n",
      "lt_loss 0.24173596897 is in [0.1196248831794334555, 0.35618156843346970852]\n",
      "with b 0.11827834262701814 and loss 0.2379032258064516\n",
      "lt_loss 0.24173596897 is in [0.11932300383843932878, 0.35571725381051400028]\n",
      "with b 0.11819712498603732 and loss 0.23752012882447665\n",
      "lt_loss 0.24173596897 is in [0.11966526015319231546, 0.35589744081143781518]\n",
      "with b 0.11811609032912276 and loss 0.23778135048231508\n",
      "lt_loss 0.24173596897 is in [0.12000649559254822352, 0.35607697150215483761]\n",
      "with b 0.11803523795480331 and loss 0.23804173354735153\n",
      "lt_loss 0.24173596897 is in [0.1198659456551069008, 0.35577507998591878513]\n",
      "with b 0.11795456716540594 and loss 0.23782051282051284\n",
      "lt_loss 0.24173596897 is in [0.12020592273297092678, 0.35595407726702904538]\n",
      "with b 0.11787407726702906 and loss 0.23807999999999999\n",
      "lt_loss 0.24173596897 is in [0.11990591294166581815, 0.3554934480806984376]\n",
      "with b 0.1177937675695163 and loss 0.23769968051118212\n",
      "lt_loss 0.24173596897 is in [0.1196069367762490343, 0.35503421154910985713]\n",
      "with b 0.1177136373864304 and loss 0.23732057416267943\n",
      "lt_loss 0.24173596897 is in [0.12042363880573710155, 0.35569101087579152454]\n",
      "with b 0.1176336860350272 and loss 0.2380573248407643\n",
      "lt_loss 0.24173596897 is in [0.12028392500160771383, 0.35539175067406797437]\n",
      "with b 0.11755391283623014 and loss 0.23783783783783785\n",
      "lt_loss 0.24173596897 is in [0.12014473050444290925, 0.355093364733652328]\n",
      "with b 0.11747431711460471 and loss 0.23761904761904762\n",
      "lt_loss 0.24173596897 is in [0.11984757406791085588, 0.35463737046457727287]\n",
      "with b 0.11739489819833321 and loss 0.23724247226624406\n",
      "lt_loss 0.24173596897 is in [0.12034257242891140127, 0.35497388326729112373]\n",
      "with b 0.11731565541918985 and loss 0.23765822784810126\n",
      "lt_loss 0.24173596897 is in [0.12115203747990124783, 0.35562521370493282991]\n",
      "with b 0.1172365881125158 and loss 0.23838862559241705\n",
      "lt_loss 0.24173596897 is in [0.12085492267933523047, 0.35517031391372472227]\n",
      "with b 0.11715769561719475 and loss 0.23801261829652998\n",
      "lt_loss 0.24173596897 is in [0.12055881799996218118, 0.35471677255121891736]\n",
      "with b 0.11707897727562838 and loss 0.23763779527559056\n",
      "lt_loss 0.24173596897 is in [0.12026371850968396726, 0.35426458337710842184]\n",
      "with b 0.11700043243371223 and loss 0.2372641509433962\n",
      "lt_loss 0.24173596897 is in [0.11996961930801079699, 0.35381374018963446249]\n",
      "with b 0.11692206044081184 and loss 0.23689167974882264\n",
      "lt_loss 0.24173596897 is in [0.11967651552580979568, 0.35336423682528739221]\n",
      "with b 0.11684386064973878 and loss 0.23652037617554858\n",
      "lt_loss 0.24173596897 is in [0.1193844023250568015, 0.35291606715851120413]\n",
      "with b 0.11676583241672721 and loss 0.236150234741784\n",
      "lt_loss 0.24173596897 is in [0.11924952489858955951, 0.35262547510141040163]\n",
      "with b 0.11668797510141043 and loss 0.2359375\n",
      "lt_loss 0.24173596897 is in [0.11895913471011332341, 0.35217971084370891521]\n",
      "with b 0.1166102880667978 and loss 0.23556942277691112\n",
      "lt_loss 0.24173596897 is in [0.11929277449208797179, 0.35235831585059118609]\n",
      "with b 0.11653277067925161 and loss 0.23582554517133958\n",
      "lt_loss 0.24173596897 is in [0.11978096960444378771, 0.35269181422137269033]\n",
      "with b 0.11645542230846445 and loss 0.23623639191290824\n",
      "lt_loss 0.24173596897 is in [0.11964660239306047773, 0.35240308704793327221]\n",
      "with b 0.11637824232743639 and loss 0.23602484472049687\n",
      "lt_loss 0.24173596897 is in [0.11951272337591928308, 0.3521151836008248881]\n",
      "with b 0.1163012301124528 and loss 0.23581395348837209\n",
      "lt_loss 0.24173596897 is in [0.1198437264120464224, 0.35229249649817029333]\n",
      "with b 0.11622438504306194 and loss 0.23606811145510836\n",
      "lt_loss 0.24173596897 is in [0.12063745578542767189, 0.35293286878953367136]\n",
      "with b 0.116147706502053 and loss 0.23678516228748067\n",
      "lt_loss 0.24173596897 is in [0.12034855921098552844, 0.35249094696185395703]\n",
      "with b 0.11607119387543421 and loss 0.23641975308641974\n",
      "lt_loss 0.24173596897 is in [0.12006062340136387789, 0.35205031650618623384]\n",
      "with b 0.11599484655241117 and loss 0.23605546995377505\n",
      "lt_loss 0.24173596897 is in [0.11992748992078854087, 0.35176481777151913377]\n",
      "with b 0.1159186639253653 and loss 0.23584615384615384\n",
      "lt_loss 0.24173596897 is in [0.11964122557790939083, 0.35132651635757444764]\n",
      "with b 0.11584264538983254 and loss 0.23548387096774193\n",
      "lt_loss 0.24173596897 is in [0.11935590904202075802, 0.35088948973098532669]\n",
      "with b 0.11576679034448228 and loss 0.23512269938650304\n",
      "lt_loss 0.24173596897 is in [0.11907153580584099728, 0.35045373218803338444]\n",
      "with b 0.1156910981910962 and loss 0.2347626339969372\n",
      "lt_loss 0.24173596897 is in [0.11878810139022298598, 0.35001923805931828282]\n",
      "with b 0.11561556833454766 and loss 0.23440366972477064\n",
      "lt_loss 0.24173596897 is in [0.11957430363401300166, 0.35065470399957476832]\n",
      "with b 0.11554020018278088 and loss 0.23511450381679388\n",
      "lt_loss 0.24173596897 is in [0.11944354343857517542, 0.35037352973215651897]\n",
      "with b 0.11546499314679066 and loss 0.23490853658536584\n",
      "lt_loss 0.24173596897 is in [0.11931324970643003569, 0.35009314298763383189]\n",
      "with b 0.1153899466406019 and loss 0.23470319634703193\n",
      "lt_loss 0.24173596897 is in [0.11979132289747376761, 0.35042144305997302567]\n",
      "with b 0.11531506008124962 and loss 0.23510638297872338\n",
      "lt_loss 0.24173596897 is in [0.11950928774857044745, 0.3499899535260881378]\n",
      "with b 0.11524033288875885 and loss 0.2347496206373293\n",
      "lt_loss 0.24173596897 is in [0.11922817490781449645, 0.34955970388006429861]\n",
      "with b 0.11516576448612491 and loss 0.2343939393939394\n",
      "lt_loss 0.24173596897 is in [0.11909926597302085416, 0.34928197457160847783]\n",
      "with b 0.1150913542992938 and loss 0.23419062027231466\n",
      "lt_loss 0.24173596897 is in [0.11987715806158850962, 0.34991136157587371391]\n",
      "with b 0.1150171017571426 and loss 0.2348942598187311\n",
      "lt_loss 0.24173596897 is in [0.12080360004338139279, 0.35068961262630182762]\n",
      "with b 0.1149430062914602 and loss 0.2357466063348416\n",
      "lt_loss 0.24173596897 is in [0.12052249892813211851, 0.35026063360198833596]\n",
      "with b 0.1148690673369281 and loss 0.23539156626506022\n",
      "lt_loss 0.24173596897 is in [0.12084381341325943493, 0.35043438207546240282]\n",
      "with b 0.11479528433110149 and loss 0.23563909774436093\n",
      "lt_loss 0.24173596897 is in [0.12056362857089505947, 0.35000694199967541387]\n",
      "with b 0.11472165671439019 and loss 0.23528528528528525\n",
      "lt_loss 0.24173596897 is in [0.12028434980309328506, 0.3495807176631736124]\n",
      "with b 0.11464818393004016 and loss 0.23493253373313344\n",
      "lt_loss 0.24173596897 is in [0.12060477529444817157, 0.34975450614267761251]\n",
      "with b 0.11457486542411473 and loss 0.2351796407185629\n",
      "lt_loss 0.24173596897 is in [0.12047587782985998139, 0.34947927912081266921]\n",
      "with b 0.11450170064547634 and loss 0.23497757847533632\n",
      "lt_loss 0.24173596897 is in [0.12019817662587360674, 0.34905555471740995488]\n",
      "with b 0.11442868904576818 and loss 0.2346268656716418\n",
      "lt_loss 0.24173596897 is in [0.12066652461508969862, 0.34937818477388193905]\n",
      "with b 0.11435583007939612 and loss 0.23502235469448582\n",
      "lt_loss 0.24173596897 is in [0.12038949584410833793, 0.34895574225112974132]\n",
      "with b 0.11428312320351071 and loss 0.23467261904761905\n",
      "lt_loss 0.24173596897 is in [0.12026194326614143837, 0.34868307902212009042]\n",
      "with b 0.11421056787798932 and loss 0.23447251114413076\n",
      "lt_loss 0.24173596897 is in [0.11998646551470018573, 0.34826279264553716697]\n",
      "with b 0.1141381635654185 and loss 0.2341246290801187\n",
      "lt_loss 0.24173596897 is in [0.12074890508373839482, 0.34888072454589125204]\n",
      "with b 0.11406590973107644 and loss 0.23481481481481484\n",
      "lt_loss 0.24173596897 is in [0.12062157877246915128, 0.34860919045830007779]\n",
      "with b 0.11399380584291546 and loss 0.23461538461538461\n",
      "lt_loss 0.24173596897 is in [0.12093782366538279038, 0.34878152640847243093]\n",
      "with b 0.11392185137154483 and loss 0.23485967503692762\n",
      "lt_loss 0.24173596897 is in [0.12169567692365070022, 0.34939576850407794151]\n",
      "with b 0.11385004579021361 and loss 0.23554572271386431\n",
      "lt_loss 0.24173596897 is in [0.12245136105701789897, 0.35000813820660514608]\n",
      "with b 0.11377838857479361 and loss 0.2362297496318115\n",
      "lt_loss 0.24173596897 is in [0.12320488550211977641, 0.35061864390964497806]\n",
      "with b 0.1137068792037626 and loss 0.23691176470588238\n",
      "lt_loss 0.24173596897 is in [0.12292835949379486704, 0.35019939381016984559]\n",
      "with b 0.1136355171581875 and loss 0.23656387665198236\n",
      "lt_loss 0.24173596897 is in [0.12265270687594614918, 0.34978131071936174878]\n",
      "with b 0.1135643019217078 and loss 0.23621700879765395\n",
      "lt_loss 0.24173596897 is in [0.12296357521860240558, 0.34995004117964062518]\n",
      "with b 0.11349323298051911 and loss 0.23645680819912152\n",
      "lt_loss 0.24173596897 is in [0.12341979543980108325, 0.35026441508651467993]\n",
      "with b 0.1134223098233568 and loss 0.23684210526315788\n",
      "lt_loss 0.24173596897 is in [0.12314481842348370955, 0.34984788230644325857]\n",
      "with b 0.11335153194147979 and loss 0.2364963503649635\n",
      "lt_loss 0.24173596897 is in [0.12287070466988782302, 0.34943250232719669235]\n",
      "with b 0.11328089882865443 and loss 0.23615160349854225\n",
      "lt_loss 0.24173596897 is in [0.1233252523187158417, 0.34974607228099302558]\n",
      "with b 0.11321040998113859 and loss 0.23653566229985443\n",
      "lt_loss 0.24173596897 is in [0.12363319091628766078, 0.34991332071161929118]\n",
      "with b 0.11314006489766582 and loss 0.23677325581395348\n",
      "lt_loss 0.24173596897 is in [0.12452084809618728378, 0.35066057425504632006]\n",
      "with b 0.11306986307942953 and loss 0.2375907111756168\n",
      "lt_loss 0.24173596897 is in [0.12482628292645413237, 0.35082589098658928384]\n",
      "with b 0.11299980403006758 and loss 0.23782608695652172\n",
      "lt_loss 0.24173596897 is in [0.12556504762134323983, 0.35142482213263648294]\n",
      "with b 0.11292988725564664 and loss 0.23849493487698986\n",
      "lt_loss 0.24173596897 is in [0.12543468542321431491, 0.35115490995250808748]\n",
      "with b 0.1128601122646469 and loss 0.23829479768786122\n",
      "lt_loss 0.24173596897 is in [0.12530475952729117073, 0.35088571666318502107]\n",
      "with b 0.11279047856794694 and loss 0.2380952380952381\n",
      "lt_loss 0.24173596897 is in [0.12503117570447691564, 0.35047314706209370394]\n",
      "with b 0.1127209856788084 and loss 0.2377521613832853\n",
      "lt_loss 0.24173596897 is in [0.12576563307418919813, 0.35106889929991152988]\n",
      "with b 0.11265163311286115 and loss 0.23841726618705036\n",
      "lt_loss 0.24173596897 is in [0.12549229225558977685, 0.35065713303176654358]\n",
      "with b 0.1125824203880884 and loss 0.23807471264367816\n",
      "lt_loss 0.24173596897 is in [0.12521979501249086431, 0.35024648906211458543]\n",
      "with b 0.11251334702481185 and loss 0.23773314203730272\n",
      "lt_loss 0.24173596897 is in [0.12595100292710231793, 0.3508398280184564233]\n",
      "with b 0.11244441254567704 and loss 0.23839541547277937\n",
      "lt_loss 0.24173596897 is in [0.12582180841706491758, 0.35057304136834277486]\n",
      "with b 0.11237561647563893 and loss 0.23819742489270385\n",
      "lt_loss 0.24173596897 is in [0.12612161308662406256, 0.35073552977051875024]\n",
      "with b 0.11230695834194733 and loss 0.2384285714285714\n",
      "lt_loss 0.24173596897 is in [0.1259926607566804746, 0.35046953610494580023]\n",
      "with b 0.11223843767413265 and loss 0.23823109843081314\n",
      "lt_loss 0.24173596897 is in [0.12586413403019636181, 0.35020424203817968056]\n",
      "with b 0.11217005400399167 and loss 0.23803418803418802\n",
      "lt_loss 0.24173596897 is in [0.12573603097226435099, 0.34993964470341132333]\n",
      "with b 0.1121018068655735 and loss 0.23783783783783785\n",
      "lt_loss 0.24173596897 is in [0.12560834965938005858, 0.34967574124971090299]\n",
      "with b 0.11203369579516541 and loss 0.23764204545454548\n",
      "lt_loss 0.24173596897 is in [0.12548108817935912929, 0.34941252884191753569]\n",
      "with b 0.11196572033127919 and loss 0.23744680851063832\n",
      "lt_loss 0.24173596897 is in [0.12521260157176511418, 0.34900836160103942962]\n",
      "with b 0.11189788001463717 and loss 0.23711048158640227\n",
      "lt_loss 0.24173596897 is in [0.12593503070377914943, 0.34959537948009639097]\n",
      "with b 0.11183017438815862 and loss 0.23776520509193777\n",
      "lt_loss 0.24173596897 is in [0.12580801847198036514, 0.34933322446587272703]\n",
      "with b 0.11176260299694618 and loss 0.23757062146892655\n",
      "lt_loss 0.24173596897 is in [0.12554037763006328787, 0.34893070840660811438]\n",
      "with b 0.1116951653882724 and loss 0.2372355430183357\n",
      "lt_loss 0.24173596897 is in [0.12527354733913792506, 0.34852926956227053834]\n",
      "with b 0.1116278611115663 and loss 0.23690140845070423\n",
      "lt_loss 0.24173596897 is in [0.12514817104109346446, 0.34826955047789387443]\n",
      "with b 0.11156068971840022 and loss 0.23670886075949368\n",
      "lt_loss 0.24173596897 is in [0.12586589979932122363, 0.34885320132427427575]\n",
      "with b 0.11149365076247651 and loss 0.23735955056179775\n",
      "lt_loss 0.24173596897 is in [0.12658167134765052619, 0.34943515894687965373]\n",
      "with b 0.11142674379961458 and loss 0.2380084151472651\n",
      "lt_loss 0.24173596897 is in [0.12631510164027337506, 0.34903503841574906597]\n",
      "with b 0.11135996838773786 and loss 0.23767507002801122\n",
      "lt_loss 0.24173596897 is in [0.12618919339565648485, 0.34877584156937846416]\n",
      "with b 0.11129332408686099 and loss 0.23748251748251747\n",
      "lt_loss 0.24173596897 is in [0.12592402752974987679, 0.34837764844790375385]\n",
      "with b 0.11122681045907695 and loss 0.23715083798882683\n",
      "lt_loss 0.24173596897 is in [0.12565965661346389926, 0.34798051075055286274]\n",
      "with b 0.11116042706854448 and loss 0.23682008368200838\n",
      "lt_loss 0.24173596897 is in [0.12595318027897026147, 0.34814152724192115596]\n",
      "with b 0.11109417348147543 and loss 0.2370473537604457\n",
      "lt_loss 0.24173596897 is in [0.12568961415529633641, 0.34774571268754095321]\n",
      "with b 0.1110280492661223 and loss 0.23671766342141864\n",
      "lt_loss 0.24173596897 is in [0.12653794600723422548, 0.34846205399276580783]\n",
      "with b 0.11096205399276578 and loss 0.23750000000000002\n",
      "lt_loss 0.24173596897 is in [0.12627440916019488926, 0.34806678362759985168]\n",
      "with b 0.1108961872337025 and loss 0.23717059639389737\n",
      "lt_loss 0.24173596897 is in [0.12615016085504970889, 0.34781105798151534803]\n",
      "with b 0.11083044856323283 and loss 0.23698060941828253\n",
      "lt_loss 0.24173596897 is in [0.12602631043681877809, 0.34755598555211625333]\n",
      "with b 0.11076483755764875 and loss 0.23679114799446752\n",
      "lt_loss 0.24173596897 is in [0.1264553423373749319, 0.3478540499278184317]\n",
      "with b 0.11069935379522174 and loss 0.23715469613259668\n",
      "lt_loss 0.24173596897 is in [0.12619358935070568162, 0.34746158306308744246]\n",
      "with b 0.1106339968561909 and loss 0.23682758620689656\n",
      "lt_loss 0.24173596897 is in [0.12607035213454922951, 0.347207884780051379]\n",
      "with b 0.11056876632275106 and loss 0.2366391184573003\n",
      "lt_loss 0.24173596897 is in [0.12594750740940452438, 0.34695483096748674923]\n",
      "with b 0.11050366177904113 and loss 0.23645116918844564\n",
      "lt_loss 0.24173596897 is in [0.12568769081524139297, 0.34656505643750579182]\n",
      "with b 0.11043868281113219 and loss 0.2361263736263736\n",
      "lt_loss 0.24173596897 is in [0.12597733697377952455, 0.34672499498781172989]\n",
      "with b 0.11037382900701609 and loss 0.2363511659807956\n",
      "lt_loss 0.24173596897 is in [0.12571829730368011546, 0.34633649721686782241]\n",
      "with b 0.11030909995659387 and loss 0.23602739726027397\n",
      "lt_loss 0.24173596897 is in [0.1255968180178295146, 0.34608580852115811144]\n",
      "with b 0.1102444952516643 and loss 0.2358413132694938\n",
      "lt_loss 0.24173596897 is in [0.12533911119714752358, 0.34569914016897274056]\n",
      "with b 0.1101800144859126 and loss 0.23551912568306013\n",
      "lt_loss 0.24173596897 is in [0.12576428817484169853, 0.34599560268463991353]\n",
      "with b 0.11011565725489912 and loss 0.2358799454297408\n",
      "lt_loss 0.24173596897 is in [0.12550715995021882732, 0.34561000626231525024]\n",
      "with b 0.11005142315604821 and loss 0.23555858310626704\n",
      "lt_loss 0.24173596897 is in [0.12525078344945811404, 0.34522540702673237822]\n",
      "with b 0.10998731178863715 and loss 0.23523809523809525\n",
      "lt_loss 0.24173596897 is in [0.12594624246360636155, 0.34579288797117629928]\n",
      "with b 0.10992332275378497 and loss 0.23586956521739133\n",
      "lt_loss 0.24173596897 is in [0.12569006944732213915, 0.34540898075620568575]\n",
      "with b 0.10985945565444176 and loss 0.2355495251017639\n",
      "lt_loss 0.24173596897 is in [0.12638315169324029763, 0.34597457188399549644]\n",
      "with b 0.10979571009537759 and loss 0.23617886178861788\n",
      "lt_loss 0.24173596897 is in [0.12612718359964272818, 0.34559135496598647475]\n",
      "with b 0.10973208568317189 and loss 0.23585926928281462\n",
      "lt_loss 0.24173596897 is in [0.12587195851433785609, 0.34520912256674324281]\n",
      "with b 0.1096685820262027 and loss 0.23554054054054055\n",
      "lt_loss 0.24173596897 is in [0.12561747333014133821, 0.34482787079941334962]\n",
      "with b 0.10960519873463599 and loss 0.23522267206477734\n",
      "lt_loss 0.24173596897 is in [0.12536372495694325657, 0.34444759579777373126]\n",
      "with b 0.10954193542041524 and loss 0.2349056603773585\n",
      "lt_loss 0.24173596897 is in [0.12511071032159168381, 0.34406829371609337631]\n",
      "with b 0.10947879169725083 and loss 0.23458950201884252\n",
      "lt_loss 0.24173596897 is in [0.12593369518498162551, 0.34476522954620114625]\n",
      "with b 0.10941576718060977 and loss 0.2353494623655914\n",
      "lt_loss 0.24173596897 is in [0.12568069555927455228, 0.34438641853468521248]\n",
      "with b 0.10935286148770532 and loss 0.23503355704697987\n",
      "lt_loss 0.24173596897 is in [0.12542842442203067099, 0.34400857289700415009]\n",
      "with b 0.10929007423748674 and loss 0.2347184986595174\n",
      "lt_loss 0.24173596897 is in [0.12571235398551539042, 0.34416716408677372474]\n",
      "with b 0.10922740505062917 and loss 0.23493975903614456\n",
      "lt_loss 0.24173596897 is in [0.12546081489967442213, 0.34379052199872128792]\n",
      "with b 0.10916485354952343 and loss 0.23462566844919786\n",
      "lt_loss 0.24173596897 is in [0.12520999719714098752, 0.34341483591367338857]\n",
      "with b 0.1091024193582662 and loss 0.2343124165554072\n",
      "lt_loss 0.24173596897 is in [0.12495989789735018061, 0.34304010210264979097]\n",
      "with b 0.1090401021026498 and loss 0.23399999999999999\n",
      "lt_loss 0.24173596897 is in [0.12471051403591931761, 0.34266631685622445103]\n",
      "with b 0.10897790141015257 and loss 0.23368841544607188\n",
      "lt_loss 0.24173596897 is in [0.12446184266453931555, 0.34229347648439689689]\n",
      "with b 0.10891581690992878 and loss 0.2333776595744681\n",
      "lt_loss 0.24173596897 is in [0.12421388085086612629, 0.34192157731646455332]\n",
      "with b 0.1088538482327992 and loss 0.23306772908366533\n",
      "lt_loss 0.24173596897 is in [0.12396662567841401636, 0.34155061570089639833]\n",
      "with b 0.10879199501124118 and loss 0.2327586206896552\n",
      "lt_loss 0.24173596897 is in [0.1237200742464486386, 0.34118058800520700835]\n",
      "with b 0.10873025687937919 and loss 0.23245033112582783\n",
      "lt_loss 0.24173596897 is in [0.12347422366988196341, 0.34081149061583226878]\n",
      "with b 0.10866863347297516 and loss 0.23214285714285712\n",
      "lt_loss 0.24173596897 is in [0.12415377385327562576, 0.34136802271211402759]\n",
      "with b 0.10860712442941921 and loss 0.23276089828269483\n",
      "lt_loss 0.24173596897 is in [0.12404002259117181961, 0.34113148136661181065]\n",
      "with b 0.10854572938771999 and loss 0.2325857519788918\n",
      "lt_loss 0.24173596897 is in [0.12379486689951493816, 0.34076376287650611552]\n",
      "with b 0.1084844479884956 and loss 0.23227931488801054\n",
      "lt_loss 0.24173596897 is in [0.12368198328393058272, 0.34052854303185886575]\n",
      "with b 0.10842327987396415 and loss 0.23210526315789473\n",
      "lt_loss 0.24173596897 is in [0.12356944416883279547, 0.34029389354470201967]\n",
      "with b 0.10836222468793462 and loss 0.23193166885676741\n",
      "lt_loss 0.24173596897 is in [0.12385094889533083962, 0.3404535130469263926]\n",
      "with b 0.10830128207579777 and loss 0.2321522309711286\n",
      "lt_loss 0.24173596897 is in [0.12452494805335986849, 0.34100585142239370207]\n",
      "with b 0.10824045168451693 and loss 0.2327653997378768\n",
      "lt_loss 0.24173596897 is in [0.1242809998216740236, 0.34064046614691240178]\n",
      "with b 0.10817973316261918 and loss 0.2324607329842932\n",
      "lt_loss 0.24173596897 is in [0.12469133135615366459, 0.34092958367652609342]\n",
      "with b 0.10811912616018622 and loss 0.23281045751633989\n",
      "lt_loss 0.24173596897 is in [0.12444789708629798441, 0.34056515774398921081]\n",
      "with b 0.10805863032884562 and loss 0.2325065274151436\n",
      "lt_loss 0.24173596897 is in [0.12420514450874654833, 0.34020163515227042073]\n",
      "with b 0.10799824532176193 and loss 0.23220338983050848\n",
      "lt_loss 0.24173596897 is in [0.12500473753970539614, 0.34088067912696129458]\n",
      "with b 0.10793797079362794 and loss 0.23294270833333333\n",
      "lt_loss 0.24173596897 is in [0.12541218059544284591, 0.34116779339675479266]\n",
      "with b 0.10787780640065599 and loss 0.23328998699609882\n",
      "lt_loss 0.24173596897 is in [0.12568874170592417294, 0.34132424530706284571]\n",
      "with b 0.10781775180056932 and loss 0.2335064935064935\n",
      "lt_loss 0.24173596897 is in [0.1255755266807398185, 0.34109113998592688333]\n",
      "with b 0.10775780665259352 and loss 0.23333333333333334\n",
      "lt_loss 0.24173596897 is in [0.12546265114421006892, 0.34085859237910598463]\n",
      "with b 0.10769797061744796 and loss 0.23316062176165803\n",
      "lt_loss 0.24173596897 is in [0.12522074758703516384, 0.34049723430170997229]\n",
      "with b 0.10763824335733739 and loss 0.23285899094437257\n",
      "lt_loss 0.24173596897 is in [0.12510871396534853361, 0.34026596303723544157]\n",
      "with b 0.10757862453594347 and loss 0.232687338501292\n",
      "lt_loss 0.24173596897 is in [0.12499701521384151692, 0.34003524285067465716]\n",
      "with b 0.10751911381841656 and loss 0.23251612903225807\n",
      "lt_loss 0.24173596897 is in [0.12540111387090080441, 0.34032053561363528882]\n",
      "with b 0.10745971087136724 and loss 0.23286082474226805\n",
      "lt_loss 0.24173596897 is in [0.12528941732697440603, 0.3400902480526909466]\n",
      "with b 0.10740041536285827 and loss 0.23268983268983268\n",
      "lt_loss 0.24173596897 is in [0.12504951853888898738, 0.33973197246368169733]\n",
      "with b 0.10734122696239634 and loss 0.23239074550128533\n",
      "lt_loss 0.24173596897 is in [0.12570886877974363216, 0.34027315946159142346]\n",
      "with b 0.10728214534092391 and loss 0.23299101412066753\n",
      "lt_loss 0.24173596897 is in [0.12559734264970157103, 0.34004368299132409215]\n",
      "with b 0.10722317017081125 and loss 0.23282051282051283\n",
      "lt_loss 0.24173596897 is in [0.12625439285622586105, 0.34058299510792261477]\n",
      "with b 0.10716430112584836 and loss 0.23341869398207424\n",
      "lt_loss 0.24173596897 is in [0.126654052911601811, 0.34086512867407592342]\n",
      "with b 0.10710553788123707 and loss 0.23375959079283887\n",
      "lt_loss 0.24173596897 is in [0.12705273674465439315, 0.34114649697182070076]\n",
      "with b 0.10704688011358315 and loss 0.23409961685823755\n",
      "lt_loss 0.24173596897 is in [0.12745044800931568107, 0.34142710301109246984]\n",
      "with b 0.10698832750088841 and loss 0.2344387755102041\n",
      "lt_loss 0.24173596897 is in [0.12733763620102386827, 0.34119739564610984672]\n",
      "with b 0.106929879722543 and loss 0.23426751592356687\n",
      "lt_loss 0.24173596897 is in [0.12709792918953735641, 0.34084100210817258603]\n",
      "with b 0.10687153645931763 and loss 0.23396946564885499\n",
      "lt_loss 0.24173596897 is in [0.12774832903612320933, 0.34137492382283485259]\n",
      "with b 0.10681329739335584 and loss 0.23456162642947903\n",
      "lt_loss 0.24173596897 is in [0.1283971220557929005, 0.34190744647212589769]\n",
      "with b 0.1067551622081665 and loss 0.2351522842639594\n",
      "lt_loss 0.24173596897 is in [0.12815711529224566023, 0.34155137646947802965]\n",
      "with b 0.10669713058861617 and loss 0.23485424588086184\n",
      "lt_loss 0.24173596897 is in [0.12804434208287590602, 0.34132274652471900067]\n",
      "with b 0.10663920222092155 and loss 0.23468354430379745\n",
      "lt_loss 0.24173596897 is in [0.12793189754364120425, 0.3410946511289251748]\n",
      "with b 0.10658137679264197 and loss 0.2345132743362832\n",
      "lt_loss 0.24173596897 is in [0.12832483085581264382, 0.34137213884115702456]\n",
      "with b 0.10652365399267219 and loss 0.23484848484848483\n",
      "lt_loss 0.24173596897 is in [0.12821240280654588872, 0.34114446982901525107]\n",
      "with b 0.1064660335112347 and loss 0.23467843631778057\n",
      "lt_loss 0.24173596897 is in [0.12810030108103420687, 0.34091733116077949095]\n",
      "with b 0.10640851503987266 and loss 0.23450881612090685\n",
      "lt_loss 0.24173596897 is in [0.12798852437006691396, 0.34069072091295193871]\n",
      "with b 0.10635109827144251 and loss 0.23433962264150943\n",
      "lt_loss 0.24173596897 is in [0.12825395579336051899, 0.34084152159357417045]\n",
      "with b 0.10629378290010683 and loss 0.23454773869346734\n",
      "lt_loss 0.24173596897 is in [0.1280168818178197554, 0.34049001906047382526]\n",
      "with b 0.10623656862132705 and loss 0.2342534504391468\n",
      "lt_loss 0.24173596897 is in [0.12865763759997317361, 0.34101654786368590377]\n",
      "with b 0.10617945513185637 and loss 0.23483709273182954\n",
      "lt_loss 0.24173596897 is in [0.12854589328954135752, 0.34079077754900682917]\n",
      "with b 0.10612244212973272 and loss 0.2346683354192741\n",
      "lt_loss 0.24173596897 is in [0.12843447068572821923, 0.34056552931427175324]\n",
      "with b 0.10606552931427177 and loss 0.2345\n",
      "lt_loss 0.24173596897 is in [0.12907243217823488601, 0.34108986495035437114]\n",
      "with b 0.10600871638605976 and loss 0.23508114856429463\n",
      "lt_loss 0.24173596897 is in [0.12933477999544717996, 0.34123878608934088419]\n",
      "with b 0.10595200304694684 and loss 0.23528678304239403\n",
      "lt_loss 0.24173596897 is in [0.12922291735114319056, 0.34101369535122294518]\n",
      "with b 0.10589538900003986 and loss 0.23511830635118305\n",
      "lt_loss 0.24173596897 is in [0.12985764346323946938, 0.34153539136263116882]\n",
      "with b 0.10583887394969585 and loss 0.23569651741293532\n",
      "lt_loss 0.24173596897 is in [0.12974549270904406351, 0.34131040791207395424]\n",
      "with b 0.10578245760151495 and loss 0.235527950310559\n",
      "lt_loss 0.24173596897 is in [0.13037807869994907928, 0.34183035802461669839]\n",
      "with b 0.10572613966233382 and loss 0.2361042183622829\n",
      "lt_loss 0.24173596897 is in [0.13014172823908715104, 0.34148156791952499756]\n",
      "with b 0.10566991984021892 and loss 0.23581164807930607\n",
      "lt_loss 0.24173596897 is in [0.12990600413573824556, 0.34113359982465774056]\n",
      "with b 0.10561379784445973 and loss 0.23551980198019798\n",
      "lt_loss 0.24173596897 is in [0.1301653415711744588, 0.34128088834229897142]\n",
      "with b 0.10555777338556227 and loss 0.23572311495673673\n",
      "lt_loss 0.24173596897 is in [0.13054753654080691883, 0.34155122889129191366]\n",
      "with b 0.10550184617524248 and loss 0.23604938271604942\n",
      "lt_loss 0.24173596897 is in [0.13043561169380235576, 0.34132764354664157924]\n",
      "with b 0.10544601592641963 and loss 0.23588162762022197\n",
      "lt_loss 0.24173596897 is in [0.13106291961723343098, 0.3418434843236532461]\n",
      "with b 0.1053902823532099 and loss 0.23645320197044334\n",
      "lt_loss 0.24173596897 is in [0.13131972137274552925, 0.34198901171458528925]\n",
      "with b 0.1053346451709199 and loss 0.23665436654366542\n",
      "lt_loss 0.24173596897 is in [0.13108453226759608778, 0.34164274045967668592]\n",
      "with b 0.1052791040960403 and loss 0.2363636363636364\n",
      "lt_loss 0.24173596897 is in [0.13084996078566243916, 0.34129727847814128605]\n",
      "with b 0.10522365884623941 and loss 0.23607361963190185\n",
      "lt_loss 0.24173596897 is in [0.13110620066356459823, 0.34144281894427858104]\n",
      "with b 0.10516830914035698 and loss 0.2362745098039216\n",
      "lt_loss 0.24173596897 is in [0.1308722574191052701, 0.34109836681590077756]\n",
      "with b 0.10511305469839777 and loss 0.23598531211750304\n",
      "lt_loss 0.24173596897 is in [0.13063892627436704541, 0.34075471675741775268]\n",
      "with b 0.10505789524152537 and loss 0.2356968215158924\n",
      "lt_loss 0.24173596897 is in [0.1308946054053797825, 0.34090026638949194604]\n",
      "with b 0.10500283049205608 and loss 0.23589743589743586\n",
      "lt_loss 0.24173596897 is in [0.13151555446069362887, 0.3414112748075989745]\n",
      "with b 0.10494786017345266 and loss 0.2364634146341463\n",
      "lt_loss 0.24173596897 is in [0.13128241184839059552, 0.34106837986902716064]\n",
      "with b 0.10489298401031827 and loss 0.23617539585870886\n",
      "lt_loss 0.24173596897 is in [0.13117153063170694516, 0.3408479340884876807]\n",
      "with b 0.10483820172839037 and loss 0.2360097323600973\n",
      "lt_loss 0.24173596897 is in [0.1309394517085273324, 0.34050647781759663113]\n",
      "with b 0.10478351305453466 and loss 0.23572296476306198\n",
      "lt_loss 0.24173596897 is in [0.13119341238034820663, 0.34065124781382655206]\n",
      "with b 0.10472891771673919 and loss 0.23592233009708738\n",
      "lt_loss 0.24173596897 is in [0.13096194819225537298, 0.3403107790804719146]\n",
      "with b 0.10467441544410826 and loss 0.23563636363636364\n",
      "lt_loss 0.24173596897 is in [0.13073108362152113804, 0.3399710955552342484]\n",
      "with b 0.10462000596685657 and loss 0.2353510895883777\n",
      "lt_loss 0.24173596897 is in [0.13050081642505084734, 0.3396321944576577434]\n",
      "with b 0.10456568901630343 and loss 0.2350665054413543\n",
      "lt_loss 0.24173596897 is in [0.13111655499880475739, 0.34013948364853824335]\n",
      "with b 0.10451146432486676 and loss 0.2356280193236715\n",
      "lt_loss 0.24173596897 is in [0.13100708333172308984, 0.33992174658383778052]\n",
      "with b 0.10445733162605736 and loss 0.23546441495778045\n",
      "lt_loss 0.24173596897 is in [0.13137984187564732963, 0.34018642318459357821]\n",
      "with b 0.10440329065447312 and loss 0.23578313253012045\n",
      "lt_loss 0.24173596897 is in [0.13199241577358081234, 0.34069109806516773009]\n",
      "with b 0.10434934114579344 and loss 0.23634175691937426\n",
      "lt_loss 0.24173596897 is in [0.13260355562476519586, 0.34119452129831173703]\n",
      "with b 0.10429548283677326 and loss 0.23689903846153845\n",
      "lt_loss 0.24173596897 is in [0.13237293039310568665, 0.34085636132358099193]\n",
      "with b 0.10424171546523764 and loss 0.23661464585834333\n",
      "lt_loss 0.24173596897 is in [0.13226280055846112438, 0.34063887809861320699]\n",
      "with b 0.10418803877007606 and loss 0.23645083932853717\n",
      "lt_loss 0.24173596897 is in [0.13215297265846379093, 0.34042187764093734259]\n",
      "with b 0.10413445249123679 and loss 0.23628742514970058\n",
      "lt_loss 0.24173596897 is in [0.13204344554415411994, 0.34020535828359710351]\n",
      "with b 0.10408095636972148 and loss 0.2361244019138756\n",
      "lt_loss 0.24173596897 is in [0.13181474375923057929, 0.33986984405438952495]\n",
      "with b 0.10402755014757947 and loss 0.23584229390681005\n",
      "lt_loss 0.24173596897 is in [0.13218328433185888571, 0.34013175146766383428]\n",
      "with b 0.10397423356790246 and loss 0.23615751789976136\n",
      "lt_loss 0.24173596897 is in [0.13207422604472807137, 0.3399162387943660546]\n",
      "with b 0.103921006374819 and loss 0.23599523241954706\n",
      "lt_loss 0.24173596897 is in [0.13196546501984418587, 0.33970120164682243713]\n",
      "with b 0.10386786831348911 and loss 0.2358333333333333\n",
      "lt_loss 0.24173596897 is in [0.13257043651793914973, 0.34020007477813690722]\n",
      "with b 0.10381481913009889 and loss 0.23638525564803803\n",
      "lt_loss 0.24173596897 is in [0.13246141933788346812, 0.339985136481593897]\n",
      "with b 0.10376185857185521 and loss 0.23622327790973868\n",
      "lt_loss 0.24173596897 is in [0.13282719392144196058, 0.34024516669540261216]\n",
      "with b 0.10370898638698034 and loss 0.2365361803084223\n",
      "lt_loss 0.24173596897 is in [0.13271820525823152526, 0.34003060990764522042]\n",
      "with b 0.10365620232470683 and loss 0.23637440758293837\n",
      "lt_loss 0.24173596897 is in [0.13249116842094094126, 0.33969818069148510764]\n",
      "with b 0.10360350613527208 and loss 0.23609467455621302\n",
      "lt_loss 0.24173596897 is in [0.13226470526696615382, 0.339366500406792726]\n",
      "with b 0.10355089756991327 and loss 0.23581560283687944\n",
      "lt_loss 0.24173596897 is in [0.13262913247391938665, 0.3396258852356437985]\n",
      "with b 0.10349837638086219 and loss 0.2361275088547816\n",
      "lt_loss 0.24173596897 is in [0.13322858598054679313, 0.34012047062322681157]\n",
      "with b 0.10344594232134 and loss 0.2366745283018868\n",
      "lt_loss 0.24173596897 is in [0.13382666398283407649, 0.34061385427393864322]\n",
      "with b 0.10339359514555227 and loss 0.23722025912838635\n",
      "lt_loss 0.24173596897 is in [0.13371748892072798931, 0.34040015813809554324]\n",
      "with b 0.10334133460868376 and loss 0.23705882352941177\n",
      "lt_loss 0.24173596897 is in [0.13407864211830036738, 0.34065696305208748029]\n",
      "with b 0.10328916046689354 and loss 0.2373678025851939\n",
      "lt_loss 0.24173596897 is in [0.13443898386071839735, 0.34091312881533797352]\n",
      "with b 0.1032370724773098 and loss 0.23767605633802819\n",
      "lt_loss 0.24173596897 is in [0.13515021682354586008, 0.34152035761959598226]\n",
      "with b 0.10318507039802505 and loss 0.2383352872215709\n",
      "lt_loss 0.24173596897 is in [0.13492305210090188572, 0.34118936007708405844]\n",
      "with b 0.10313315398809107 and loss 0.23805620608899297\n",
      "lt_loss 0.24173596897 is in [0.13469645477026376268, 0.340859100785291802]\n",
      "with b 0.103081323007514 and loss 0.23777777777777778\n",
      "lt_loss 0.24173596897 is in [0.13493771250237665549, 0.34099686693687569772]\n",
      "with b 0.10302957721724953 and loss 0.2379672897196262\n",
      "lt_loss 0.24173596897 is in [0.13517844301403425522, 0.34113427577243010669]\n",
      "with b 0.10297791637919791 and loss 0.23815635939323218\n",
      "lt_loss 0.24173596897 is in [0.13495244762258856719, 0.34080512813498720082]\n",
      "with b 0.10292634025619932 and loss 0.23787878787878788\n",
      "lt_loss 0.24173596897 is in [0.1355419150666672401, 0.34129161229072502159]\n",
      "with b 0.10287484861202889 and loss 0.23841676367869613\n",
      "lt_loss 0.24173596897 is in [0.13531609367232888541, 0.34096297609511300175]\n",
      "with b 0.10282344121139204 and loss 0.23813953488372094\n",
      "lt_loss 0.24173596897 is in [0.13509083223815218644, 0.34063506787799180398]\n",
      "with b 0.1027721178199198 and loss 0.23786295005807198\n",
      "lt_loss 0.24173596897 is in [0.13544617516010520886, 0.34088793156843305576]\n",
      "with b 0.10272087820416392 and loss 0.23816705336426913\n",
      "lt_loss 0.24173596897 is in [0.13603247949065555567, 0.34137192375384040055]\n",
      "with b 0.10266972213159241 and loss 0.23870220162224798\n",
      "lt_loss 0.24173596897 is in [0.13661746174052635805, 0.34185476048169582963]\n",
      "with b 0.10261864937058472 and loss 0.2392361111111111\n",
      "lt_loss 0.24173596897 is in [0.13639187788182710603, 0.34152719726268160327]\n",
      "with b 0.10256765969042725 and loss 0.23895953757225435\n",
      "lt_loss 0.24173596897 is in [0.13697516399781367591, 0.34200866972043114655]\n",
      "with b 0.10251675286130875 and loss 0.2394919168591224\n",
      "lt_loss 0.24173596897 is in [0.13674975762019417336, 0.34168161492882542785]\n",
      "with b 0.10246592865431564 and loss 0.23921568627450981\n",
      "lt_loss 0.24173596897 is in [0.13710094219083041045, 0.3419313158736856928]\n",
      "with b 0.10241518684142764 and loss 0.23951612903225805\n",
      "lt_loss 0.24173596897 is in [0.13699105393221985838, 0.34172010832324617446]\n",
      "with b 0.10236452719551317 and loss 0.23935558112773303\n",
      "lt_loss 0.24173596897 is in [0.1368814528085257054, 0.34150935178917546375]\n",
      "with b 0.10231394949032487 and loss 0.23919540229885058\n",
      "lt_loss 0.24173596897 is in [0.13677213777390198612, 0.34129904477489247938]\n",
      "with b 0.10226345350049526 and loss 0.23903559127439725\n",
      "lt_loss 0.24173596897 is in [0.13654842888837603887, 0.34097450689144043201]\n",
      "with b 0.10221303900153218 and loss 0.23876146788990824\n",
      "lt_loss 0.24173596897 is in [0.1363252667387765682, 0.34065067827840556092]\n",
      "with b 0.10216270576981451 and loss 0.23848797250859108\n",
      "lt_loss 0.24173596897 is in [0.13610264939224070435, 0.3403275565574160888]\n",
      "with b 0.10211245358258768 and loss 0.2382151029748284\n",
      "lt_loss 0.24173596897 is in [0.13588057492489763467, 0.34000513936081661059]\n",
      "with b 0.1020622822179595 and loss 0.23794285714285712\n",
      "lt_loss 0.24173596897 is in [0.13611566242638273305, 0.34014004533617425707]\n",
      "with b 0.10201219145489576 and loss 0.2381278538812785\n",
      "lt_loss 0.24173596897 is in [0.13680634800318097755, 0.3407307101496126478]\n",
      "with b 0.10196218107321582 and loss 0.2387685290763968\n",
      "lt_loss 0.24173596897 is in [0.13669822750632026898, 0.34052272921349752144]\n",
      "with b 0.10191225085358864 and loss 0.2386104783599089\n",
      "lt_loss 0.24173596897 is in [0.13704544925182327031, 0.34077025040687980439]\n",
      "with b 0.10186240057752825 and loss 0.23890784982935154\n",
      "lt_loss 0.24173596897 is in [0.13739191542715570304, 0.34101717548193521967]\n",
      "with b 0.10181263002738974 and loss 0.23920454545454545\n",
      "lt_loss 0.24173596897 is in [0.13717009166062699155, 0.34069596963335702089]\n",
      "with b 0.10176293898636501 and loss 0.238933030646992\n",
      "lt_loss 0.24173596897 is in [0.13774245507444657366, 0.34116910955140378192]\n",
      "with b 0.10171332723847862 and loss 0.2394557823129252\n",
      "lt_loss 0.24173596897 is in [0.13842680565791698477, 0.34175439479508418206]\n",
      "with b 0.1016637945685836 and loss 0.24009060022650058\n",
      "lt_loss 0.24173596897 is in [0.1389965189661493683, 0.34222520049086424532]\n",
      "with b 0.10161434076235742 and loss 0.2406108597285068\n",
      "lt_loss 0.24173596897 is in [0.13888701179483198267, 0.34201694300742790933]\n",
      "with b 0.10156496560629798 and loss 0.24045197740112995\n",
      "lt_loss 0.24173596897 is in [0.13866491801972985476, 0.34169625579516854641]\n",
      "with b 0.10151566888771935 and loss 0.2401805869074492\n",
      "lt_loss 0.24173596897 is in [0.13900705580592850885, 0.34193995659542431031]\n",
      "with b 0.10146645039474791 and loss 0.24047350620067642\n",
      "lt_loss 0.24173596897 is in [0.13878539278638440946, 0.34162001261902097404]\n",
      "with b 0.10141730991631828 and loss 0.2402027027027027\n",
      "lt_loss 0.24173596897 is in [0.1385642611942761171, 0.34130075567861473118]\n",
      "with b 0.10136824724216931 and loss 0.23993250843644542\n",
      "lt_loss 0.24173596897 is in [0.1389054569382834059, 0.34154398126396379176]\n",
      "with b 0.1013192621628402 and loss 0.2402247191011236\n",
      "lt_loss 0.24173596897 is in [0.13868475215210679385, 0.34122546109143975235]\n",
      "with b 0.10127035446966648 and loss 0.23995510662177327\n",
      "lt_loss 0.24173596897 is in [0.13924932806316103751, 0.34169237597271340245]\n",
      "with b 0.1012215239547762 and loss 0.24047085201793722\n",
      "lt_loss 0.24173596897 is in [0.13902879733807424478, 0.34137433816024598254]\n",
      "with b 0.10117277041108588 and loss 0.24020156774916013\n",
      "lt_loss 0.24173596897 is in [0.13880879227374343099, 0.34105697953833713498]\n",
      "with b 0.10112409363229685 and loss 0.23993288590604028\n",
      "lt_loss 0.24173596897 is in [0.13858931105638250258, 0.34074029788216497749]\n",
      "with b 0.10107549341289124 and loss 0.23966480446927374\n",
      "lt_loss 0.24173596897 is in [0.13892838759472886379, 0.34098232669098538228]\n",
      "with b 0.10102696954812825 and loss 0.23995535714285712\n",
      "lt_loss 0.24173596897 is in [0.13870932654946019347, 0.34066637021754087034]\n",
      "with b 0.10097852183404035 and loss 0.23968784838350055\n",
      "lt_loss 0.24173596897 is in [0.13927029536686894029, 0.34113059550172786238]\n",
      "with b 0.10093015006742947 and loss 0.24020044543429842\n",
      "lt_loss 0.24173596897 is in [0.13905140513099992217, 0.34081511322272639575]\n",
      "with b 0.10088185404586325 and loss 0.23993325917686317\n",
      "lt_loss 0.24173596897 is in [0.13883303309899527878, 0.34050030023433808246]\n",
      "with b 0.10083363356767139 and loss 0.23966666666666667\n",
      "lt_loss 0.24173596897 is in [0.13861517749480622985, 0.34018615435868987396]\n",
      "with b 0.10078548843194182 and loss 0.23940066592674805\n",
      "lt_loss 0.24173596897 is in [0.13839783655039633592, 0.33987267342743071596]\n",
      "with b 0.10073741843851719 and loss 0.23913525498891353\n",
      "lt_loss 0.24173596897 is in [0.13829175047690386857, 0.33967059725288573091]\n",
      "with b 0.10068942338799095 and loss 0.2389811738648948\n",
      "lt_loss 0.24173596897 is in [0.13818593054661454378, 0.33946893671002259518]\n",
      "with b 0.10064150308170401 and loss 0.23882743362831857\n",
      "lt_loss 0.24173596897 is in [0.13885385649041379064, 0.34004117113389553673]\n",
      "with b 0.10059365732174089 and loss 0.23944751381215468\n",
      "lt_loss 0.24173596897 is in [0.13874771232306931656, 0.33983948414492187728]\n",
      "with b 0.10054588591092627 and loss 0.2392935982339956\n",
      "lt_loss 0.24173596897 is in [0.13853157981465391568, 0.33952795712029648634]\n",
      "with b 0.1004981886528213 and loss 0.2390297684674752\n",
      "lt_loss 0.24173596897 is in [0.1383159544720684031, 0.33921708517550869244]\n",
      "with b 0.10045056535172013 and loss 0.23876651982378855\n",
      "lt_loss 0.24173596897 is in [0.13898092258119298936, 0.33978695420648574732]\n",
      "with b 0.10040301581264638 and loss 0.23938393839383937\n",
      "lt_loss 0.24173596897 is in [0.13887522938941970763, 0.33958630907211878602]\n",
      "with b 0.10035553984134954 and loss 0.23923076923076925\n",
      "lt_loss 0.24173596897 is in [0.13866002960531423338, 0.3392763040939174024]\n",
      "with b 0.10030813724430157 and loss 0.2389681668496158\n",
      "lt_loss 0.24173596897 is in [0.13932252550463991581, 0.33984414116202665834]\n",
      "with b 0.10026080782869336 and loss 0.2395833333333333\n",
      "lt_loss 0.24173596897 is in [0.13921689766657188714, 0.33964400047143472605]\n",
      "with b 0.1002135514024314 and loss 0.2394304490690033\n",
      "lt_loss 0.24173596897 is in [0.13954916833089864303, 0.33988190387916700219]\n",
      "with b 0.10016636777413418 and loss 0.23971553610503282\n",
      "lt_loss 0.24173596897 is in [0.1400993224818438132, 0.340337835988101578]\n",
      "with b 0.10011925675312888 and loss 0.2402185792349727\n",
      "lt_loss 0.24173596897 is in [0.13988411372828127299, 0.34002855002717724542]\n",
      "with b 0.100072218149448 and loss 0.23995633187772927\n",
      "lt_loss 0.24173596897 is in [0.14043276349334962716, 0.34048326704100151385]\n",
      "with b 0.10002525177382596 and loss 0.24045801526717558\n",
      "lt_loss 0.24173596897 is in [0.14021772099367685316, 0.34017443586906825903]\n",
      "with b 0.0999783574376957 and loss 0.24019607843137256\n",
      "lt_loss 0.24173596897 is in [0.14000317668990486242, 0.33986624659627573397]\n",
      "with b 0.09993153495318544 and loss 0.2399347116430903\n",
      "lt_loss 0.24173596897 is in [0.13978912891036293642, 0.33955869717659353801]\n",
      "with b 0.09988478413311529 and loss 0.23967391304347824\n",
      "lt_loss 0.24173596897 is in [0.13968415362377256672, 0.33936036320576057346]\n",
      "with b 0.09983810479099402 and loss 0.23952225841476657\n",
      "lt_loss 0.24173596897 is in [0.139470976144016795, 0.33905396962604827937]\n",
      "with b 0.09979149674101573 and loss 0.23926247288503252\n",
      "lt_loss 0.24173596897 is in [0.13925829047279919548, 0.3387482100689125919]\n",
      "with b 0.09974495979805668 and loss 0.2390032502708559\n",
      "lt_loss 0.24173596897 is in [0.13915432007514183521, 0.33855130763048579823]\n",
      "with b 0.09969849377767197 and loss 0.23885281385281382\n",
      "lt_loss 0.24173596897 is in [0.13948303663904279559, 0.33878723363122742462]\n",
      "with b 0.09965209849609233 and loss 0.23913513513513512\n",
      "lt_loss 0.24173596897 is in [0.1392711160785911062, 0.33848266361903306398]\n",
      "with b 0.09960577377022099 and loss 0.23887688984881209\n",
      "lt_loss 0.24173596897 is in [0.13905968230836740496, 0.3381787211436283469]\n",
      "with b 0.09955951941763047 and loss 0.23861920172599788\n",
      "lt_loss 0.24173596897 is in [0.13884873370895789435, 0.33787540422207656965]\n",
      "with b 0.09951333525655935 and loss 0.23836206896551723\n",
      "lt_loss 0.24173596897 is in [0.13939176705340178275, 0.33832620926522033455]\n",
      "with b 0.09946722110590926 and loss 0.23885898815931106\n",
      "lt_loss 0.24173596897 is in [0.13918097375239274482, 0.33802332732287598827]\n",
      "with b 0.09942117678524164 and loss 0.23860215053763437\n",
      "lt_loss 0.24173596897 is in [0.13897066254687939768, 0.33772106677642876882]\n",
      "with b 0.0993752021147747 and loss 0.23834586466165408\n",
      "lt_loss 0.24173596897 is in [0.13919001638934072607, 0.33784861022010137521]\n",
      "with b 0.09932929691538031 and loss 0.23851931330472104\n",
      "lt_loss 0.24173596897 is in [0.13898020458627435847, 0.33754712660343622055]\n",
      "with b 0.09928346100858092 and loss 0.2382636655948553\n",
      "lt_loss 0.24173596897 is in [0.13877087109394597997, 0.33724625952703907172]\n",
      "with b 0.09923769421654653 and loss 0.23800856531049253\n",
      "lt_loss 0.24173596897 is in [0.13931067743469977005, 0.33769467015888310346]\n",
      "with b 0.09919199636209165 and loss 0.23850267379679144\n",
      "lt_loss 0.24173596897 is in [0.13910149597919099773, 0.33739423051653549823]\n",
      "with b 0.09914636726867226 and loss 0.23824786324786326\n",
      "lt_loss 0.24173596897 is in [0.13889278982446240374, 0.33709440334522811078]\n",
      "with b 0.09910080676038287 and loss 0.23799359658484526\n",
      "lt_loss 0.24173596897 is in [0.13921760644678857211, 0.33732823577069548371]\n",
      "with b 0.09905531466195344 and loss 0.23827292110874201\n",
      "lt_loss 0.24173596897 is in [0.13975475243874019293, 0.33777453403623319828]\n",
      "with b 0.09900989079874649 and loss 0.2387646432374867\n",
      "lt_loss 0.24173596897 is in [0.1402907841521820187, 0.33821985414569033512]\n",
      "with b 0.09896453499675414 and loss 0.23925531914893616\n",
      "lt_loss 0.24173596897 is in [0.14018808554227196739, 0.33802657970746236016]\n",
      "with b 0.09891924708259518 and loss 0.23910733262486716\n",
      "lt_loss 0.24173596897 is in [0.13997947630120127771, 0.33772753006822547883]\n",
      "with b 0.09887402688351211 and loss 0.23885350318471338\n",
      "lt_loss 0.24173596897 is in [0.14061969417135916638, 0.33827744262609577008]\n",
      "with b 0.0988288742273683 and loss 0.23944856839872747\n",
      "lt_loss 0.24173596897 is in [0.14115265173532101639, 0.33872022962061121287]\n",
      "with b 0.09878378894264508 and loss 0.2399364406779661\n",
      "lt_loss 0.24173596897 is in [0.14147286935320133039, 0.33895041107007906067]\n",
      "with b 0.09873877085843888 and loss 0.2402116402116402\n",
      "lt_loss 0.24173596897 is in [0.14200385461414630206, 0.33939149422306302828]\n",
      "with b 0.09869381980445835 and loss 0.24069767441860465\n",
      "lt_loss 0.24173596897 is in [0.1425337465431494588, 0.33983161776519266173]\n",
      "with b 0.09864893561102159 and loss 0.24118268215417105\n",
      "lt_loss 0.24173596897 is in [0.14232415193314079671, 0.33953238815124736627]\n",
      "with b 0.09860411810905328 and loss 0.24092827004219408\n",
      "lt_loss 0.24173596897 is in [0.14211502696896971543, 0.33923376122913351249]\n",
      "with b 0.0985593671300819 and loss 0.24067439409905161\n",
      "lt_loss 0.24173596897 is in [0.14232742275692095157, 0.33935678776939487422]\n",
      "with b 0.09851468250623696 and loss 0.2408421052631579\n",
      "lt_loss 0.24173596897 is in [0.1422239422389021124, 0.33916407037939444447]\n",
      "with b 0.09847006407024617 and loss 0.24069400630914828\n",
      "lt_loss 0.24173596897 is in [0.14201566481515548457, 0.33886668812602099843]\n",
      "with b 0.09842551165543277 and loss 0.24044117647058824\n",
      "lt_loss 0.24173596897 is in [0.14191278392842157641, 0.33867483411984700137]\n",
      "with b 0.09838102509571273 and loss 0.2402938090241343\n",
      "lt_loss 0.24173596897 is in [0.14170532449558198573, 0.33837853294676606408]\n",
      "with b 0.09833660422559204 and loss 0.24004192872117402\n",
      "lt_loss 0.24173596897 is in [0.14202188724549044685, 0.33860638500581852206]\n",
      "with b 0.09829224888016402 and loss 0.24031413612565447\n",
      "lt_loss 0.24173596897 is in [0.14191940512162976029, 0.3384153229118430084]\n",
      "with b 0.09824795889510662 and loss 0.24016736401673638\n",
      "lt_loss 0.24173596897 is in [0.14171267132696704905, 0.33812013954032649199]\n",
      "with b 0.09820373410667974 and loss 0.23991640543364678\n",
      "lt_loss 0.24173596897 is in [0.14161078055433173883, 0.33792992925777681767]\n",
      "with b 0.09815957435172253 and loss 0.23977035490605428\n",
      "lt_loss 0.24173596897 is in [0.14213478122056605324, 0.33836574015586773356]\n",
      "with b 0.09811547946765085 and loss 0.2402502606882169\n",
      "lt_loss 0.24173596897 is in [0.14265771737421217846, 0.33880061595912114303]\n",
      "with b 0.0980714492924545 and loss 0.24072916666666666\n",
      "lt_loss 0.24173596897 is in [0.14245118438941556382, 0.33850615171880499288]\n",
      "with b 0.09802748366469471 and loss 0.24047866805411028\n",
      "lt_loss 0.24173596897 is in [0.14266090822098914659, 0.33862807306799214135]\n",
      "with b 0.09798358242350148 and loss 0.24064449064449064\n",
      "lt_loss 0.24173596897 is in [0.14245485479911329518, 0.33833434561625536086]\n",
      "with b 0.09793974540857102 and loss 0.24039460020768433\n",
      "lt_loss 0.24173596897 is in [0.14235299019543851129, 0.33814493511576482199]\n",
      "with b 0.09789597246016314 and loss 0.24024896265560167\n",
      "lt_loss 0.24173596897 is in [0.14214773658090121278, 0.33785226341909868619]\n",
      "with b 0.09785226341909875 and loss 0.23999999999999996\n",
      "lt_loss 0.24173596897 is in [0.14246053301195910068, 0.33807776926547361551]\n",
      "with b 0.09780861812675724 and loss 0.24026915113871636\n",
      "lt_loss 0.24173596897 is in [0.14225564609819377204, 0.33778571894834186207]\n",
      "with b 0.09776503642507403 and loss 0.2400206825232678\n",
      "lt_loss 0.24173596897 is in [0.14215451490131325585, 0.33759755121438916881]\n",
      "with b 0.09772151815653796 and loss 0.2398760330578512\n",
      "lt_loss 0.24173596897 is in [0.14236321650557376417, 0.3377193428339514969]\n",
      "with b 0.09767806316418888 and loss 0.24004127966976263\n",
      "lt_loss 0.24173596897 is in [0.14215914314137462204, 0.33742848572460476531]\n",
      "with b 0.09763467129161509 and loss 0.2397938144329897\n",
      "lt_loss 0.24173596897 is in [0.14195551652539101228, 0.3371382012912927939]\n",
      "with b 0.09759134238295089 and loss 0.2395468589083419\n",
      "lt_loss 0.24173596897 is in [0.14175233523975958039, 0.33684848780550791236]\n",
      "with b 0.09754807628287415 and loss 0.23930041152263373\n",
      "lt_loss 0.24173596897 is in [0.14154959787254320358, 0.33655934354575078871]\n",
      "with b 0.09750487283660378 and loss 0.23905447070914698\n",
      "lt_loss 0.24173596897 is in [0.14144997242221757361, 0.33637343620201237693]\n",
      "with b 0.09746173188989742 and loss 0.23891170431211498\n",
      "lt_loss 0.24173596897 is in [0.14196596209556655577, 0.3368032686736642245]\n",
      "with b 0.09741865328904885 and loss 0.2393846153846154\n",
      "lt_loss 0.24173596897 is in [0.14227600246337651635, 0.33702727622514805361]\n",
      "with b 0.09737563688088575 and loss 0.23965163934426228\n",
      "lt_loss 0.24173596897 is in [0.14248308002561560492, 0.33714844505115004747]\n",
      "with b 0.09733268251276722 and loss 0.23981576253838283\n",
      "lt_loss 0.24173596897 is in [0.14228076211465784384, 0.33686034217982069316]\n",
      "with b 0.09728979003258141 and loss 0.23957055214723927\n",
      "lt_loss 0.24173596897 is in [0.14207888340788610293, 0.3365728019853723163]\n",
      "with b 0.09724695928874309 and loss 0.2393258426966292\n",
      "lt_loss 0.24173596897 is in [0.14187744252286976776, 0.33628582278325264143]\n",
      "with b 0.09720419013019144 and loss 0.2390816326530612\n",
      "lt_loss 0.24173596897 is in [0.14177837488209357741, 0.33610133969486866157]\n",
      "with b 0.09716148240638756 and loss 0.23893985728848113\n",
      "lt_loss 0.24173596897 is in [0.14239236566201562972, 0.33663003759664011927]\n",
      "with b 0.09711883596731226 and loss 0.23951120162932787\n",
      "lt_loss 0.24173596897 is in [0.14290340345657703836, 0.33705590478350433425]\n",
      "with b 0.09707625066346365 and loss 0.2399796541200407\n",
      "lt_loss 0.24173596897 is in [0.14280367202812888072, 0.3368711247198385994]\n",
      "with b 0.09703372634585486 and loss 0.23983739837398374\n",
      "lt_loss 0.24173596897 is in [0.14260264576342984721, 0.33658517149545341685]\n",
      "with b 0.09699126286601178 and loss 0.23959390862944163\n",
      "lt_loss 0.24173596897 is in [0.14311199185100692555, 0.33700971200294849162]\n",
      "with b 0.09694886007597078 and loss 0.2400608519269777\n",
      "lt_loss 0.24173596897 is in [0.1429111113510549147, 0.33672414700760766593]\n",
      "with b 0.09690651782827639 and loss 0.2398176291793313\n",
      "lt_loss 0.24173596897 is in [0.14281187738434483747, 0.33654034933630294635]\n",
      "with b 0.09686423597597907 and loss 0.2396761133603239\n",
      "lt_loss 0.24173596897 is in [0.14301620605203838044, 0.33666023479730444734]\n",
      "with b 0.09682201437263302 and loss 0.2398382204246714\n",
      "lt_loss 0.24173596897 is in [0.14281610672366573667, 0.33637581246825343229]\n",
      "with b 0.09677985287229386 and loss 0.23959595959595958\n",
      "lt_loss 0.24173596897 is in [0.14332279357462071601, 0.33679829623365376001]\n",
      "with b 0.09673775132951651 and loss 0.24006054490413722\n",
      "lt_loss 0.24173596897 is in [0.14322364523935679492, 0.33661506443806255007]\n",
      "with b 0.09669570959935286 and loss 0.23991935483870966\n",
      "lt_loss 0.24173596897 is in [0.14302401667211650516, 0.3363314717468159909]\n",
      "with b 0.09665372753734973 and loss 0.23967774420946625\n",
      "lt_loss 0.24173596897 is in [0.14282481471876332102, 0.33604842471785634217]\n",
      "with b 0.09661180499954652 and loss 0.23943661971830985\n",
      "lt_loss 0.24173596897 is in [0.14312855061983831284, 0.33626843430478475794]\n",
      "with b 0.09656994184247321 and loss 0.23969849246231154\n",
      "lt_loss 0.24173596897 is in [0.14292969340215311291, 0.3359859692484492566]\n",
      "with b 0.09652813792314806 and loss 0.23945783132530118\n",
      "lt_loss 0.24173596897 is in [0.14283156076250924649, 0.33580434696066030487]\n",
      "with b 0.09648639309907552 and loss 0.23931795386158478\n",
      "lt_loss 0.24173596897 is in [0.14273364948518271755, 0.33562306394167096268]\n",
      "with b 0.09644470722824411 and loss 0.23917835671342683\n",
      "lt_loss 0.24173596897 is in [0.14253585876981461622, 0.33534201910806321623]\n",
      "with b 0.09640308016912431 and loss 0.23893893893893892\n"
     ]
    }
   ],
   "source": [
    "e.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fabulous.FABULOUS.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_regret': 29.864031029689794,\n",
       " 'exp_regret': 31.507883957998672,\n",
       " 'total_rewards': -271.5999999999986}"
      ]
     },
     "execution_count": 1100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 0] 0.345651583594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([LossTuple(loss=0.24729281430529226, br=[0, 0, 0, 0, 0, 1], attacker=<StochasticAttacker id:1 resources:1>),\n",
       "  LossTuple(loss=0.33614949498421326, br=[1, 0, 0, 0, 0, 0], attacker=<StochasticAttacker id:1 resources:1>),\n",
       "  LossTuple(loss=0.34565158359362325, br=[0, 0, 0, 0, 1, 0], attacker=<StochasticAttacker id:1 resources:1>)],)"
      ]
     },
     "execution_count": 1093,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.get_best_responder().compute_strategy(), a.opt_loss())\n",
    "e.agent.opt_lt, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 1, 0],\n",
       " [1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 0, 1],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 1, 0]]"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[h[0] for h in e.game.strategy_history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([[0, 0, 0, 0, 1, 0],\n",
    " [1, 0, 0, 0, 0, 0],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1],\n",
    " [0, 0, 0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lt_loss 0.235200535889 is in [0.19553636942449839631, 0.53936559135981543278]\n",
      "with b 0.1719146109676585 and loss 0.3674509803921569\n",
      "LossTuple(loss=0.18590356728181023, br=[0, 0, 1, 0, 0, 0], attacker=<StochasticAttacker id:1 resources:1>)\n",
      "LossTuple(loss=0.23520053588908357, br=[0, 1, 0, 0, 0, 0], attacker=<StochasticAttacker id:1 resources:1>)\n",
      "LossTuple(loss=0.28834530472000469, br=[0, 0, 0, 0, 1, 0], attacker=<StochasticAttacker id:1 resources:1>)\n",
      "[0, 0, 0, 0, 1, 0] 0.28834530472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 1087,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.run_interaction()\n",
    "for lt in e.agent.opt_lt:\n",
    "    print(lt)\n",
    "print(a.get_best_responder().compute_strategy(), a.opt_loss())\n",
    "e.agent.tau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6, 0.2, 0.0, 0.2, 0.0, 0.0]"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.mock_sto.compute_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 0] 0.27710843373493976\n",
      "[1, 0, 0, 0, 0, 0] 0.37108433734939755\n",
      "[0, 1, 0, 0, 0, 0] 0.37831325301204816\n",
      "[0, 0, 0, 0, 0, 1] 0.3855421686746988\n",
      "[0, 0, 0, 1, 0, 0] 0.43855421686746987\n",
      "[0, 0, 1, 0, 0, 0] 0.46265060240963857\n"
     ]
    }
   ],
   "source": [
    "for f in e.agent.avg_rewards:\n",
    "    print(f.fixed_strategy, -e.agent.avg_rewards[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t \t \t \t\t \t\n",
      "0.4\t0.5\t0.3\t0.1\t0.7\t0.8\t\n",
      "\t \t \t \t \t \t\n",
      "------------------------------------------------\n",
      "\t \t \t \t \t \t\n",
      "0.4\t0.5\t0.3\t0.1\t0.7\t0.8\t\n",
      "\t \t \t \t \t \t\n",
      "------------------------------------------------\n",
      " \t \t\t \t \t \t\n",
      "0.4\t0.5\t0.3\t0.1\t0.7\t0.8\t\n",
      " \t\t \t \t \t \t\n",
      "------------------------------------------------\n",
      " \t \t\t \t \t \t\n",
      "0.4\t0.5\t0.3\t0.1\t0.7\t0.8\t\n",
      "\t \t \t \t \t \t\n"
     ]
    }
   ],
   "source": [
    "print(util.game_str(e.game))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: [2], 1: [3]},\n",
       " {0: [0], 1: [2]},\n",
       " {0: [5], 1: [2]},\n",
       " {0: [5], 1: [3]},\n",
       " {0: [5], 1: [0]},\n",
       " {0: [5], 1: [3]}]"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.mock_sto.game.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "self = e.agent\n",
    "self.norm_const = max([v[self.id] for v in self.game.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.norm_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function sorted in module builtins:\n",
      "\n",
      "sorted(iterable, key=None, reverse=False)\n",
      "    Return a new list containing all items from the iterable in ascending order.\n",
      "    \n",
      "    A custom key function can be supplied to customize the sort order, and the\n",
      "    reverse flag can be set to request the result in descending order.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<FixedActionDefender id:0 resources:1>: -0.75,\n",
       " <FixedActionDefender id:0 resources:1>: -0.5}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.avg_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: [1], 1: [0]},\n",
       " {0: [1], 1: [0]},\n",
       " {0: [0], 1: [0]},\n",
       " {0: [0], 1: [1]},\n",
       " {0: [0], 1: [0]},\n",
       " {0: [0], 1: [0]}]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpi('2.0', '3.0')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpi(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16128183810759994, 0.8387181618924] [0, 1]\n",
      "[0.69736230169271662, 0.30263769830728338] [1, 0]\n",
      "[0.130854094058935, 0.86914590594106511] [0, 1]\n"
     ]
    }
   ],
   "source": [
    "for p in e.game.profiles:\n",
    "    if isinstance(p, attackers.StochasticAttacker):\n",
    "        print(p.distribution, p.get_best_responder().compute_strategy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_best_responder().compute_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<UnknownStochasticAttacker id:1 resources:1>,\n",
       " <StochasticAttacker id:1 resources:1>,\n",
       " <StochasticAttacker id:1 resources:1>,\n",
       " <StochasticAttacker id:1 resources:1>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] [1, 0]\n",
      "[0, 1] [0, 1]\n",
      "[0, 1] [0, 1]\n",
      "[0, 1] [1, 0]\n"
     ]
    }
   ],
   "source": [
    "self = e.agent\n",
    "for lt in self.opt_lt:\n",
    "    loss = [-self.avg_rewards[k] for k\n",
    "            in self.avg_rewards\n",
    "            if k.last_strategy == lt.br]\n",
    "    print(k.last_strategy, lt.br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [1, 0]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k.fixed_strategy for k in self.avg_rewards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = mpmath.mpi(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.1 in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<FixedActionDefender id:0 resources:1>: -0.3333333333333333,\n",
       " <FixedActionDefender id:0 resources:1>: -0.8333333333333334}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.avg_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.87916302864945817, 0.12083697135054182]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets_dict = {i:[] for i in range(2,13)}\n",
    "T = 15 #np.random.randint(2,10)\n",
    "time_horizon =1000\n",
    "while sum([len(targets_dict[x]) for x in range(2,13)]) < 9:\n",
    "    targets = [round(x,3) for x in util.gen_norm_targets(T)]\n",
    "    values = tuple((v, v) for v in targets)\n",
    "    g = game.Game(values, time_horizon)\n",
    "    g.attackers = [1]\n",
    "    g.defenders = [0]\n",
    "    s = util.support(g)\n",
    "    if len(targets_dict[len(s)])==0:\n",
    "        targets_dict[len(s)].append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [[0.94, 0.709]],\n",
       " 3: [[0.899, 0.872, 0.872]],\n",
       " 4: [[0.706, 0.796, 0.744, 0.821]],\n",
       " 5: [[0.659, 0.763, 0.858, 0.681, 0.73]],\n",
       " 6: [[0.605, 0.986, 0.931, 0.629, 0.703, 0.594]],\n",
       " 7: [[0.715, 0.676, 0.675, 0.88, 0.925, 0.656, 0.89]],\n",
       " 8: [[0.636, 0.674, 0.958, 0.742, 0.736, 0.764, 0.676, 0.687]],\n",
       " 9: [[0.989, 0.873, 0.74, 0.973, 0.73, 0.894, 0.778, 0.769, 0.741]],\n",
       " 10: [[0.818, 0.987, 0.864, 0.937, 0.924, 0.872, 0.914, 0.991, 0.81, 0.921]],\n",
       " 11: [],\n",
       " 12: []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_horizon =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = 2\n",
    "P = 1\n",
    "targets = translate(targets_dict[T][0])\n",
    "distributions = []\n",
    "for i in range(P):\n",
    "    distributions.append(tuple(gen_distr(T)))\n",
    "values = tuple((v, v) for v in targets)\n",
    "g = game.Game(values, time_horizon)\n",
    "#print(T, targets)\n",
    "profiles = [attackers.StackelbergAttacker(g, 1),\n",
    "            attackers.UnknownStochasticAttacker(g, 1)]\n",
    "for d in distributions[1:]:\n",
    "    #print(d)\n",
    "    profiles.append(attackers.StochasticAttacker(g, 1, 1, *d))\n",
    "#agent = defenders.BR_MAB(g, 0, 1)\n",
    "agent = detection.HOLMES(g, 0, 1, 2)\n",
    "attacker = attackers.StochasticAttacker(g, 1, 1, *distributions[0])\n",
    "g.set_players([agent], [attacker], profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = runner.Configuration(deepcopy(g), \"trial\", \"trial\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2 = runner.Configuration(deepcopy(g), \"trial\", \"trial2\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm -rf trial/trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e =runner.Experiment(deepcopy(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5140483379364014\n",
      " \t\t\n",
      "0.298\t0.413\t\n",
      "\t \t\n",
      "{<StackelbergAttacker id:1 resources:1>: 0.6000000000000001, <UnknownStochasticAttacker id:1 resources:1>: 0.4}\n",
      "{0: (0.41812798874824186, 0.5818720112517581), 1: [0.74074067539405486, 0.25925932460594497]}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "e.run_interaction()\n",
    "print(time.time() - start_time)\n",
    "print(game_str(e.game, lenght=7))\n",
    "print(e.agent.belief)\n",
    "print(e.game.strategy_history[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.29799999999999993, 0.29799999999999993),\n",
       " (0.4129999999999999, 0.4129999999999999))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7109999999999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.29799999999999993 + 0.4129999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " state  b: [0.5, 0.5] r: 0 p: 1\n",
      " branches:\n",
      "\n",
      " (0, 1)\n",
      "\t exp_regret  0.10512025\n",
      "\t branches:\n",
      "\n",
      "\t (1, 0)\n",
      "\t\t state  b: [0.6666666666666666, 0.3333333333333333] r: -0.29799999999999993 p: 0.75\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (1, 0)\n",
      "\t\t\t exp_regret  0.22248347398030935\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.7109999999999999 p: 0.5833333333333333\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.16666666666666666\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  0.11155595182841069\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.7109999999999999 p: 0.034843999062353484\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.5959999999999999 p: 0.38791467416783876\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.29799999999999993 p: 0.27875199249882787\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.048489334270979845\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  0.11158295182841065\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.7109999999999999 p: 0.24507466010314105\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.5959999999999999 p: 0.09664533520862635\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.0700213314580403\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.29799999999999993 p: 0.3382586732301922\n",
      "\t (1, 1)\n",
      "\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.25\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (1, 0)\n",
      "\t\t\t exp_regret  0.01916666666666667\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.16666666666666666\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.08333333333333333\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  -0.006435701828410686\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.06968799812470697\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.048489334270979845\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.034843999062353484\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.09697866854195969\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  -0.006347701828410681\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.0700213314580403\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.048322667604313176\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.03501066572902015\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.09664533520862635\n",
      " (0.41812798874824186, 0.5818720112517581)\n",
      "\t exp_regret  0.04714779469413936\n",
      "\t branches:\n",
      "\n",
      "\t (0, 1)\n",
      "\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.10453199718706047\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (0, 1)\n",
      "\t\t\t exp_regret  0.03278820311767462\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.7109999999999999 p: 0.034843999062353484\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.06968799812470697\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  0.04048076777655922\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.8259999999999998 p: 0.029138502495774977\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.7109999999999999 p: 0.020274747814465997\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.014569251247887488\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.040549495628931995\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  0.04051756303956906\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.8259999999999998 p: 0.02927787849202439\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.7109999999999999 p: 0.02020505981634129\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.014638939246012195\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.04041011963268258\n",
      "\t (1, 0)\n",
      "\t\t state  b: [0.6666666666666666, 0.3333333333333333] r: -0.29799999999999993 p: 0.4364040084388186\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (0, 1)\n",
      "\t\t\t exp_regret  0.10487281399981405\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.5959999999999999 p: 0.38791467416783876\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.048489334270979845\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  0.06491128605750159\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.7109999999999999 p: 0.020274747814466\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.5959999999999999 p: 0.22571669165211075\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.29799999999999993 p: 0.162197982515728\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.028214586456513844\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  0.06492699660180536\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.7109999999999999 p: 0.14260208538105568\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.5959999999999999 p: 0.05623521557594377\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.04074345296601592\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.29799999999999993 p: 0.19682325451580318\n",
      "\t (0, 0)\n",
      "\t\t state  b: [0.6666666666666666, 0.3333333333333333] r: 0.0 p: 0.3135959915611814\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (1, 0)\n",
      "\t\t\t exp_regret  -0.00042503798012346466\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.4129999999999999 p: 0.2439079934364744\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.06968799812470697\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  -0.04680693971432291\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.014569251247887488\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.29799999999999993 p: 0.16219798251572798\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: 0.0 p: 0.11655400998309991\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.020274747814465997\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  -0.04679565025862672\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.4129999999999999 p: 0.10247257472208537\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.04041011963268258\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.02927787849202439\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: 0.0 p: 0.14143541871438903\n",
      "\t (1, 1)\n",
      "\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.14546800281293953\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (1, 0)\n",
      "\t\t\t exp_regret  0.011152546882325367\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.09697866854195969\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.048489334270979845\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  -0.00374475476671394\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.040549495628932\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.028214586456513844\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.020274747814466\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.05642917291302769\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  -0.0036935500297237862\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.04074345296601592\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.028117607787971885\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.02037172648300796\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.05623521557594377\n",
      " (0.42012798874824187, 0.5798720112517581)\n",
      "\t exp_regret  0.05120964731029027\n",
      "\t branches:\n",
      "\n",
      "\t (0, 1)\n",
      "\t\t state  b: [0.6666666666666666, 0.3333333333333333] r: -0.4129999999999999 p: 0.3150959915611814\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (1, 0)\n",
      "\t\t\t exp_regret  0.15221943154636497\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.8259999999999998 p: 0.2800853258321612\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.03501066572902015\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  0.09113137723844308\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.8259999999999998 p: 0.02927787849202439\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.7109999999999999 p: 0.1426020853810557\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.4129999999999999 p: 0.10247257472208536\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.04074345296601591\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  0.09119250586080596\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.8259999999999998 p: 0.1176716846197619\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.7109999999999999 p: 0.020301705151549918\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.014708960577470237\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.4129999999999999 p: 0.16241364121239935\n",
      "\t (1, 0)\n",
      "\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.14496800281293953\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (0, 1)\n",
      "\t\t\t exp_regret  0.03208625128926394\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.5959999999999999 p: 0.09664533520862635\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.048322667604313176\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  0.02838872534287349\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.7109999999999999 p: 0.02020505981634129\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.5959999999999999 p: 0.05623521557594377\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.04041011963268258\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.028117607787971885\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  0.02837103924653031\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.7109999999999999 p: 0.020301705151549918\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.5959999999999999 p: 0.056041924905526515\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.040603410303099836\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.028020962452763257\n",
      "\t (0, 0)\n",
      "\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.10503199718706047\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (1, 0)\n",
      "\t\t\t exp_regret  -0.01445940494608532\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.03501066572902015\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.0700213314580403\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  -0.010731378999694865\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.014638939246012195\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.04074345296601591\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.02927787849202439\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.020371726483007956\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  -0.010744192903351685\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.014708960577470237\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.040603410303099836\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.029417921154940473\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.020301705151549918\n",
      "\t (1, 1)\n",
      "\t\t state  b: [0.6666666666666666, 0.3333333333333333] r: 0.0 p: 0.4349040084388186\n",
      "\t\t branches:\n",
      "\n",
      "\t\t (0, 1)\n",
      "\t\t\t exp_regret  -0.028374988860007784\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.29799999999999993 p: 0.3382586732301922\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.09664533520862635\n",
      "\t\t (0.41812798874824186, 0.5818720112517581)\n",
      "\t\t\t exp_regret  -0.05383336422859781\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.4129999999999999 p: 0.04041011963268258\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: -0.29799999999999993 p: 0.19682325451580318\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.8571428571428572, 0.14285714285714288] r: 0.0 p: 0.14143541871438903\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.05623521557594377\n",
      "\t\t (0.42012798874824187, 0.5798720112517581)\n",
      "\t\t\t exp_regret  -0.053748992850960665\n",
      "\t\t\t branches:\n",
      "\n",
      "\t\t\t (0, 1)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: -0.4129999999999999 p: 0.16241364121239935\n",
      "\t\t\t (1, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: -0.29799999999999993 p: 0.028020962452763257\n",
      "\t\t\t (0, 0)\n",
      "\t\t\t\t state  b: [0.0, 1.0] r: 0.0 p: 0.020301705151549918\n",
      "\t\t\t (1, 1)\n",
      "\t\t\t\t state  b: [0.75, 0.25] r: 0.0 p: 0.22416769962210606\n"
     ]
    }
   ],
   "source": [
    "e.agent.tree.print_tree(end=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "util.plot_conf2(\"exp_regret\", [c], \"trial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm -rf trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = runner.Batch(\"/home/lorenzo/Scrivania/Experiments/UnknownStochastic_Stackelberg2/t4/p1/br_mab1-1_br_expert1-1_b2bw2w1_holmes1-1.csv\",\n",
    "                \"trial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.parse_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Configuration game:1000,0.778,0.893,0.545,0.747,br_mab1-1,sto1-0.471429133561-0.00602317029063-0.096473268935-0.426074427213,sta1,unk_stochastic_attacker1,sto1-0.0346193189847-0.0966672214518-0.379762168635-0.488951290929 experiments:[] stats:{}>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.configurations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = deepcopy(b.configurations[0].game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = runner.Configuration(g, \".\", \"ciao\", print_results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "util.plot_conf2(\"exp_regret\", [c], \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1.csv                           Fighting Stochastic-2.0.ipynb\r\n",
      "B2BW2W_expert_mab1.csv            Fighting Stochastic.ipynb\r\n",
      "B2BW2W_expert_mab2.csv            gurobi.log\r\n",
      "\u001b[0m\u001b[01;34mbatch\u001b[0m/                            help.txt\r\n",
      "batch1.csv                        Il carcere sovraffollato.ipynb\r\n",
      "batch.csv                         Linear Programming Examples.ipynb\r\n",
      "\u001b[01;34mciao\u001b[0m/                             Matplotlib trials.ipynb\r\n",
      "ciao.txt                          plot\r\n",
      "Compare Algorithms.ipynb          Presentation.ipynb\r\n",
      "Compare configurations.ipynb      prova.csv\r\n",
      "Compute Losses.ipynb              Results.ipynb\r\n",
      "\u001b[01;34mconcurrent\u001b[0m/                       Run Batch.ipynb\r\n",
      "\u001b[01;34mconcurrent1\u001b[0m/                      Run Configuration.ipynb\r\n",
      "\u001b[01;34mdifficulties\u001b[0m/                     Runner.ipynb\r\n",
      "Example-Copy1.ipynb               Stackerlberg Best Response.ipynb\r\n",
      "Example-Copy2.ipynb               status.txt\r\n",
      "Example-Copy3.ipynb               \u001b[01;34msto_sta\u001b[0m/\r\n",
      "\u001b[01;32mExample.ipynb\u001b[0m*                    \u001b[01;34msto_sta1\u001b[0m/\r\n",
      "Experiments-1.ipynb               \u001b[01;34mtrial\u001b[0m/\r\n",
      "Experiments-Prepare.ipynb         Tutorial.ipynb\r\n",
      "Experiments-Runner.ipynb          Untitled.ipynb\r\n",
      "\u001b[01;35mexp_regret.png\u001b[0m                    Watch Images-Copy1.ipynb\r\n",
      "Fighting Stackelberg-Copy1.ipynb  Watch Images.ipynb\r\n",
      "Fighting Stackelberg.ipynb        \u001b[01;35mwat.jpeg\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = runner.Experiment(g, 45333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform\n",
      "1.404613567831535\n",
      "1.0884789134632844\n",
      "-0.44447984592909195\n",
      "1.4893842466621894\n",
      "-0.29647691163777634\n",
      "-0.2604539637001497\n",
      "0.17516859941865592\n",
      "0.3318221104763115\n",
      "0.06682730874152987\n",
      "-0.0513341196736391\n",
      "-0.08178556329469044\n",
      "-0.22740471991963096\n",
      "-0.27344128420270875\n",
      "-0.5006459158220038\n",
      "-0.6259784330242586\n",
      "-0.31903861462725674\n",
      "-0.17474240944648484\n",
      "-0.5088426484985966\n",
      "-0.47674104393793637\n",
      "-0.19346136714711515\n",
      "-0.33971333195567754\n",
      "-0.36512899988274444\n",
      "-0.4468543745262948\n",
      "-0.33405759688170267\n",
      "-0.19913266106844552\n",
      "-0.4674503026311515\n",
      "-0.5518659186165786\n",
      "-0.1885813497705484\n",
      "-0.3381673082935635\n",
      "-0.50749260136533\n",
      "-0.4839845385228221\n",
      "-0.3150854952984752\n",
      "-0.21075277462361858\n",
      "-0.6065548297629414\n",
      "-0.5392268694015836\n",
      "-0.33538294761434195\n",
      "-0.26859164362795684\n",
      "-0.6568714940915499\n",
      "-0.6059925210789266\n",
      "-0.32905070331221065\n",
      "-0.23226561740507734\n",
      "-0.6292372204394215\n",
      "-0.5952625177376483\n",
      "-0.3674699103940948\n",
      "-0.18038606664889745\n",
      "-0.5889775299489857\n",
      "-0.6440683909789091\n",
      "-0.42413021862786343\n",
      "-0.34800777383370074\n",
      "-0.6366582177489405\n",
      "-0.6458572826249939\n",
      "-0.4390715854430385\n",
      "-0.285618625688204\n",
      "-0.5863085826619702\n",
      "-0.7213286305335174\n",
      "-0.42774786232419876\n",
      "-0.2813499460235067\n",
      "-0.6277582879555825\n",
      "-0.6635861915667889\n",
      "-0.47106305824007905\n",
      "-0.2479978438539695\n",
      "-0.6529361079962543\n",
      "-0.6207517694626357\n",
      "-0.4651710430420796\n",
      "-0.2584055887230359\n",
      "-0.6517082828245611\n",
      "-0.7126318926207584\n",
      "-0.4202019711205392\n",
      "-0.3140129812878666\n",
      "-0.7177451095333792\n",
      "-0.7244496443711504\n",
      "-0.4510777148034094\n",
      "-0.26325642542736577\n",
      "-0.6420110441261406\n",
      "-0.6431658186730866\n",
      "-0.4046828177761308\n",
      "-0.3450487909548374\n",
      "-0.6749460147305627\n",
      "-0.6662812227471647\n",
      "-0.3880422572826128\n",
      "-0.28275824112897474\n",
      "-0.6735787346320831\n",
      "-0.7088756167533099\n",
      "-0.38779117078815495\n",
      "-0.30986162535860384\n",
      "-0.7185791321216413\n",
      "-0.7170197786528884\n",
      "-0.4644856951658755\n",
      "-0.30370044358970755\n",
      "-0.7004608717596575\n",
      "-0.7060318725472261\n",
      "-0.4797877919545015\n",
      "-0.2369249523794632\n",
      "-0.6628737298829442\n",
      "-0.7331545637383053\n",
      "-0.44393493068264306\n",
      "-0.2763870373359468\n",
      "-0.6472494706075628\n",
      "-0.6686323436959477\n",
      "-0.43938398355817776\n",
      "-0.2699040530873663\n",
      "-0.6570749916795335\n",
      "-0.6575692762029051\n",
      "-0.47422001497060357\n",
      "-0.3052060783711114\n",
      "-0.665632456055638\n",
      "-0.6724953570644658\n",
      "-0.483477727693732\n",
      "-0.3278261043988319\n",
      "-0.7167396811293186\n",
      "-0.7010814054997948\n",
      "-0.4385625240338968\n",
      "-0.3051576216892487\n",
      "-0.695734041009162\n",
      "-0.7133529825960186\n",
      "-0.48056340894383276\n",
      "-0.3015143092984598\n",
      "-0.7294716099365111\n",
      "-0.6699519668776741\n",
      "-0.46639682196659915\n",
      "-0.30819603437683346\n",
      "-0.6827735446338998\n",
      "-0.7112391532328508\n",
      "-0.43298246873780905\n",
      "-0.2838600684817272\n",
      "-0.7211918374666468\n",
      "-0.7243330659373975\n",
      "-0.42806667049365765\n",
      "-0.2941203488786177\n",
      "-0.6675206959043608\n",
      "-0.6979540942270364\n",
      "-0.4789822226999516\n",
      "-0.30981440582234754\n",
      "-0.6923932957272002\n",
      "-0.6547389664015913\n",
      "-0.48049599777167373\n",
      "-0.31289450003007935\n",
      "-0.677627446320936\n",
      "-0.6610411553317583\n",
      "-0.4577168806599502\n",
      "-0.3069171348165111\n",
      "-0.6829901988737178\n",
      "-0.6894396820764069\n",
      "-0.44598643803387894\n",
      "-0.3257321195052289\n",
      "-0.7181679756007682\n",
      "-0.662297102129874\n",
      "-0.4391569479519299\n",
      "-0.3162125721408465\n",
      "-0.7011787539794688\n",
      "-0.6983163757047489\n",
      "-0.443944625148752\n",
      "-0.3265208142110025\n",
      "-0.7096668246956155\n",
      "-0.7047567740290164\n",
      "-0.43600946765237336\n",
      "-0.2841827270477257\n",
      "-0.6948153253409121\n",
      "-0.6842941847416978\n",
      "-0.45977999939794856\n",
      "-0.28080711895188154\n",
      "-0.7212611719450657\n",
      "-0.6943489584523517\n",
      "-0.4672552853107301\n",
      "-0.2854719187999937\n",
      "-0.7203761537519605\n",
      "-0.7144619197373625\n",
      "-0.45376590210830625\n",
      "-0.326780891815822\n",
      "-0.7007435626534076\n",
      "-0.6605142992286999\n",
      "-0.4686161332770937\n",
      "-0.32122279551128674\n",
      "-0.7170487064109696\n",
      "-0.6648626356173308\n",
      "-0.4641529787248644\n",
      "-0.3299782862964547\n",
      "-0.6993775652598069\n",
      "-0.6954484973032714\n",
      "-0.4335867922536245\n",
      "-0.3061056963252066\n",
      "-0.6898752307614748\n",
      "-0.702916163964972\n",
      "-0.4437530587778618\n",
      "-0.2982259034254481\n",
      "-0.7169304132224898\n",
      "-0.6750551445775274\n",
      "-0.43660347517788434\n",
      "-0.3132081197267834\n",
      "-0.69812380272642\n",
      "-0.6821211313204836\n",
      "-0.42911726333387323\n",
      "-0.31883912955821975\n",
      "-0.7141370664652701\n",
      "-0.6921501867156155\n",
      "-0.4305061093952009\n",
      "-0.34382610467499813\n",
      "-0.711393328600145\n",
      "-0.6793638963479125\n",
      "-0.4445222323121108\n",
      "-0.35306130155944687\n",
      "-0.6953644708903091\n",
      "-0.6906437605676363\n",
      "-0.4463548103135001\n",
      "-0.31851994538609774\n",
      "-0.7058250013799235\n",
      "-0.6798217756567704\n",
      "-0.4658737588367434\n",
      "-0.3458408953298531\n",
      "-0.7172123590683124\n",
      "-0.6960186803298157\n",
      "-0.4365087756812095\n",
      "-0.3246824327154517\n",
      "-0.7114371226775205\n",
      "-0.709874378452872\n",
      "-0.4494732278301107\n",
      "-0.34457213703579703\n",
      "-0.7108151657242759\n",
      "-0.6959066192401103\n",
      "-0.4513066035074543\n",
      "-0.32212407551801364\n",
      "-0.6951278462343927\n",
      "-0.6991381405331484\n",
      "-0.45236044339199893\n",
      "-0.3251910038887765\n",
      "-0.69717040265336\n",
      "-0.6862310707009884\n",
      "-0.4512611635632531\n",
      "-0.32557252384178087\n",
      "-0.7013316171330974\n",
      "-0.7197991731913731\n",
      "-0.475156997971248\n",
      "-0.3145795228340163\n",
      "-0.7213274828023947\n",
      "-0.6924886900927136\n",
      "-0.4742713780379109\n",
      "-0.31415687408377585\n",
      "-0.7042908168014053\n",
      "-0.69821460722177\n",
      "-0.4802729669814562\n",
      "-0.3330560287969371\n",
      "-0.7032462982527248\n",
      "-0.7118489290794277\n",
      "-0.4625339367730274\n",
      "-0.3038090281313191\n",
      "-0.7175006261225646\n",
      "-0.7048785976094436\n",
      "-0.4801147304585592\n",
      "-0.2963753584419033\n",
      "-0.7219569807437416\n",
      "-0.7214950240186571\n",
      "-0.45999150884417445\n",
      "-0.3147699970172956\n",
      "-0.7129111974667589\n",
      "-0.7079696078926824\n",
      "-0.4746457486620313\n",
      "-0.29903468908619024\n",
      "-0.7060121432897274\n",
      "-0.6996591838616245\n",
      "-0.47026634963348934\n",
      "-0.30616278899955285\n",
      "-0.717224673093339\n",
      "-0.7150123618843722\n",
      "-0.4677689633575199\n",
      "-0.32120030095894475\n",
      "-0.72682433043689\n",
      "-0.7200808439654671\n",
      "-0.46834579904708973\n",
      "-0.3179520011337646\n",
      "-0.703052154615258\n",
      "-0.7210408572992453\n",
      "-0.4658092325125067\n",
      "-0.3237696187726982\n",
      "-0.7219964940133344\n",
      "-0.7225179345636373\n",
      "-0.4557237559365037\n",
      "-0.3186047342793726\n",
      "-0.7269701756946804\n",
      "-0.7190948893344166\n",
      "-0.45033359674742207\n",
      "-0.3207882916333635\n",
      "-0.7111383146075302\n",
      "-0.7095695050198977\n",
      "-0.4636024897491496\n",
      "-0.3290183702747421\n",
      "-0.7066483254609026\n",
      "-0.7241096928659357\n",
      "-0.4615841266368974\n",
      "-0.3073193517010514\n",
      "-0.7227032660294695\n",
      "-0.7049350043495284\n",
      "-0.4522147686308106\n",
      "-0.30215135465336745\n",
      "-0.72214557302001\n",
      "-0.7279267225346628\n",
      "-0.47202383107082074\n",
      "-0.31682256989584673\n",
      "-0.7225912355043103\n",
      "-0.7206650148681368\n",
      "-0.46663474594827276\n",
      "-0.32229103274490306\n",
      "-0.7111531466694438\n",
      "-0.7218087421172418\n",
      "-0.4652742487312695\n",
      "-0.3285238105582948\n",
      "-0.7220844815262397\n",
      "-0.722040239977994\n",
      "-0.4502443279537716\n",
      "-0.32229391129363794\n",
      "-0.7176802089483753\n",
      "-0.7156027778836827\n",
      "-0.4630244709814122\n",
      "-0.32211034876406475\n",
      "-0.7340691636284271\n",
      "-0.7276333456378044\n",
      "-0.4531629323386439\n",
      "-0.32783329457063226\n",
      "-0.7141056820374624\n",
      "-0.7278204951776232\n",
      "-0.46272337347422\n",
      "-0.3315951270107417\n",
      "-0.7323864628869129\n",
      "-0.7293884897553203\n",
      "-0.45808731857012597\n",
      "-0.32771865400825817\n",
      "-0.719619114957954\n",
      "-0.7153265849750013\n",
      "-0.4470145310485119\n",
      "-0.318290348204272\n",
      "-0.7235636669921849\n",
      "-0.732745141093053\n",
      "-0.4506066889955753\n",
      "-0.31993069981451516\n",
      "-0.7203508584622103\n",
      "-0.7095837157439737\n",
      "-0.45807257671439405\n",
      "-0.3370468384933709\n",
      "-0.7343637723412199\n",
      "-0.7200004348405475\n",
      "-0.4521481302843954\n",
      "-0.32488655144325573\n",
      "-0.718583911526489\n",
      "-0.7161760115905345\n",
      "-0.45207309626586595\n",
      "-0.32511387785797025\n",
      "-0.7125386790621465\n",
      "-0.7168254463218631\n",
      "-0.4570227039989608\n",
      "-0.3324973022208535\n",
      "-0.7226163712642766\n",
      "-0.7078889618890619\n",
      "-0.45243343126123736\n",
      "-0.3275971304410206\n",
      "-0.722062633071947\n",
      "-0.7154578490787527\n",
      "-0.4587000700509696\n",
      "-0.3315152294120369\n",
      "-0.7336616273701948\n",
      "-0.7015068134894917\n",
      "-0.4441885928208059\n",
      "-0.32838611999275313\n",
      "-0.7146561433324412\n",
      "-0.7153614155099215\n",
      "-0.4622431555806038\n",
      "-0.3208396188237487\n",
      "-0.7273950685224078\n",
      "-0.7185293921038141\n",
      "-0.4489278384142136\n",
      "-0.32809927638647457\n",
      "-0.7162782252425182\n",
      "-0.706640251372334\n",
      "-0.4482516265456708\n",
      "-0.32163280016601486\n",
      "-0.7225655156579244\n",
      "-0.7076540941217035\n",
      "-0.44487215018832665\n",
      "-0.32854568406170426\n",
      "-0.721707798311002\n",
      "-0.7093162125067176\n",
      "-0.46326676791340066\n",
      "-0.33629170582129064\n",
      "-0.7264958169454503\n",
      "-0.7020713485882929\n",
      "-0.45189221245901984\n",
      "-0.335117614453198\n",
      "-0.7264142242500595\n",
      "-0.7204289827342418\n",
      "-0.4458026214822745\n",
      "-0.32375910420367915\n",
      "-0.7355293336800395\n",
      "-0.7064605117596783\n",
      "-0.44872114655051537\n",
      "-0.32596165737323135\n",
      "-0.7166256308260874\n",
      "-0.7148126704585502\n",
      "-0.4620478020847972\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    e.run_interaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_regret': 35.960780232780778,\n",
       " 'exp_regret': 22.677175004483665,\n",
       " 'total_rewards': -412.19500000000437}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3762342197672186"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.players[1].opt_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e.agent.arms.items())[2][1].mock_sto is e.game.profiles[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.arms[0].mock_sto is e.game.profiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<UnknownStochasticAttacker id:1 resources:1>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.profiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e.agent.arms.items())[1][1].embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1] -0.42754807692307695\n",
      "[0, 0, 1, 0] -0.6911826923076922\n",
      "[1, 0, 0, 0] -0.3770288461538462\n",
      "[0, 1, 0, 0] -0.7350000000000001\n"
     ]
    }
   ],
   "source": [
    "d1 = list(e.agent.arms.items())[0][1].avg_rewards\n",
    "for k in d1:\n",
    "    print(k.last_strategy, d1[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_finalized': True,\n",
       " 'algorithm': <ExpAlgorithm.fpls: 3>,\n",
       " 'arms': (<FixedActionDefender id:0 resources:1>,\n",
       "  <FixedActionDefender id:0 resources:1>,\n",
       "  <FixedActionDefender id:0 resources:1>,\n",
       "  <FixedActionDefender id:0 resources:1>),\n",
       " 'avg_rewards': {<FixedActionDefender id:0 resources:1>: -0.42754807692307695,\n",
       "  <FixedActionDefender id:0 resources:1>: -0.6911826923076922,\n",
       "  <FixedActionDefender id:0 resources:1>: -0.3770288461538462,\n",
       "  <FixedActionDefender id:0 resources:1>: -0.7350000000000001},\n",
       " 'embedded': False,\n",
       " 'feedbacks': [],\n",
       " 'game': <Game values:[[0.778, 0.778], [0.893, 0.893], [0.545, 0.545], [0.747, 0.747]] players{0: <HOLMES id:0 resources:1>, 1: <StochasticAttacker id:1 resources:1>} time_horizon:1000>,\n",
       " 'id': 0,\n",
       " 'last_strategy': [1, 0, 0, 0],\n",
       " 'learning': <Learning.EXPERT: 2>,\n",
       " 'mock_sto': <UnknownStochasticAttacker id:1 resources:1>,\n",
       " 'norm_const': 0.893,\n",
       " 'resources': 1,\n",
       " 'sel_arm': <FixedActionDefender id:0 resources:1>}"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e.agent.arms.items())[0][1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Learning.MAB: 1>"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_regret': 25.536780232781361,\n",
       " 'exp_regret': 41.187497530224164,\n",
       " 'total_rewards': -401.77100000000274}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: (0, 0, 0, 1), 1: [0.471429133561, 0.00602317029063, 0.096473268935, 0.426074427213]}\n",
      "{<UnknownStochasticAttacker id:1 resources:1>: 1.0, <StochasticAttacker id:1 resources:1>: 2.800258122799861e-48, <StackelbergAttacker id:1 resources:1>: 0.0}\n",
      "{0: [3], 1: [3]} 111\n"
     ]
    }
   ],
   "source": [
    "e.run_interaction()\n",
    "print(e.game.strategy_history[-1])\n",
    "print(e.agent.belief)\n",
    "#print(util.game_str(e.game, lenght=7))\n",
    "print(e.game.history[-1], e.agent.tau())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e.agent.arms.items())[0][1].compute_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4434782608695652,\n",
       " 0.017391304347826087,\n",
       " 0.08695652173913043,\n",
       " 0.45217391304347826]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.profiles[1].last_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.471429133561, 0.00602317029063, 0.096473268935, 0.426074427213]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.players[1].distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0, 1), (0, 0, 1, 0)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.get_br_strategies(e.agent.arms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0, 1), (0, 1, 0, 0)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tuple(e.agent.arms[k].compute_strategy()) for k in e.agent.profiles if k.__class__.name != attackers.StackelbergAttacker.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<StochasticAttacker id:1 resources:1>,\n",
       " <UnknownStochasticAttacker id:1 resources:1>,\n",
       " <StackelbergAttacker id:1 resources:1>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.agent.tree.branches[(0,0,0,1)].branches[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p 0.32900284734860696\n",
    "p 0.11090171664439692\n",
    "p 0.11500577150033305\n",
    "p 0.44508966450667015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.3, 0.1, 0.1, 0.5\n",
    "0.0346193189847, 0.0966672214518, 0.379762168635, 0.488951290929\n",
    "0.471429133561, 0.00602317029063, 0.096473268935, 0.426074427213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " state  b: [0.014497096810704484, 0.0, 0.9855029031892955] r: 0 p: 1\n",
      " branches:\n",
      "\n",
      " (0, 0, 0, 1)\n",
      "\t exp_regret  -2.3314683517128287e-15\n",
      "\t branches:\n",
      "\n",
      "\t (3, 0)\n",
      "\t\t state  b: [0.0015254567639351483, 0.0, 0.9984745432360649] r: -0.778 p: 0.32900284734860696\n",
      "\t (3, 2)\n",
      "\t\t state  b: [0.047871066398860976, 0.0, 0.952128933601139] r: -0.545 p: 0.11500577150033305\n",
      "\t (3, 1)\n",
      "\t\t state  b: [0.012636360465925721, 0.0, 0.9873636395340744] r: -0.893 p: 0.11090171664439692\n",
      "\t (3, 3)\n",
      "\t\t state  b: [0.015925721861399053, 0.0, 0.9840742781386009] r: 0.0 p: 0.44508966450667015\n",
      " (0, 0, 1, 0)\n",
      "\t exp_regret  0.2698038339187988\n",
      "\t branches:\n",
      "\n",
      "\t (2, 0)\n",
      "\t\t state  b: [0.0015254567639351483, 0.0, 0.9984745432360649] r: -0.778 p: 0.32900284734860696\n",
      "\t (2, 3)\n",
      "\t\t state  b: [0.015925721861399053, 0.0, 0.9840742781386009] r: -0.747 p: 0.44508966450667015\n",
      "\t (2, 1)\n",
      "\t\t state  b: [0.012636360465925721, 0.0, 0.9873636395340744] r: -0.893 p: 0.11090171664439692\n",
      "\t (2, 2)\n",
      "\t\t state  b: [0.047871066398860976, 0.0, 0.952128933601139] r: 0.0 p: 0.11500577150033305\n"
     ]
    }
   ],
   "source": [
    "e.agent.tree.print_tree(end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4176775936683442"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.Attacker(g,1).exp_loss({0: (0,0,0, 1), 1: (0.32900284734860696, 0.11090171664439692, 0.11500577150033305, 0.44508966450667015)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4941953578176106"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player.Attacker(g,1).exp_loss({0: (1,0,0,0), 1: (0.32900284734860696, 0.11090171664439692, 0.11500577150033305, 0.44508966450667015)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.players[1].get_best_responder().compute_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<FixedActionDefender id:0 resources:1>: -0.6614,\n",
       " <FixedActionDefender id:0 resources:1>: -0.6961999999999999,\n",
       " <FixedActionDefender id:0 resources:1>: -0.5173,\n",
       " <FixedActionDefender id:0 resources:1>: -0.3772}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e.agent.arms.items())[1][1].tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.profiles[1].get_best_responder().tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1] -0.4191111111111111\n",
      "[0, 1, 0, 0] -0.6518888888888889\n",
      "[0, 0, 1, 0] -0.6905555555555555\n",
      "[1, 0, 0, 0] -0.49177777777777776\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d = e.game.profiles[0].get_best_responder().avg_rewards\n",
    "for k in d:\n",
    "    print(k.fixed_strategy, d[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3762342197672186"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.players[1].exp_loss({0: (1,0,0,0), 1:None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42472848854956563"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.players[1].exp_loss({0: (0,0,0,1), 1:None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exp_regret: -2.3314683517128287e-15branches: {(3, 0): state: b: [0.9984745432360649, 0.0015254567639351483, 0.0] r: -0.778 p: 0.32900284734860696branches: {}, (3, 2): state: b: [0.952128933601139, 0.047871066398860976, 0.0] r: -0.545 p: 0.11500577150033305branches: {}, (3, 1): state: b: [0.9873636395340744, 0.012636360465925721, 0.0] r: -0.893 p: 0.11090171664439692branches: {}, (3, 3): state: b: [0.9840742781386009, 0.015925721861399053, 0.0] r: 0.0 p: 0.44508966450667015branches: {}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.agent.tree.branches[(0,0,0,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6585408249864955"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.profiles[0].exp_loss({0: (1,0,0,0), 1:None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.320228040832629"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.profiles[0].exp_loss({0: (0,0,0,1), 1:None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3762342197672186"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.players[1].exp_loss({0: (1,0,0,0), 1:None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42472848854956563"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.game.players[1].exp_loss({0: (0,0,0,1), 1:None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.471429133561, 0.00602317029063, 0.096473268935, 0.426074427213]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.players[1].distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3, 0.1, 0.1, 0.5]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.profiles[0].compute_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0346193189847, 0.0966672214518, 0.379762168635, 0.488951290929]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.profiles[2].distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08207315419926424"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4748799881664601 * 0.1728292542209529"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
